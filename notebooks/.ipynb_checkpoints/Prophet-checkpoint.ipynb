{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "import ast\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from Orion.orion.evaluation import CONTEXTUAL_METRICS as METRICS\n",
    "from Orion.orion.evaluation import contextual_confusion_matrix\n",
    "from functools import partial\n",
    "from Orion.orion.benchmark import _summarize_results_datasets\n",
    "import os\n",
    "import pandas as pd\n",
    "from orion.benchmark import benchmark\n",
    "\n",
    "\n",
    "site.addsitedir('Orion/')\n",
    "site.addsitedir('MLPrimitives/')\n",
    "\n",
    "S3_URL = 'https://{}.s3.amazonaws.com/{}'\n",
    "BUCKET = 'd3-ai-orion'\n",
    "\n",
    "\n",
    "\n",
    "BENCHMARK_DATA = pd.read_csv(S3_URL.format(\n",
    "    BUCKET, 'datasets.csv'), index_col=0, header=None).applymap(ast.literal_eval).to_dict()[1]\n",
    "\n",
    "\n",
    "\n",
    "pipelines = [\n",
    "    'deepar'\n",
    "]\n",
    "\n",
    "# hyperparamters = {'MSL':{ \n",
    "# \"orion.primitives.mssa.mSSATAD#1\" :{'rank':50}}}\n",
    "\n",
    "del METRICS['accuracy']\n",
    "METRICS['confusion_matrix'] = contextual_confusion_matrix\n",
    "metrics = {k: partial(fun, weighted=False) for k, fun in METRICS.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting dataset MSL with 27 signals..\n",
      "HYPERPARAMS None\n",
      "Scoring pipeline deepar on signal M-6 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMAP\n",
      "MSL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.mx.context:Using CPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp  value\n",
      "0     1222819200   -1.0\n",
      "1     1222840800   -1.0\n",
      "2     1222862400   -1.0\n",
      "3     1222884000   -1.0\n",
      "4     1222905600   -1.0\n",
      "...          ...    ...\n",
      "1560  1256515200   -1.0\n",
      "1561  1256536800   -1.0\n",
      "1562  1256558400   -1.0\n",
      "1563  1256580000   -1.0\n",
      "1564  1256601600   -1.0\n",
      "\n",
      "[1565 rows x 2 columns]\n",
      "TEST:         timestamp       value\n",
      "0     1256623200   -1.000000\n",
      "1     1256644800   -1.000000\n",
      "2     1256666400   -1.000000\n",
      "3     1256688000   -1.000000\n",
      "4     1256709600   -1.000000\n",
      "...          ...         ...\n",
      "2044  1300773600  129.891892\n",
      "2045  1300795200  129.891892\n",
      "2046  1300816800  129.891892\n",
      "2047  1300838400  129.891892\n",
      "2048  1300860000  129.891892\n",
      "\n",
      "[2049 rows x 2 columns]\n",
      "TIMESEGMENT:  (1565, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(1565, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.96it/s, epoch=1/20, avg_epoch_loss=-.608]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 12.634 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.608388\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.64it/s, epoch=2/20, avg_epoch_loss=-2.36]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 10.788 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.355685\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.26it/s, epoch=3/20, avg_epoch_loss=-2.37]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.504 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.374316\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=4/20, avg_epoch_loss=-2.14]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.464 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.144747\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=5/20, avg_epoch_loss=-2.9]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.487 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.904964\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=6/20, avg_epoch_loss=-2.82]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.443 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.823366\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.36it/s, epoch=7/20, avg_epoch_loss=-3.07]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.334 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.065824\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.36it/s, epoch=8/20, avg_epoch_loss=-2.74]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.338 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.742073\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.24it/s, epoch=9/20, avg_epoch_loss=-3.12]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 9.546 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.120662\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.82it/s, epoch=10/20, avg_epoch_loss=-3.14]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 10.377 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.140133\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=11/20, avg_epoch_loss=-2.43]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 9.458 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.426557\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.34it/s, epoch=12/20, avg_epoch_loss=-3.33]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 9.360 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.327918\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=13/20, avg_epoch_loss=-2.98]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 9.479 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.981662\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=14/20, avg_epoch_loss=-3.26]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 9.437 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.258089\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.45it/s, epoch=15/20, avg_epoch_loss=-3.41]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.184 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.413450\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.32it/s, epoch=16/20, avg_epoch_loss=-3.52]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 9.397 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.515159\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.35it/s, epoch=17/20, avg_epoch_loss=-3.54]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.350 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.536226\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.15it/s, epoch=18/20, avg_epoch_loss=-3.55]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.709 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.549717\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.00it/s, epoch=19/20, avg_epoch_loss=-3.6]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 10.002 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.601001\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.84it/s, epoch=20/20, avg_epoch_loss=-3.63]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 10.327 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.627078\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-0.99465799]\n",
      " [-1.00313258]\n",
      " [-0.99907815]\n",
      " ...\n",
      " [-1.00421154]\n",
      " [-1.00645423]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2049, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-1 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ -1.        ]\n",
      " [ -1.        ]\n",
      " [ -1.        ]\n",
      " ...\n",
      " [129.89189189]\n",
      " [129.89189189]\n",
      " [129.89189189]]\n",
      "Y_HAT:  [[-1.0069716 ]\n",
      " [-1.00031233]\n",
      " [-1.00123835]\n",
      " ...\n",
      " [-1.00362873]\n",
      " [-1.00298679]\n",
      " [-1.00019169]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.999976\n",
      "1     1222840800  0.999976\n",
      "2     1222862400  0.999976\n",
      "3     1222884000  0.999976\n",
      "4     1222905600  0.999976\n",
      "...          ...       ...\n",
      "2204  1270425600  1.000000\n",
      "2205  1270447200  1.000000\n",
      "2206  1270468800  1.000000\n",
      "2207  1270490400  1.000000\n",
      "2208  1270512000  1.000000\n",
      "\n",
      "[2209 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1270533600  0.999906\n",
      "1     1270555200  0.999906\n",
      "2     1270576800  0.999906\n",
      "3     1270598400  0.999906\n",
      "4     1270620000  0.999906\n",
      "...          ...       ...\n",
      "2272  1319608800  1.000012\n",
      "2273  1319630400  1.000012\n",
      "2274  1319652000  1.000012\n",
      "2275  1319673600  1.000012\n",
      "2276  1319695200  1.000012\n",
      "\n",
      "[2277 rows x 2 columns]\n",
      "TIMESEGMENT:  (2209, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2209, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.71it/s, epoch=1/20, avg_epoch_loss=0.531]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.612 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.530954\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=2/20, avg_epoch_loss=-.424]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 9.463 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.423662\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.34it/s, epoch=3/20, avg_epoch_loss=-.74]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.366 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.740500\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=4/20, avg_epoch_loss=-.92]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.492 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.920103\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.40it/s, epoch=5/20, avg_epoch_loss=-1.07]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.261 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.071254\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=6/20, avg_epoch_loss=-1.26]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.497 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.262403\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.25it/s, epoch=7/20, avg_epoch_loss=-1.34]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.533 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.336571\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.25it/s, epoch=8/20, avg_epoch_loss=-1.4]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.528 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.403605\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.08it/s, epoch=9/20, avg_epoch_loss=-1.46]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 9.853 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.463186\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=10/20, avg_epoch_loss=-1.61]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 9.416 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.608399\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=11/20, avg_epoch_loss=-1.43]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 9.458 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.430873\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.36it/s, epoch=12/20, avg_epoch_loss=-1.65]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 9.330 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.651994\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=13/20, avg_epoch_loss=-1.75]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 9.474 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.750396\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s, epoch=14/20, avg_epoch_loss=-1.69]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 9.671 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.689828\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.05it/s, epoch=15/20, avg_epoch_loss=-1.75]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.898 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.750371\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.86it/s, epoch=16/20, avg_epoch_loss=-1.8]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 10.280 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.798429\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.83it/s, epoch=17/20, avg_epoch_loss=-1.74]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 10.353 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.737658\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.86it/s, epoch=18/20, avg_epoch_loss=-1.77]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 10.282 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.767230\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.89it/s, epoch=19/20, avg_epoch_loss=-1.9] \n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 10.234 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.899243\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.85it/s, epoch=20/20, avg_epoch_loss=-1.92]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 10.307 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.920365\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.99997645]\n",
      " [0.99997645]\n",
      " [0.99997645]\n",
      " ...\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " [1.        ]]\n",
      "Y_HAT:  [[0.24500996]\n",
      " [0.55244333]\n",
      " [0.9558447 ]\n",
      " ...\n",
      " [0.87391913]\n",
      " [0.8906166 ]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (2277, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-2 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.99990579]\n",
      " [0.99990579]\n",
      " [0.99990579]\n",
      " ...\n",
      " [1.00001178]\n",
      " [1.00001178]\n",
      " [1.00001178]]\n",
      "Y_HAT:  [[0.64939189]\n",
      " [1.02436984]\n",
      " [1.07160556]\n",
      " ...\n",
      " [1.42397869]\n",
      " [1.43525851]\n",
      " [1.46068239]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.748738\n",
      "1     1222840800 -0.748738\n",
      "2     1222862400 -0.748738\n",
      "3     1222884000 -0.748738\n",
      "4     1222905600 -0.748738\n",
      "...          ...       ...\n",
      "2203  1270404000 -0.748717\n",
      "2204  1270425600 -0.748717\n",
      "2205  1270447200 -0.748717\n",
      "2206  1270468800 -0.748717\n",
      "2207  1270490400 -0.748717\n",
      "\n",
      "[2208 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1270512000 -0.748738\n",
      "1     1270533600 -0.748738\n",
      "2     1270555200 -0.748738\n",
      "3     1270576800 -0.748738\n",
      "4     1270598400 -0.748738\n",
      "...          ...       ...\n",
      "2272  1319587200 -0.748738\n",
      "2273  1319608800 -0.748738\n",
      "2274  1319630400 -0.748738\n",
      "2275  1319652000 -0.748738\n",
      "2276  1319673600 -0.748738\n",
      "\n",
      "[2277 rows x 2 columns]\n",
      "TIMESEGMENT:  (2208, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2208, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.91it/s, epoch=1/20, avg_epoch_loss=-.34]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.185 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.339652\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.22it/s, epoch=2/20, avg_epoch_loss=-1.03]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 9.583 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.031666\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.22it/s, epoch=3/20, avg_epoch_loss=-1.29]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.576 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.291188\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=4/20, avg_epoch_loss=-1.44]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.491 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.440059\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.26it/s, epoch=5/20, avg_epoch_loss=-1.54]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.518 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.540726\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=6/20, avg_epoch_loss=-1.59]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.451 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.594537\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=7/20, avg_epoch_loss=-1.7]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.481 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.701907\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=8/20, avg_epoch_loss=-1.74]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.416 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.740632\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.72it/s, epoch=9/20, avg_epoch_loss=-1.78]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.602 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.784185\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.95it/s, epoch=10/20, avg_epoch_loss=-1.82]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 10.105 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.821128\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.91it/s, epoch=11/20, avg_epoch_loss=-1.91]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 10.179 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.913487\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.77it/s, epoch=12/20, avg_epoch_loss=-1.93]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 10.491 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.928382\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.75it/s, epoch=13/20, avg_epoch_loss=-1.63]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 10.533 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.629350\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s, epoch=14/20, avg_epoch_loss=-1.73]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 10.207 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.732116\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.95it/s, epoch=15/20, avg_epoch_loss=-2.03]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 10.103 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.031508\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.97it/s, epoch=16/20, avg_epoch_loss=-2]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 10.064 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.001525\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.01it/s, epoch=17/20, avg_epoch_loss=-2.07]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.990 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.073406\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.04it/s, epoch=18/20, avg_epoch_loss=-2.14]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.921 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.138437\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=19/20, avg_epoch_loss=-2.15]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.440 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.151384\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=20/20, avg_epoch_loss=-2.16]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 9.419 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.159725\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.74873821]\n",
      " [-0.74873821]\n",
      " [-0.74873821]\n",
      " ...\n",
      " [-0.74871711]\n",
      " [-0.74871711]\n",
      " [-0.74871711]]\n",
      "Y_HAT:  [[-0.28392154]\n",
      " [-0.32375544]\n",
      " [-0.59084958]\n",
      " ...\n",
      " [-0.79858702]\n",
      " [-0.77564764]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2277, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal S-2 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.74873821]\n",
      " [-0.74873821]\n",
      " [-0.74873821]\n",
      " ...\n",
      " [-0.74873821]\n",
      " [-0.74873821]\n",
      " [-0.74873821]]\n",
      "Y_HAT:  [[-0.54857826]\n",
      " [-0.60917747]\n",
      " [-0.75564307]\n",
      " ...\n",
      " [-0.83067   ]\n",
      " [-0.82902414]\n",
      " [-0.82662958]]\n",
      "TRAIN:        timestamp  value\n",
      "0    1222819200   -1.0\n",
      "1    1222840800   -1.0\n",
      "2    1222862400   -1.0\n",
      "3    1222884000   -1.0\n",
      "4    1222905600   -1.0\n",
      "..          ...    ...\n",
      "921  1242712800   -1.0\n",
      "922  1242734400   -1.0\n",
      "923  1242756000   -1.0\n",
      "924  1242777600   -1.0\n",
      "925  1242799200   -1.0\n",
      "\n",
      "[926 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1242820800   -1.0\n",
      "1     1242842400   -1.0\n",
      "2     1242864000   -1.0\n",
      "3     1242885600   -1.0\n",
      "4     1242907200   -1.0\n",
      "...          ...    ...\n",
      "1822  1282176000   -1.0\n",
      "1823  1282197600   -1.0\n",
      "1824  1282219200   -1.0\n",
      "1825  1282240800   -1.0\n",
      "1826  1282262400   -1.0\n",
      "\n",
      "[1827 rows x 2 columns]\n",
      "TIMESEGMENT:  (926, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(926, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.70it/s, epoch=1/20, avg_epoch_loss=-.761]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.657 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.760829\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.99it/s, epoch=2/20, avg_epoch_loss=-2.4]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 10.030 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.404599\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.71it/s, epoch=3/20, avg_epoch_loss=-2.73]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 10.610 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.733916\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.92it/s, epoch=4/20, avg_epoch_loss=-2.7]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 10.161 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.704463\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.99it/s, epoch=5/20, avg_epoch_loss=-2.98]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 10.027 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.976215\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.00it/s, epoch=6/20, avg_epoch_loss=-3.05]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.998 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-3.051711\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.08it/s, epoch=7/20, avg_epoch_loss=-3.14]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.844 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.137794\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.03it/s, epoch=8/20, avg_epoch_loss=-3.25]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.949 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-3.251523\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.98it/s, epoch=9/20, avg_epoch_loss=-3.3]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.044 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.301232\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.07it/s, epoch=10/20, avg_epoch_loss=-3.35]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 9.863 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.347631\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.02it/s, epoch=11/20, avg_epoch_loss=-3.42]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 9.976 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.423564\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.92it/s, epoch=12/20, avg_epoch_loss=-3.44]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 10.158 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.439343\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.97it/s, epoch=13/20, avg_epoch_loss=-3.51]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 10.065 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.507704\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.22it/s, epoch=14/20, avg_epoch_loss=-3.52]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 9.587 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.524485\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.35it/s, epoch=15/20, avg_epoch_loss=-3.57]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.345 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.566859\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.35it/s, epoch=16/20, avg_epoch_loss=-3.58]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 9.347 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.581612\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.27it/s, epoch=17/20, avg_epoch_loss=-3.62]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.493 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.622125\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.11it/s, epoch=18/20, avg_epoch_loss=-3.58]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.783 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.575816\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=19/20, avg_epoch_loss=-3.67]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.477 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.672136\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.32it/s, epoch=20/20, avg_epoch_loss=-3.68]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 9.409 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.682876\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-0.93077475]\n",
      " [-1.00820196]\n",
      " [-1.01108837]\n",
      " [-1.00700557]\n",
      " [-0.9981268 ]\n",
      " [-0.99484026]\n",
      " [-1.00632024]\n",
      " [-1.00075293]\n",
      " [-1.00320876]\n",
      " [-1.00168133]\n",
      " [-1.00309384]\n",
      " [-1.00377035]\n",
      " [-1.00302386]\n",
      " [-1.00346792]\n",
      " [-1.00220072]\n",
      " [-1.0010519 ]\n",
      " [-1.00184751]\n",
      " [-1.00478756]\n",
      " [-1.00448728]\n",
      " [-1.00433171]\n",
      " [-1.0029633 ]\n",
      " [-1.00340831]\n",
      " [-1.00493312]\n",
      " [-0.99531156]\n",
      " [-1.00169361]\n",
      " [-1.00740087]\n",
      " [-1.00027263]\n",
      " [-1.00087881]\n",
      " [-1.00047266]\n",
      " [-1.00082076]\n",
      " [-1.00285184]\n",
      " [-1.00274384]\n",
      " [-1.00076389]\n",
      " [-1.00094438]\n",
      " [-1.00241351]\n",
      " [-1.00161338]\n",
      " [-1.00172722]\n",
      " [-0.99961925]\n",
      " [-1.00264263]\n",
      " [-1.00079226]\n",
      " [-1.00284338]\n",
      " [-1.0020647 ]\n",
      " [-1.00243747]\n",
      " [-0.99942458]\n",
      " [-1.00163198]\n",
      " [-1.00287151]\n",
      " [-1.00037646]\n",
      " [-1.01634026]\n",
      " [-0.99526858]\n",
      " [-1.0016377 ]\n",
      " [-1.00186872]\n",
      " [-1.00336397]\n",
      " [-1.00293088]\n",
      " [-1.00289166]\n",
      " [-1.00596571]\n",
      " [-1.00434363]\n",
      " [-1.00473237]\n",
      " [-1.00507426]\n",
      " [-1.0036248 ]\n",
      " [-1.00381267]\n",
      " [-1.00500011]\n",
      " [-1.00302494]\n",
      " [-1.00648403]\n",
      " [-1.00448728]\n",
      " [-1.0027914 ]\n",
      " [-1.00378692]\n",
      " [-1.0040009 ]\n",
      " [-1.00065446]\n",
      " [-1.00316882]\n",
      " [-1.00382471]\n",
      " [-1.00186646]\n",
      " [-1.00025845]\n",
      " [-1.00163567]\n",
      " [-1.01109576]\n",
      " [-1.00459671]\n",
      " [-1.00208521]\n",
      " [-1.00224912]\n",
      " [-1.00091815]\n",
      " [-1.00250804]\n",
      " [-1.0034436 ]\n",
      " [-1.00471807]\n",
      " [-1.00120425]\n",
      " [-1.00282526]\n",
      " [-1.00284207]\n",
      " [-1.00279403]\n",
      " [-1.00211418]\n",
      " [-1.00332677]\n",
      " [-1.00373042]\n",
      " [-1.00340235]\n",
      " [-1.00180626]\n",
      " [-1.0017885 ]\n",
      " [-1.00241923]\n",
      " [-1.00108194]\n",
      " [-1.00189602]\n",
      " [-1.00304365]\n",
      " [-1.00657856]\n",
      " [-1.00635338]\n",
      " [-1.00250089]\n",
      " [-1.00148153]\n",
      " [-1.00062013]\n",
      " [-1.00173736]\n",
      " [-1.00385177]\n",
      " [-1.00120425]\n",
      " [-1.00363982]\n",
      " [-1.00329304]\n",
      " [-1.00435841]\n",
      " [-1.00298584]\n",
      " [-1.00382853]\n",
      " [-1.0026238 ]\n",
      " [-1.00286508]\n",
      " [-1.00440121]\n",
      " [-1.00517809]\n",
      " [-1.00437474]\n",
      " [-1.00554752]\n",
      " [-1.00282347]\n",
      " [-1.0054009 ]\n",
      " [-1.00492346]\n",
      " [-1.00399172]\n",
      " [-1.0048331 ]\n",
      " [-0.9935497 ]\n",
      " [-1.00644255]\n",
      " [-1.00596726]\n",
      " [-1.00128949]\n",
      " [-0.9989807 ]\n",
      " [-1.00222909]\n",
      " [-1.00399089]\n",
      " [-1.00271261]\n",
      " [-1.00320566]\n",
      " [-1.00440991]\n",
      " [-1.00367427]\n",
      " [-1.00392187]\n",
      " [-1.00355136]\n",
      " [-1.00305951]\n",
      " [-1.001531  ]\n",
      " [-1.0033952 ]\n",
      " [-1.00400531]\n",
      " [-1.00452876]\n",
      " [-1.0033592 ]\n",
      " [-1.00393391]\n",
      " [-1.00448167]\n",
      " [-1.00198781]\n",
      " [-1.00386691]\n",
      " [-1.00284755]\n",
      " [-1.00463319]\n",
      " [-0.99085975]\n",
      " [-1.0052861 ]\n",
      " [-1.00392449]\n",
      " [-1.0054127 ]\n",
      " [-1.00487649]\n",
      " [-1.00488889]\n",
      " [-1.00489569]\n",
      " [-1.00461566]\n",
      " [-1.00570667]\n",
      " [-1.00432682]\n",
      " [-1.00589347]\n",
      " [-1.0054214 ]\n",
      " [-1.00542593]\n",
      " [-1.00569797]\n",
      " [-1.0048852 ]\n",
      " [-1.00633526]\n",
      " [-1.00676012]\n",
      " [-1.00401354]\n",
      " [-1.00624621]\n",
      " [-1.00439548]\n",
      " [-1.00544643]\n",
      " [-1.00431812]\n",
      " [-1.00571001]\n",
      " [-0.994636  ]\n",
      " [-0.99461114]\n",
      " [-1.00028408]\n",
      " [-1.00100338]\n",
      " [-1.00309944]\n",
      " [-1.00271106]\n",
      " [-1.00314689]\n",
      " [-1.002195  ]\n",
      " [-1.00353253]\n",
      " [-1.00428975]\n",
      " [-1.00295556]\n",
      " [-1.00310457]\n",
      " [-1.00419343]\n",
      " [-1.00395954]\n",
      " [-1.00518072]\n",
      " [-1.00294268]\n",
      " [-1.00374126]\n",
      " [-1.00248945]\n",
      " [-1.00393915]\n",
      " [-1.00261068]\n",
      " [-1.0028466 ]\n",
      " [-1.00221145]\n",
      " [-1.00359046]\n",
      " [-1.00420797]\n",
      " [-1.00199389]\n",
      " [-1.00437319]\n",
      " [-1.00130427]\n",
      " [-1.0018332 ]\n",
      " [-1.00488031]\n",
      " [-1.00327313]\n",
      " [-1.00384319]\n",
      " [-1.00376022]\n",
      " [-1.00346565]\n",
      " [-1.00294614]\n",
      " [-1.00367451]\n",
      " [-1.00345838]\n",
      " [-1.00275552]\n",
      " [-1.00261247]\n",
      " [-1.00296092]\n",
      " [-1.00291729]\n",
      " [-1.00292301]\n",
      " [-1.0018127 ]\n",
      " [-1.00350249]\n",
      " [-1.00293207]\n",
      " [-1.00205362]\n",
      " [-1.00418019]\n",
      " [-1.00226772]\n",
      " [-1.00341666]\n",
      " [-1.00249767]\n",
      " [-1.00295782]\n",
      " [-1.00152779]\n",
      " [-1.00300109]\n",
      " [-1.0021261 ]\n",
      " [-1.00227296]\n",
      " [-1.00208056]\n",
      " [-1.00160134]\n",
      " [-1.0031575 ]\n",
      " [-1.00299597]\n",
      " [-1.00183904]\n",
      " [-1.00321591]\n",
      " [-1.00203764]\n",
      " [-1.00277245]\n",
      " [-1.00230157]\n",
      " [-1.00295734]\n",
      " [-1.00161207]\n",
      " [-1.00267708]\n",
      " [-1.00273085]\n",
      " [-1.00300527]\n",
      " [-1.00380957]\n",
      " [-1.00297344]\n",
      " [-1.00138712]\n",
      " [-1.00321913]\n",
      " [-1.00241077]\n",
      " [-1.00251985]\n",
      " [-1.00178897]\n",
      " [-1.00252092]\n",
      " [-0.99968094]\n",
      " [-1.00085914]\n",
      " [-1.00127721]\n",
      " [-1.00132096]\n",
      " [-1.00136733]\n",
      " [-1.00071669]\n",
      " [-1.00152159]\n",
      " [-1.00257313]\n",
      " [-1.00065756]\n",
      " [-1.0013814 ]\n",
      " [-1.00150037]\n",
      " [-1.00238299]\n",
      " [-1.00115001]\n",
      " [-1.00260258]\n",
      " [-1.00370896]\n",
      " [-1.00318718]\n",
      " [-1.00204623]\n",
      " [-1.00280869]\n",
      " [-1.00237048]\n",
      " [-1.00164115]\n",
      " [-1.00127184]\n",
      " [-1.00311327]\n",
      " [-1.00160122]\n",
      " [-1.00077176]\n",
      " [-1.00176036]\n",
      " [-1.00167966]\n",
      " [-1.0002085 ]\n",
      " [-1.00184321]\n",
      " [-1.00214231]\n",
      " [-1.00072801]\n",
      " [-1.00169504]\n",
      " [-1.00104642]\n",
      " [-1.0012629 ]\n",
      " [-1.00204253]\n",
      " [-1.00133729]\n",
      " [-1.00260222]\n",
      " [-1.00176167]\n",
      " [-1.00147069]\n",
      " [-1.00166023]\n",
      " [-1.00240552]\n",
      " [-1.00211525]\n",
      " [-1.00136828]\n",
      " [-1.00154102]\n",
      " [-1.00193989]\n",
      " [-1.00115943]\n",
      " [-1.00176191]\n",
      " [-1.00021136]\n",
      " [-0.99976057]\n",
      " [-1.00049067]\n",
      " [-1.00115979]\n",
      " [-1.00047207]\n",
      " [-1.00062847]\n",
      " [-1.00124192]\n",
      " [-1.0013622 ]\n",
      " [-1.00106883]\n",
      " [-1.00116551]\n",
      " [-1.00114202]\n",
      " [-1.00169587]\n",
      " [-0.99991339]\n",
      " [-1.00214303]\n",
      " [-1.00116551]\n",
      " [-1.00055659]\n",
      " [-1.00181389]\n",
      " [-1.00064266]\n",
      " [-1.00109541]\n",
      " [-0.99989963]\n",
      " [-0.9996962 ]\n",
      " [-1.0015043 ]\n",
      " [-1.00058603]\n",
      " [-1.00678861]\n",
      " [-1.00272107]\n",
      " [-1.00189602]\n",
      " [-1.00265157]\n",
      " [-1.00188589]\n",
      " [-1.00141346]\n",
      " [-1.00182259]\n",
      " [-1.00162137]\n",
      " [-1.00081301]\n",
      " [-1.00040853]\n",
      " [-1.00256109]\n",
      " [-1.00067174]\n",
      " [-1.00217986]\n",
      " [-1.001652  ]\n",
      " [-1.00313306]\n",
      " [-1.0014993 ]\n",
      " [-1.00170863]\n",
      " [-1.00024247]\n",
      " [-1.00225401]\n",
      " [-1.00097048]\n",
      " [-1.00178099]\n",
      " [-1.00184584]\n",
      " [-1.00102043]\n",
      " [-1.0073756 ]\n",
      " [-0.99154884]\n",
      " [-0.99991602]\n",
      " [-1.0003525 ]\n",
      " [-0.99872971]\n",
      " [-1.0026629 ]\n",
      " [-1.00234342]\n",
      " [-1.00137329]\n",
      " [-1.00158179]\n",
      " [-1.00141704]\n",
      " [-1.00290775]\n",
      " [-1.00313663]\n",
      " [-1.00174224]\n",
      " [-1.00255549]\n",
      " [-1.00272906]\n",
      " [-1.00106764]\n",
      " [-1.00094724]\n",
      " [-1.00246036]\n",
      " [-1.00063956]\n",
      " [-1.00223041]\n",
      " [-1.00241792]\n",
      " [-1.00152934]\n",
      " [-1.00200868]\n",
      " [-1.00098276]\n",
      " [-1.00037861]\n",
      " [-1.00135112]\n",
      " [-1.00041759]\n",
      " [-1.00095332]\n",
      " [-1.00151432]\n",
      " [-1.00108218]\n",
      " [-1.0027746 ]\n",
      " [-1.00199413]\n",
      " [-1.00185323]\n",
      " [-1.00141346]\n",
      " [-1.00167727]\n",
      " [-1.00194836]\n",
      " [-1.00188208]\n",
      " [-1.00116909]\n",
      " [-1.0025233 ]\n",
      " [-1.00091624]\n",
      " [-1.00125706]\n",
      " [-1.00027156]\n",
      " [-1.00366175]\n",
      " [-1.0020932 ]\n",
      " [-1.00128424]\n",
      " [-1.00179565]\n",
      " [-1.00199056]\n",
      " [-1.001598  ]\n",
      " [-1.00153506]\n",
      " [-1.00115848]\n",
      " [-1.0005548 ]\n",
      " [-1.00026655]\n",
      " [-1.00122929]\n",
      " [-1.00104129]\n",
      " [-1.00090754]\n",
      " [-1.00154853]\n",
      " [-1.00093508]\n",
      " [-1.00144446]\n",
      " [-1.00230277]\n",
      " [-1.00113094]\n",
      " [-1.00056791]\n",
      " [-1.00119364]\n",
      " [-1.00145364]\n",
      " [-1.0023464 ]\n",
      " [-1.00150144]\n",
      " [-1.00112605]\n",
      " [-0.99992478]\n",
      " [-1.00205135]\n",
      " [-1.0016346 ]\n",
      " [-1.00070775]\n",
      " [-1.00127816]\n",
      " [-1.00069439]\n",
      " [-1.00132716]\n",
      " [-0.99982202]\n",
      " [-1.00033247]\n",
      " [-1.000911  ]\n",
      " [-0.99995005]\n",
      " [-1.00056577]\n",
      " [-1.0023644 ]\n",
      " [-1.00247562]\n",
      " [-1.00043833]\n",
      " [-1.00147879]\n",
      " [-1.00066626]\n",
      " [-1.00139976]\n",
      " [-1.00128794]\n",
      " [-1.00194192]\n",
      " [-1.00151384]\n",
      " [-1.00146651]\n",
      " [-1.00045979]\n",
      " [-1.00208998]\n",
      " [-1.0015974 ]\n",
      " [-1.00014722]\n",
      " [-1.00159931]\n",
      " [-1.00140834]\n",
      " [-1.00223315]\n",
      " [-1.00155187]\n",
      " [-1.00138748]\n",
      " [-1.00065088]\n",
      " [-1.00032568]\n",
      " [-1.00008273]\n",
      " [-1.00045192]\n",
      " [-1.00068486]\n",
      " [-1.00244081]\n",
      " [-1.00039017]\n",
      " [-1.00035   ]\n",
      " [-1.00047135]\n",
      " [-1.00207865]\n",
      " [-1.00210142]\n",
      " [-1.00178039]\n",
      " [-1.00268412]\n",
      " [-0.99922282]\n",
      " [-1.00146198]\n",
      " [-1.0011493 ]\n",
      " [-1.00100386]\n",
      " [-1.00045133]\n",
      " [-1.00153518]\n",
      " [-1.00105703]\n",
      " [-1.00204921]\n",
      " [-0.99981201]\n",
      " [-1.00131047]\n",
      " [-1.00013959]\n",
      " [-0.99933457]\n",
      " [-1.00027287]\n",
      " [-1.00105631]\n",
      " [-1.00104451]\n",
      " [-1.00176501]\n",
      " [-0.99975258]\n",
      " [-0.99969023]\n",
      " [-0.99984461]\n",
      " [-1.00105143]\n",
      " [-1.00294471]\n",
      " [-1.00065804]\n",
      " [-1.00241995]\n",
      " [-1.00084436]\n",
      " [-1.00096357]\n",
      " [-1.00013566]\n",
      " [-1.00107265]\n",
      " [-1.00140929]\n",
      " [-1.00008631]\n",
      " [-0.99853987]\n",
      " [-1.00169706]\n",
      " [-1.00035954]\n",
      " [-1.00249147]\n",
      " [-1.00138021]\n",
      " [-1.00069356]\n",
      " [-1.00386167]\n",
      " [-1.00244081]\n",
      " [-1.00213444]\n",
      " [-1.00239968]\n",
      " [-1.00260186]\n",
      " [-1.00285041]\n",
      " [-1.00211334]\n",
      " [-1.0023129 ]\n",
      " [-1.00337863]\n",
      " [-1.00259817]\n",
      " [-1.00155675]\n",
      " [-1.00238609]\n",
      " [-1.00215483]\n",
      " [-1.00244415]\n",
      " [-1.00270045]\n",
      " [-1.00161588]\n",
      " [-1.00265265]\n",
      " [-1.00111246]\n",
      " [-1.00144041]\n",
      " [-1.00103033]\n",
      " [-1.00180662]\n",
      " [-1.00246525]\n",
      " [-1.00171351]\n",
      " [-1.02756274]\n",
      " [-1.02011657]\n",
      " [-0.9959864 ]\n",
      " [-0.99993306]\n",
      " [-1.00112402]\n",
      " [-1.00209928]\n",
      " [-1.00135493]\n",
      " [-1.00376773]\n",
      " [-1.00344729]\n",
      " [-1.0026654 ]\n",
      " [-1.00311613]\n",
      " [-1.00170696]\n",
      " [-1.00099957]\n",
      " [-1.002298  ]\n",
      " [-1.00148273]\n",
      " [-1.00211298]\n",
      " [-1.00219476]\n",
      " [-1.00308681]\n",
      " [-1.00155652]\n",
      " [-1.00221872]\n",
      " [-1.00183213]\n",
      " [-1.00328839]\n",
      " [-1.0026803 ]\n",
      " [-1.00272954]\n",
      " [-1.00152683]\n",
      " [-1.00080717]\n",
      " [-1.00217342]\n",
      " [-1.00171328]\n",
      " [-1.00242209]\n",
      " [-1.00066519]\n",
      " [-1.00303662]\n",
      " [-1.00302172]\n",
      " [-1.00159848]\n",
      " [-1.00282073]\n",
      " [-1.0017904 ]\n",
      " [-1.00106442]\n",
      " [-1.00080323]\n",
      " [-1.00282192]\n",
      " [-1.00170124]\n",
      " [-1.00240445]\n",
      " [-1.00413668]\n",
      " [-0.99989283]\n",
      " [-1.00248826]\n",
      " [-1.00154221]\n",
      " [-1.0011245 ]\n",
      " [-1.00203812]\n",
      " [-1.00118649]\n",
      " [-1.00331008]\n",
      " [-1.00237536]\n",
      " [-1.00022662]\n",
      " [-1.00292528]\n",
      " [-1.0019151 ]\n",
      " [-1.00244904]\n",
      " [-1.00171626]\n",
      " [-1.00180256]\n",
      " [-1.0019784 ]\n",
      " [-1.00254643]\n",
      " [-1.00261045]\n",
      " [-1.00061834]\n",
      " [-1.00213671]\n",
      " [-1.00144362]\n",
      " [-1.00227702]\n",
      " [-1.00214624]\n",
      " [-1.0021373 ]\n",
      " [-1.0015676 ]\n",
      " [-1.00150895]\n",
      " [-1.00299597]\n",
      " [-1.001809  ]\n",
      " [-1.00107098]\n",
      " [-1.00314045]\n",
      " [-1.00172591]\n",
      " [-1.00092149]\n",
      " [-1.00085378]\n",
      " [-0.99979037]\n",
      " [-1.0012145 ]\n",
      " [-0.99972147]\n",
      " [-1.00339139]\n",
      " [-1.00256574]\n",
      " [-1.00285053]\n",
      " [-1.00343227]\n",
      " [-1.00281978]\n",
      " [-1.00255024]\n",
      " [-0.99963129]\n",
      " [-1.00177991]\n",
      " [-1.00207174]\n",
      " [-1.00070417]\n",
      " [-1.00267935]\n",
      " [-1.00191689]\n",
      " [-1.00148094]\n",
      " [-1.00112116]\n",
      " [-1.00078917]\n",
      " [-1.00178194]\n",
      " [-1.00100362]\n",
      " [-1.00259304]\n",
      " [-1.0027535 ]\n",
      " [-1.00290132]\n",
      " [-1.00363779]\n",
      " [-0.99996895]\n",
      " [-1.00079906]\n",
      " [-1.00178742]\n",
      " [-1.00114107]\n",
      " [-1.00080514]\n",
      " [-1.00123799]\n",
      " [-1.00161815]\n",
      " [-1.00085914]\n",
      " [-1.00210714]\n",
      " [-1.00098681]\n",
      " [-1.00009382]\n",
      " [-1.00192332]\n",
      " [-1.00253463]\n",
      " [-0.9997046 ]\n",
      " [-1.00222814]\n",
      " [-1.00177705]\n",
      " [-1.00068438]\n",
      " [-0.99997902]\n",
      " [-1.00116706]\n",
      " [-1.00101137]\n",
      " [-1.00065064]\n",
      " [-1.00130498]\n",
      " [-1.00157022]\n",
      " [-1.00188994]\n",
      " [-0.99984819]\n",
      " [-1.00093508]\n",
      " [-1.00111628]\n",
      " [-1.00035799]\n",
      " [-1.00048852]\n",
      " [-1.00243425]\n",
      " [-1.00245154]\n",
      " [-1.00156689]\n",
      " [-1.00088549]\n",
      " [-1.00171316]\n",
      " [-1.00222826]\n",
      " [-1.00201726]\n",
      " [-1.00092149]\n",
      " [-1.00055492]\n",
      " [-1.00018537]\n",
      " [-1.00247157]\n",
      " [-1.00172031]\n",
      " [-0.9998216 ]\n",
      " [-1.0014652 ]\n",
      " [-1.00239205]\n",
      " [-1.0006882 ]\n",
      " [-1.00060129]\n",
      " [-1.00130713]\n",
      " [-1.00101972]\n",
      " [-1.00376534]\n",
      " [-1.0041945 ]\n",
      " [-1.0031606 ]\n",
      " [-1.00360858]\n",
      " [-1.00080991]\n",
      " [-1.00258207]\n",
      " [-1.00277007]\n",
      " [-1.00124729]\n",
      " [-1.00272608]\n",
      " [-1.00136518]\n",
      " [-1.00278032]\n",
      " [-1.00181186]\n",
      " [-1.00221467]\n",
      " [-1.00269878]\n",
      " [-1.00253546]\n",
      " [-1.00158501]\n",
      " [-1.00096691]\n",
      " [-1.00200963]\n",
      " [-1.00171423]\n",
      " [-1.00130093]\n",
      " [-1.00112116]\n",
      " [-1.00211751]\n",
      " [-1.00180721]\n",
      " [-1.00741017]\n",
      " [-1.01388001]\n",
      " [-1.0008955 ]\n",
      " [-0.99847114]\n",
      " [-1.00018501]\n",
      " [-1.00259197]\n",
      " [-0.99998629]\n",
      " [-1.00073886]\n",
      " [-1.00326705]\n",
      " [-1.00055933]\n",
      " [-1.00084257]\n",
      " [-1.00235963]\n",
      " [-1.0025804 ]\n",
      " [-1.00277424]\n",
      " [-1.00300395]\n",
      " [-1.00173116]\n",
      " [-1.00157106]\n",
      " [-1.00068641]\n",
      " [-1.00170898]\n",
      " [-1.00159633]\n",
      " [-1.00196433]\n",
      " [-1.00310087]\n",
      " [-1.00231016]\n",
      " [-1.00052881]\n",
      " [-1.0017122 ]\n",
      " [-1.00310588]\n",
      " [-1.00123918]\n",
      " [-1.00159204]\n",
      " [-1.00400615]\n",
      " [-1.00256836]\n",
      " [-1.00195599]\n",
      " [-1.00252712]\n",
      " [-1.00120699]\n",
      " [-1.00112605]\n",
      " [-1.00019872]\n",
      " [-1.00245202]\n",
      " [-1.00044739]\n",
      " [-1.00162804]\n",
      " [-1.00159132]\n",
      " [-1.00252664]\n",
      " [-0.99996352]\n",
      " [-1.00233603]\n",
      " [-1.00097418]\n",
      " [-0.99990392]\n",
      " [-1.00229406]\n",
      " [-1.00012028]\n",
      " [-1.00165617]\n",
      " [-1.00010824]\n",
      " [-1.01406384]\n",
      " [-0.99600238]\n",
      " [-1.0073899 ]\n",
      " [-1.00418961]\n",
      " [-1.00371695]\n",
      " [-1.00453794]\n",
      " [-1.00240362]\n",
      " [-1.00412333]\n",
      " [-1.0040288 ]\n",
      " [-1.00307047]\n",
      " [-1.00388849]\n",
      " [-1.00441611]\n",
      " [-1.00377285]\n",
      " [-1.00603974]\n",
      " [-1.00408709]\n",
      " [-1.00493181]\n",
      " [-1.00576258]\n",
      " [-1.00473297]\n",
      " [-1.00490618]\n",
      " [-1.00495327]\n",
      " [-1.00442719]\n",
      " [-1.0042851 ]\n",
      " [-1.00415647]\n",
      " [-1.00449634]\n",
      " [-1.00364661]\n",
      " [-1.0016979 ]\n",
      " [-1.0046556 ]\n",
      " [-1.00462604]\n",
      " [-1.00415146]\n",
      " [-1.00413263]\n",
      " [-1.00494862]\n",
      " [-1.00497139]\n",
      " [-1.00536215]\n",
      " [-1.00476885]\n",
      " [-1.00506854]\n",
      " [-1.00460386]\n",
      " [-1.00565791]\n",
      " [-1.00422084]\n",
      " [-1.00494075]\n",
      " [-1.00506449]\n",
      " [-1.00592053]\n",
      " [-1.00521743]\n",
      " [-1.00391316]\n",
      " [-1.00510836]\n",
      " [-1.00418437]\n",
      " [-1.00414097]\n",
      " [-1.00690258]\n",
      " [-1.00653172]\n",
      " [-1.00539041]\n",
      " [-1.00496173]\n",
      " [-1.0039109 ]\n",
      " [-1.00466883]\n",
      " [-1.00594139]\n",
      " [-1.00522816]\n",
      " [-1.00384176]\n",
      " [-1.00510848]\n",
      " [-1.00537062]\n",
      " [-1.00532866]\n",
      " [-1.00388467]\n",
      " [-1.005615  ]\n",
      " [-1.00454664]\n",
      " [-1.00408518]\n",
      " [-1.00482571]\n",
      " [-1.00577807]\n",
      " [-1.00344729]\n",
      " [-1.00518227]\n",
      " [-1.00540328]\n",
      " [-1.00450802]\n",
      " [-1.00507104]\n",
      " [-1.00300264]\n",
      " [-1.00629961]\n",
      " [-1.00464571]\n",
      " [-1.00514531]\n",
      " [-1.00482404]\n",
      " [-1.00434947]\n",
      " [-1.00341344]\n",
      " [-1.00427556]\n",
      " [-1.00524294]\n",
      " [-1.00421512]\n",
      " [-1.00311959]\n",
      " [-1.00378168]\n",
      " [-1.00399721]\n",
      " [-1.00411749]\n",
      " [-1.00479829]\n",
      " [-1.00560713]\n",
      " [-1.00641489]\n",
      " [-1.00573385]\n",
      " [-1.0043906 ]\n",
      " [-1.00459242]\n",
      " [-1.0063709 ]\n",
      " [-1.00517595]\n",
      " [-1.00392377]\n",
      " [-1.00271726]\n",
      " [-1.0050633 ]\n",
      " [-1.00611317]\n",
      " [-1.00514865]\n",
      " [-1.00488186]\n",
      " [-1.00506973]\n",
      " [-1.00425756]\n",
      " [-1.00612426]\n",
      " [-1.006845  ]\n",
      " [-1.00664127]\n",
      " [-1.00594401]\n",
      " [-1.00627065]\n",
      " [-1.00662982]\n",
      " [-1.00649345]\n",
      " [-1.0059731 ]\n",
      " [-1.00614464]\n",
      " [-1.00578427]\n",
      " [-1.00541997]\n",
      " [-1.00502789]\n",
      " [-1.00611222]\n",
      " [-1.00672734]\n",
      " [-1.00624716]\n",
      " [-1.00642276]\n",
      " [-1.00736594]\n",
      " [-1.00550199]\n",
      " [-1.00539637]\n",
      " [-1.00613058]\n",
      " [-1.00554013]\n",
      " [-1.00507963]\n",
      " [-1.00593531]\n",
      " [-1.00478101]\n",
      " [-1.00521135]\n",
      " [-1.00518727]\n",
      " [-1.00542891]\n",
      " [-1.00528026]\n",
      " [-1.00450587]\n",
      " [-1.00535631]\n",
      " [-1.00591516]\n",
      " [-1.00556958]\n",
      " [-1.00563657]\n",
      " [-1.00575876]\n",
      " [-1.00583148]\n",
      " [-1.00537074]\n",
      " [-1.004269  ]\n",
      " [-1.00492835]\n",
      " [-1.00587296]\n",
      " [-1.00483322]\n",
      " [-1.00612843]\n",
      " [-1.00522935]\n",
      " [-1.00631297]\n",
      " [-1.00576007]\n",
      " [-1.0055083 ]\n",
      " [-1.00539052]\n",
      " [-1.00501204]\n",
      " [-1.00551617]\n",
      " [-1.00489652]\n",
      " [-1.00455439]\n",
      " [-1.00551379]\n",
      " [-1.00438154]\n",
      " [-1.0055964 ]\n",
      " [-1.00498807]\n",
      " [-1.00452495]\n",
      " [-1.00552213]\n",
      " [-1.00543666]\n",
      " [-1.00483048]\n",
      " [-1.00617957]\n",
      " [-1.00453007]\n",
      " [-1.00625062]\n",
      " [-1.00507927]\n",
      " [-1.00640249]\n",
      " [-1.00474477]\n",
      " [-1.00332868]\n",
      " [-1.00589752]\n",
      " [-1.00603294]\n",
      " [-1.00564611]\n",
      " [-1.00382483]\n",
      " [-1.00594044]\n",
      " [-1.00616872]\n",
      " [-1.00445867]\n",
      " [-1.00511098]\n",
      " [-1.00572658]\n",
      " [-1.00534427]\n",
      " [-1.00579929]\n",
      " [-1.0049969 ]\n",
      " [-1.00428271]\n",
      " [-1.00626647]\n",
      " [-1.00427699]\n",
      " [-1.0058322 ]\n",
      " [-1.0055362 ]\n",
      " [-1.00665414]\n",
      " [-1.00441265]\n",
      " [-1.00419402]\n",
      " [-1.00536346]\n",
      " [-1.00574601]\n",
      " [-1.00574982]\n",
      " [-1.00483668]\n",
      " [-1.00640774]\n",
      " [-1.0049144 ]\n",
      " [-1.00443685]\n",
      " [-1.00517809]\n",
      " [-1.00661695]\n",
      " [-1.00411308]\n",
      " [-1.00428236]\n",
      " [-1.00449824]\n",
      " [-1.00404119]\n",
      " [-1.00485015]\n",
      " [-1.00471115]\n",
      " [-1.0058198 ]\n",
      " [-1.00606906]\n",
      " [-1.00487649]\n",
      " [-1.00444794]\n",
      " [-1.00555718]\n",
      " [-1.00405025]\n",
      " [-1.00601065]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (1827, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal P-10 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.01346242]\n",
      " [-1.01373911]\n",
      " [-1.00381136]\n",
      " ...\n",
      " [-1.0061636 ]\n",
      " [-1.00783062]\n",
      " [-1.00628674]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.994353\n",
      "1     1222840800  0.993788\n",
      "2     1222862400  0.994353\n",
      "3     1222884000  0.993506\n",
      "4     1222905600  0.994353\n",
      "...          ...       ...\n",
      "4303  1315764000  0.991811\n",
      "4304  1315785600  0.992376\n",
      "4305  1315807200  0.994635\n",
      "4306  1315828800  0.993506\n",
      "4307  1315850400  0.993506\n",
      "\n",
      "[4308 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1315872000  0.992941\n",
      "1     1315893600  0.993788\n",
      "2     1315915200  0.993788\n",
      "3     1315936800  0.994635\n",
      "4     1315958400  0.994635\n",
      "...          ...       ...\n",
      "6095  1447524000 -0.653819\n",
      "6096  1447545600 -0.654666\n",
      "6097  1447567200 -0.654666\n",
      "6098  1447588800 -0.652972\n",
      "6099  1447610400 -0.663137\n",
      "\n",
      "[6100 rows x 2 columns]\n",
      "TIMESEGMENT:  (4308, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(4308, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.54it/s, epoch=1/20, avg_epoch_loss=-.882]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 11.012 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.881787\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.55it/s, epoch=2/20, avg_epoch_loss=-2.58]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 10.992 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.581626\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.14it/s, epoch=3/20, avg_epoch_loss=-1.96]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 12.091 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.957739\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.79it/s, epoch=4/20, avg_epoch_loss=-2.84]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 10.447 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.836738\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.88it/s, epoch=5/20, avg_epoch_loss=-3.01]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 10.258 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-3.006258\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.18it/s, epoch=6/20, avg_epoch_loss=-3.06]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.662 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-3.064468\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.16it/s, epoch=7/20, avg_epoch_loss=-3.16]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.698 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.158757\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.07it/s, epoch=8/20, avg_epoch_loss=-3.23]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.856 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-3.227380\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s, epoch=9/20, avg_epoch_loss=-3.32]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.213 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.320898\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.87it/s, epoch=10/20, avg_epoch_loss=-3.34]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 10.286 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.342293\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.65it/s, epoch=11/20, avg_epoch_loss=-3.43]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 10.748 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.426085\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s, epoch=12/20, avg_epoch_loss=-3.35]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 10.208 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.349942\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.96it/s, epoch=13/20, avg_epoch_loss=-3.45]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 10.090 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.454732\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.90it/s, epoch=14/20, avg_epoch_loss=-3.48]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 10.205 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.484740\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.44it/s, epoch=15/20, avg_epoch_loss=-3.53]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.190 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.526916\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=16/20, avg_epoch_loss=-3.55]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.946 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.545482\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.10it/s, epoch=17/20, avg_epoch_loss=-3.58]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.199 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.575349\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.16it/s, epoch=18/20, avg_epoch_loss=-3.58]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.121 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.583646\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=19/20, avg_epoch_loss=-3.61]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.023 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.610320\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.13it/s, epoch=20/20, avg_epoch_loss=-3.63]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.169 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.626632\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.99435268]\n",
      " [0.99378794]\n",
      " [0.99435268]\n",
      " ...\n",
      " [0.99463504]\n",
      " [0.99350558]\n",
      " [0.99350558]]\n",
      "Y_HAT:  [[0.78940988]\n",
      " [0.86943316]\n",
      " [1.01371813]\n",
      " ...\n",
      " [0.99591255]\n",
      " [0.99769843]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (6100, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 0.99294084]\n",
      " [ 0.99378794]\n",
      " [ 0.99378794]\n",
      " ...\n",
      " [-0.6546661 ]\n",
      " [-0.6529719 ]\n",
      " [-0.66313709]]\n",
      "Y_HAT:  [[0.88188994]\n",
      " [0.99869817]\n",
      " [1.00223994]\n",
      " ...\n",
      " [0.99909109]\n",
      " [1.00083041]\n",
      " [0.99907172]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-4 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp  value\n",
      "0     1222819200    0.0\n",
      "1     1222840800    0.0\n",
      "2     1222862400    0.0\n",
      "3     1222884000    0.0\n",
      "4     1222905600    0.0\n",
      "...          ...    ...\n",
      "2267  1271786400    0.0\n",
      "2268  1271808000    0.0\n",
      "2269  1271829600    0.0\n",
      "2270  1271851200    0.0\n",
      "2271  1271872800    0.0\n",
      "\n",
      "[2272 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1271894400    0.0\n",
      "1     1271916000    0.0\n",
      "2     1271937600    0.0\n",
      "3     1271959200    0.0\n",
      "4     1271980800    0.0\n",
      "...          ...    ...\n",
      "2212  1319673600    0.0\n",
      "2213  1319695200    0.0\n",
      "2214  1319716800    0.0\n",
      "2215  1319738400    0.0\n",
      "2216  1319760000    0.0\n",
      "\n",
      "[2217 rows x 2 columns]\n",
      "TIMESEGMENT:  (2272, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2272, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.78it/s, epoch=1/20, avg_epoch_loss=0.443]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.658 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.442945\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s, epoch=2/20, avg_epoch_loss=-.342]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.181 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.341886\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.10it/s, epoch=3/20, avg_epoch_loss=-.758]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.206 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.757820\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=4/20, avg_epoch_loss=-.982]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.114 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.982116\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.28it/s, epoch=5/20, avg_epoch_loss=-1.11]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.968 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.113442\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s, epoch=6/20, avg_epoch_loss=-1.25]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.183 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.252798\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.19it/s, epoch=7/20, avg_epoch_loss=-1.35]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.081 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.354100\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=8/20, avg_epoch_loss=-1.48]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.796 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.476952\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=9/20, avg_epoch_loss=-1.53]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.806 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.534483\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=10/20, avg_epoch_loss=-1.61]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.870 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.614390\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=11/20, avg_epoch_loss=-1.67]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.995 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.671274\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=12/20, avg_epoch_loss=-1.62]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.938 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.619582\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.46it/s, epoch=13/20, avg_epoch_loss=-1.61]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 7.750 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.613089\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=14/20, avg_epoch_loss=-1.78]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 7.860 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.782993\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=15/20, avg_epoch_loss=-1.85]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 7.928 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.853251\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=16/20, avg_epoch_loss=-1.85]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.833 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.851114\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=17/20, avg_epoch_loss=-1.88]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.902 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.875076\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s, epoch=18/20, avg_epoch_loss=-1.91]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.236 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.913017\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=19/20, avg_epoch_loss=-1.97]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.988 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.974082\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.46it/s, epoch=20/20, avg_epoch_loss=-1.86]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.747 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.863389\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Y_HAT:  [[-0.00108364]\n",
      " [ 0.00047007]\n",
      " [ 0.0030073 ]\n",
      " ...\n",
      " [-0.00345523]\n",
      " [ 0.025413  ]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2217, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-5 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Y_HAT:  [[-0.00194912]\n",
      " [ 0.0002073 ]\n",
      " [-0.00608778]\n",
      " ...\n",
      " [ 0.02577072]\n",
      " [ 0.00729995]\n",
      " [ 0.0056974 ]]\n",
      "TRAIN:         timestamp  value\n",
      "0     1222819200   -1.0\n",
      "1     1222840800   -1.0\n",
      "2     1222862400   -1.0\n",
      "3     1222884000   -1.0\n",
      "4     1222905600   -1.0\n",
      "...          ...    ...\n",
      "2267  1271786400   -1.0\n",
      "2268  1271808000   -1.0\n",
      "2269  1271829600   -1.0\n",
      "2270  1271851200   -1.0\n",
      "2271  1271872800   -1.0\n",
      "\n",
      "[2272 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1271894400   -1.0\n",
      "1     1271916000   -1.0\n",
      "2     1271937600   -1.0\n",
      "3     1271959200   -1.0\n",
      "4     1271980800   -1.0\n",
      "...          ...    ...\n",
      "2213  1319695200   -1.0\n",
      "2214  1319716800   -1.0\n",
      "2215  1319738400   -1.0\n",
      "2216  1319760000   -1.0\n",
      "2217  1319781600   -1.0\n",
      "\n",
      "[2218 rows x 2 columns]\n",
      "TIMESEGMENT:  (2272, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2272, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.93it/s, epoch=1/20, avg_epoch_loss=-.678]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.444 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.677915\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.45it/s, epoch=2/20, avg_epoch_loss=-1.85]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.749 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.846099\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.40it/s, epoch=3/20, avg_epoch_loss=-2.53]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.818 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.529272\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=4/20, avg_epoch_loss=-2.86]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 7.862 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.863969\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.40it/s, epoch=5/20, avg_epoch_loss=-3.05]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.818 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-3.046826\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=6/20, avg_epoch_loss=-2.45]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 7.857 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.452269\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=7/20, avg_epoch_loss=-3.18]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.858 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.182882\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=8/20, avg_epoch_loss=-2.93]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.889 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.931948\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.35it/s, epoch=9/20, avg_epoch_loss=-3.22]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.881 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.224955\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=10/20, avg_epoch_loss=-3.06]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.921 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.060428\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=11/20, avg_epoch_loss=-2.71]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.935 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.705178\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.98it/s, epoch=12/20, avg_epoch_loss=-3.05]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.371 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.053518\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.95it/s, epoch=13/20, avg_epoch_loss=-3.13]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.408 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.133956\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.13it/s, epoch=14/20, avg_epoch_loss=-3.45]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.165 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.452932\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=15/20, avg_epoch_loss=-3.51]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.033 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.511949\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=16/20, avg_epoch_loss=-3.32]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.797 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.324266\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.43it/s, epoch=17/20, avg_epoch_loss=-2.63]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.776 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.625734\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.35it/s, epoch=18/20, avg_epoch_loss=-3.53]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.881 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.530220\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.16it/s, epoch=19/20, avg_epoch_loss=-3.59]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.123 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.587079\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=20/20, avg_epoch_loss=-3.6]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.938 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.597098\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.00482464]\n",
      " [-1.01269865]\n",
      " [-1.00906193]\n",
      " ...\n",
      " [-0.99367923]\n",
      " [-0.99260694]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2218, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal F-7 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.00978386]\n",
      " [-1.00729299]\n",
      " [-1.00973046]\n",
      " ...\n",
      " [-0.99360824]\n",
      " [-0.99156469]\n",
      " [-0.99580526]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.642857\n",
      "1     1222840800 -0.964286\n",
      "2     1222862400 -0.785714\n",
      "3     1222884000 -0.892857\n",
      "4     1222905600 -0.964286\n",
      "...          ...       ...\n",
      "2506  1276948800 -0.892857\n",
      "2507  1276970400 -0.535714\n",
      "2508  1276992000 -0.785714\n",
      "2509  1277013600 -0.500000\n",
      "2510  1277035200 -0.535714\n",
      "\n",
      "[2511 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1277056800 -0.892857\n",
      "1     1277078400 -0.892857\n",
      "2     1277100000 -0.428571\n",
      "3     1277121600 -0.500000\n",
      "4     1277143200 -0.892857\n",
      "...          ...       ...\n",
      "5049  1386115200  0.964286\n",
      "5050  1386136800 -0.964286\n",
      "5051  1386158400 -0.964286\n",
      "5052  1386180000 -0.964286\n",
      "5053  1386201600 -0.892857\n",
      "\n",
      "[5054 rows x 2 columns]\n",
      "TIMESEGMENT:  (2511, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2511, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.67it/s, epoch=1/20, avg_epoch_loss=0.774]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.826 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.773628\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=2/20, avg_epoch_loss=0.302]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.949 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=0.301515\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=3/20, avg_epoch_loss=0.133]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.847 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=0.132787\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.06it/s, epoch=4/20, avg_epoch_loss=-.00174]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.249 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.001737\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=5/20, avg_epoch_loss=-.063]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.100 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.062973\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.99it/s, epoch=6/20, avg_epoch_loss=-.122]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.355 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-0.121699\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.96it/s, epoch=7/20, avg_epoch_loss=-.175]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.394 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-0.174808\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=8/20, avg_epoch_loss=-.184]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.941 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-0.184047\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=9/20, avg_epoch_loss=-.217]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.792 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-0.216630\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s, epoch=10/20, avg_epoch_loss=-.191]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 8.141 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-0.190816\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.06it/s, epoch=11/20, avg_epoch_loss=-.292]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.256 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-0.291678\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.03it/s, epoch=12/20, avg_epoch_loss=-.308]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.288 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-0.307886\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.18it/s, epoch=13/20, avg_epoch_loss=-.32]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.093 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-0.319734\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=14/20, avg_epoch_loss=-.347]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.119 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-0.347234\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.08it/s, epoch=15/20, avg_epoch_loss=-.367]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.234 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-0.367366\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=16/20, avg_epoch_loss=-.314]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.018 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-0.314472\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=17/20, avg_epoch_loss=-.402]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.945 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-0.402033\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=18/20, avg_epoch_loss=-.372]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.912 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-0.371589\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.22it/s, epoch=19/20, avg_epoch_loss=-.412]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.043 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-0.412344\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.25it/s, epoch=20/20, avg_epoch_loss=-.462]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.997 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-0.461842\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.64285714]\n",
      " [-0.96428571]\n",
      " [-0.78571429]\n",
      " ...\n",
      " [-0.78571429]\n",
      " [-0.5       ]\n",
      " [-0.53571429]]\n",
      "Y_HAT:  [[-0.69331908]\n",
      " [-0.75153464]\n",
      " [-0.8870616 ]\n",
      " ...\n",
      " [-0.85028076]\n",
      " [-0.88863784]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (5054, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.89285714]\n",
      " [-0.89285714]\n",
      " [-0.42857143]\n",
      " ...\n",
      " [-0.96428571]\n",
      " [-0.96428571]\n",
      " [-0.89285714]]\n",
      "Y_HAT:  [[-0.72075254]\n",
      " [-0.86741102]\n",
      " [-0.87792104]\n",
      " ...\n",
      " [-0.91991442]\n",
      " [-0.99080575]\n",
      " [-0.97030503]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-3 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp     value\n",
      "0     1222819200  1.000046\n",
      "1     1222840800  1.000046\n",
      "2     1222862400  1.000046\n",
      "3     1222884000  1.000046\n",
      "4     1222905600  1.000046\n",
      "...          ...       ...\n",
      "2032  1266710400  1.000052\n",
      "2033  1266732000  1.000052\n",
      "2034  1266753600  1.000052\n",
      "2035  1266775200  1.000052\n",
      "2036  1266796800  1.000052\n",
      "\n",
      "[2037 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1266818400  1.000000\n",
      "1     1266840000  1.000000\n",
      "2     1266861600  1.000000\n",
      "3     1266883200  1.000000\n",
      "4     1266904800  1.000000\n",
      "...          ...       ...\n",
      "2122  1312653600  1.000049\n",
      "2123  1312675200  1.000049\n",
      "2124  1312696800  1.000049\n",
      "2125  1312718400  1.000049\n",
      "2126  1312740000  1.000049\n",
      "\n",
      "[2127 rows x 2 columns]\n",
      "TIMESEGMENT:  (2037, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2037, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.63it/s, epoch=1/20, avg_epoch_loss=0.419]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.876 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.418700\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.43it/s, epoch=2/20, avg_epoch_loss=-.62]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.787 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.619951\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=3/20, avg_epoch_loss=-.908]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.804 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.907780\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=4/20, avg_epoch_loss=-.82]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 7.810 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.819767\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=5/20, avg_epoch_loss=-.914]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.805 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.913623\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=6/20, avg_epoch_loss=-1.03]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 7.856 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.031849\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s, epoch=7/20, avg_epoch_loss=-1.19]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.020 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.190469\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=8/20, avg_epoch_loss=-1.34]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.804 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.336158\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=9/20, avg_epoch_loss=-1.37]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.862 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.370934\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=10/20, avg_epoch_loss=-1.54]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.828 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.536473\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=11/20, avg_epoch_loss=-1.35]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.865 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.345215\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.46it/s, epoch=12/20, avg_epoch_loss=-1.56]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.753 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.556649\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=13/20, avg_epoch_loss=-1.64]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 7.861 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.635394\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s, epoch=14/20, avg_epoch_loss=-1.6]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.014 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.600036\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.38it/s, epoch=15/20, avg_epoch_loss=-1.61]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 7.841 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.610696\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=16/20, avg_epoch_loss=-1.66]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.936 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.661792\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=17/20, avg_epoch_loss=-1.65]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.826 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.650312\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.38it/s, epoch=18/20, avg_epoch_loss=-1.62]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.842 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.619508\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=19/20, avg_epoch_loss=-1.7]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.873 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.697930\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=20/20, avg_epoch_loss=-1.8]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.826 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.801256\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[1.00004615]\n",
      " [1.00004615]\n",
      " [1.00004615]\n",
      " ...\n",
      " [1.0000523 ]\n",
      " [1.0000523 ]\n",
      " [1.0000523 ]]\n",
      "Y_HAT:  [[0.3338086 ]\n",
      " [0.69458127]\n",
      " [0.89027756]\n",
      " ...\n",
      " [0.98129988]\n",
      " [0.97797889]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (2127, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-4 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " ...\n",
      " [1.00004922]\n",
      " [1.00004922]\n",
      " [1.00004922]]\n",
      "Y_HAT:  [[0.59216022]\n",
      " [0.80952001]\n",
      " [0.95668894]\n",
      " ...\n",
      " [0.90939325]\n",
      " [0.89984053]\n",
      " [0.90962863]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  1.000000\n",
      "1     1222840800  1.000000\n",
      "2     1222862400  1.000000\n",
      "3     1222884000  1.000000\n",
      "4     1222905600  1.000000\n",
      "...          ...       ...\n",
      "2071  1267552800  0.999973\n",
      "2072  1267574400  0.999973\n",
      "2073  1267596000  0.999973\n",
      "2074  1267617600  0.999973\n",
      "2075  1267639200  0.999973\n",
      "\n",
      "[2076 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1267660800  1.000005\n",
      "1     1267682400  1.000005\n",
      "2     1267704000  1.000005\n",
      "3     1267725600  1.000005\n",
      "4     1267747200  1.000005\n",
      "...          ...       ...\n",
      "2033  1311573600  0.999995\n",
      "2034  1311595200  0.999995\n",
      "2035  1311616800  0.999995\n",
      "2036  1311638400  0.999995\n",
      "2037  1311660000  0.999995\n",
      "\n",
      "[2038 rows x 2 columns]\n",
      "TIMESEGMENT:  (2076, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2076, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.69it/s, epoch=1/20, avg_epoch_loss=0.22]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.787 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.219754\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=2/20, avg_epoch_loss=-.528]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.900 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.527747\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=3/20, avg_epoch_loss=-.859]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.800 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.858960\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s, epoch=4/20, avg_epoch_loss=-.953]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.233 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.952946\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s, epoch=5/20, avg_epoch_loss=-1.27]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.150 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.272952\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.18it/s, epoch=6/20, avg_epoch_loss=-1.11]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.090 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.114524\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.35it/s, epoch=7/20, avg_epoch_loss=-1.38]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.881 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.378274\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=8/20, avg_epoch_loss=-1.24]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.874 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.244440\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.43it/s, epoch=9/20, avg_epoch_loss=-1.18]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.784 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.183879\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=10/20, avg_epoch_loss=-1.38]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.892 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.382051\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=11/20, avg_epoch_loss=-1.47]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.111 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.465225\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=12/20, avg_epoch_loss=-1.42]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.846 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.416965\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.29it/s, epoch=13/20, avg_epoch_loss=-1.44]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 7.945 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.439353\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=14/20, avg_epoch_loss=-1.66]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.005 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.664679\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s, epoch=15/20, avg_epoch_loss=-1.22]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.177 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.219479\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.04it/s, epoch=16/20, avg_epoch_loss=-1.53]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.277 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.525431\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s, epoch=17/20, avg_epoch_loss=-1.72]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.149 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.716035\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.08it/s, epoch=18/20, avg_epoch_loss=-1.66]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.232 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.659941\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s, epoch=19/20, avg_epoch_loss=-1.61]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.149 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.607452\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=20/20, avg_epoch_loss=-1.74]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.031 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.739244\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[1.        ]\n",
      " [1.        ]\n",
      " [1.        ]\n",
      " ...\n",
      " [0.99997263]\n",
      " [0.99997263]\n",
      " [0.99997263]]\n",
      "Y_HAT:  [[0.76010239]\n",
      " [0.72749275]\n",
      " [0.89020449]\n",
      " ...\n",
      " [0.97907525]\n",
      " [0.98639113]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (2038, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-5 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[1.00000547]\n",
      " [1.00000547]\n",
      " [1.00000547]\n",
      " ...\n",
      " [0.99999453]\n",
      " [0.99999453]\n",
      " [0.99999453]]\n",
      "Y_HAT:  [[0.83549666]\n",
      " [0.84678131]\n",
      " [0.93742979]\n",
      " ...\n",
      " [0.77249169]\n",
      " [0.75801802]\n",
      " [0.77090776]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.566415\n",
      "1     1222840800  0.280476\n",
      "2     1222862400 -1.225864\n",
      "3     1222884000 -0.418766\n",
      "4     1222905600  0.714043\n",
      "...          ...       ...\n",
      "2027  1266602400 -1.000000\n",
      "2028  1266624000 -1.000000\n",
      "2029  1266645600 -1.000000\n",
      "2030  1266667200 -1.000000\n",
      "2031  1266688800 -1.000000\n",
      "\n",
      "[2032 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1266710400   -1.0\n",
      "1     1266732000   -1.0\n",
      "2     1266753600   -1.0\n",
      "3     1266775200   -1.0\n",
      "4     1266796800   -1.0\n",
      "...          ...    ...\n",
      "2298  1316347200   -1.0\n",
      "2299  1316368800   -1.0\n",
      "2300  1316390400   -1.0\n",
      "2301  1316412000   -1.0\n",
      "2302  1316433600   -1.0\n",
      "\n",
      "[2303 rows x 2 columns]\n",
      "TIMESEGMENT:  (2032, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2032, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.81it/s, epoch=1/20, avg_epoch_loss=0.516]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.601 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.515963\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=2/20, avg_epoch_loss=-.146]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.942 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.145847\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=3/20, avg_epoch_loss=-.324]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.940 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.323929\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.09it/s, epoch=4/20, avg_epoch_loss=-.424]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.211 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.424279\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=5/20, avg_epoch_loss=-.612]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.937 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.611803\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=6/20, avg_epoch_loss=-.655]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 7.829 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-0.654700\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.35it/s, epoch=7/20, avg_epoch_loss=-.857]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.874 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-0.857460\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.06it/s, epoch=8/20, avg_epoch_loss=-.851]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.260 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-0.851395\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=9/20, avg_epoch_loss=-.895]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 8.053 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-0.895260\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=10/20, avg_epoch_loss=-.809]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 8.104 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-0.808761\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s, epoch=11/20, avg_epoch_loss=-1.07]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.240 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.074641\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.27it/s, epoch=12/20, avg_epoch_loss=-1.08]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.971 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.076536\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.05it/s, epoch=13/20, avg_epoch_loss=-1.18]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.283 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.175841\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=14/20, avg_epoch_loss=-1.12]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 7.857 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.124043\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.16it/s, epoch=15/20, avg_epoch_loss=-1.27]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.118 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.265232\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s, epoch=16/20, avg_epoch_loss=-1.2]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.168 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.204532\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=17/20, avg_epoch_loss=-1.17]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.003 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.174687\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=18/20, avg_epoch_loss=-1.26]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.928 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.260502\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=19/20, avg_epoch_loss=-1.32]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.806 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.320577\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.22it/s, epoch=20/20, avg_epoch_loss=-1.23]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.065 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.228035\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 0.56641514]\n",
      " [ 0.28047572]\n",
      " [-1.22586389]\n",
      " ...\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]]\n",
      "Y_HAT:  [[ 0.20414495]\n",
      " [ 0.31224114]\n",
      " [ 0.33605388]\n",
      " ...\n",
      " [-0.91333425]\n",
      " [-0.89544648]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2303, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal P-15 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[ 0.32682297]\n",
      " [ 0.27692309]\n",
      " [-0.0597109 ]\n",
      " ...\n",
      " [-0.38316932]\n",
      " [-0.12323897]\n",
      " [ 0.0129165 ]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.998434\n",
      "1     1222840800  0.997912\n",
      "2     1222862400  1.000522\n",
      "3     1222884000  0.998086\n",
      "4     1222905600  0.998434\n",
      "...          ...       ...\n",
      "3677  1302242400  0.976686\n",
      "3678  1302264000  1.003828\n",
      "3679  1302285600  1.004350\n",
      "3680  1302307200  1.004698\n",
      "3681  1302328800  1.004872\n",
      "\n",
      "[3682 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1302350400  0.957547\n",
      "1     1302372000  0.956851\n",
      "2     1302393600  0.956329\n",
      "3     1302415200  0.944672\n",
      "4     1302436800  0.955285\n",
      "...          ...       ...\n",
      "2851  1363932000 -0.968856\n",
      "2852  1363953600 -0.969900\n",
      "2853  1363975200 -0.969378\n",
      "2854  1363996800 -0.970248\n",
      "2855  1364018400 -0.968160\n",
      "\n",
      "[2856 rows x 2 columns]\n",
      "TIMESEGMENT:  (3682, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(3682, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.61it/s, epoch=1/20, avg_epoch_loss=-.878]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.917 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.878454\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.87it/s, epoch=2/20, avg_epoch_loss=-1.67]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.519 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.673961\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.78it/s, epoch=3/20, avg_epoch_loss=-2.21]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.657 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.213831\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.92it/s, epoch=4/20, avg_epoch_loss=-2.45]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.447 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.450407\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.09it/s, epoch=5/20, avg_epoch_loss=-2.5]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.217 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.500724\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.13it/s, epoch=6/20, avg_epoch_loss=-2.6]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.156 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.604165\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=7/20, avg_epoch_loss=-2.64]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.945 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.640048\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=8/20, avg_epoch_loss=-2.7]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.862 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.698764\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=9/20, avg_epoch_loss=-2.67]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.890 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.670335\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=10/20, avg_epoch_loss=-2.7]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.825 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-2.704165\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.43it/s, epoch=11/20, avg_epoch_loss=-2.72]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.782 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.724869\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=12/20, avg_epoch_loss=-2.76]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.891 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.757020\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s, epoch=13/20, avg_epoch_loss=-2.78]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.242 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.776113\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s, epoch=14/20, avg_epoch_loss=-2.84]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.190 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.842473\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.15it/s, epoch=15/20, avg_epoch_loss=-2.89]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.135 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.891357\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.13it/s, epoch=16/20, avg_epoch_loss=-2.83]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.153 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.826474\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=17/20, avg_epoch_loss=-2.88]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.107 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.882329\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s, epoch=18/20, avg_epoch_loss=-2.97]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.172 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.969053\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.19it/s, epoch=19/20, avg_epoch_loss=-2.93]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.083 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.934912\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s, epoch=20/20, avg_epoch_loss=-2.93]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.142 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.930590\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.9984341 ]\n",
      " [0.99791214]\n",
      " [1.00052197]\n",
      " ...\n",
      " [1.00434972]\n",
      " [1.00469769]\n",
      " [1.00487168]]\n",
      "Y_HAT:  [[0.94421929]\n",
      " [0.99197525]\n",
      " [0.99477798]\n",
      " ...\n",
      " [0.97977084]\n",
      " [0.97736555]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (2856, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 0.95754676]\n",
      " [ 0.9568508 ]\n",
      " [ 0.95632884]\n",
      " ...\n",
      " [-0.96937799]\n",
      " [-0.97024793]\n",
      " [-0.96816007]]\n",
      "Y_HAT:  [[0.98563081]\n",
      " [0.99629819]\n",
      " [0.9997915 ]\n",
      " ...\n",
      " [0.98658884]\n",
      " [0.9837963 ]\n",
      " [0.97472852]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal C-1 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp     value\n",
      "0     1222819200  2.146646\n",
      "1     1222840800  2.146646\n",
      "2     1222862400  2.146646\n",
      "3     1222884000  2.151326\n",
      "4     1222905600  2.163807\n",
      "...          ...       ...\n",
      "2153  1269324000 -0.996880\n",
      "2154  1269345600 -0.998440\n",
      "2155  1269367200 -0.982839\n",
      "2156  1269388800 -0.976599\n",
      "2157  1269410400 -0.976599\n",
      "\n",
      "[2158 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1269432000 -0.946958\n",
      "1     1269453600 -0.942278\n",
      "2     1269475200 -0.936037\n",
      "3     1269496800 -0.923557\n",
      "4     1269518400 -0.917317\n",
      "...          ...       ...\n",
      "2259  1318226400 -0.920437\n",
      "2260  1318248000 -0.920437\n",
      "2261  1318269600 -0.920437\n",
      "2262  1318291200 -0.907956\n",
      "2263  1318312800 -0.904836\n",
      "\n",
      "[2264 rows x 2 columns]\n",
      "TIMESEGMENT:  (2158, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2158, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=1/20, avg_epoch_loss=0.157]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.671 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.156537\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=2/20, avg_epoch_loss=-.934]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.986 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.934219\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.07it/s, epoch=3/20, avg_epoch_loss=-1.35]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.236 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.354999\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.05it/s, epoch=4/20, avg_epoch_loss=-1.55]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.271 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.549707\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.18it/s, epoch=5/20, avg_epoch_loss=-1.64]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.098 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.641422\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=6/20, avg_epoch_loss=-1.84]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.051 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.835645\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=7/20, avg_epoch_loss=-1.89]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.984 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.894984\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=8/20, avg_epoch_loss=-1.88]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.923 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.883456\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=9/20, avg_epoch_loss=-2.02]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.984 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.022367\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.96it/s, epoch=10/20, avg_epoch_loss=-2.04]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 8.387 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-2.042347\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.10it/s, epoch=11/20, avg_epoch_loss=-2.07]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.197 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.074219\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.18it/s, epoch=12/20, avg_epoch_loss=-1.57]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.092 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.574765\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s, epoch=13/20, avg_epoch_loss=-2.1]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.180 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.099390\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.19it/s, epoch=14/20, avg_epoch_loss=-2.18]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.082 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.180540\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.99it/s, epoch=15/20, avg_epoch_loss=-2.23]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.343 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.234108\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.15it/s, epoch=16/20, avg_epoch_loss=-2.05]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.135 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.046249\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=17/20, avg_epoch_loss=-2.2]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.903 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.199121\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=18/20, avg_epoch_loss=-2.38]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.984 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.384634\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.18it/s, epoch=19/20, avg_epoch_loss=-2.42]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.096 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.417348\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=20/20, avg_epoch_loss=-2.4]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.005 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.404435\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 2.14664587]\n",
      " [ 2.14664587]\n",
      " [ 2.14664587]\n",
      " ...\n",
      " [-0.98283931]\n",
      " [-0.97659906]\n",
      " [-0.97659906]]\n",
      "Y_HAT:  [[-0.09493076]\n",
      " [ 1.39824331]\n",
      " [ 1.97094274]\n",
      " ...\n",
      " [-0.97766405]\n",
      " [-0.96887422]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2264, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal C-2 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.94695788]\n",
      " [-0.94227769]\n",
      " [-0.93603744]\n",
      " ...\n",
      " [-0.92043682]\n",
      " [-0.90795632]\n",
      " [-0.90483619]]\n",
      "Y_HAT:  [[ 1.11655116]\n",
      " [ 2.00865364]\n",
      " [ 2.25316715]\n",
      " ...\n",
      " [-0.96168035]\n",
      " [-0.95666564]\n",
      " [-0.95372611]]\n",
      "TRAIN:        timestamp  value\n",
      "0    1222819200   -1.0\n",
      "1    1222840800   -1.0\n",
      "2    1222862400   -1.0\n",
      "3    1222884000   -1.0\n",
      "4    1222905600   -1.0\n",
      "..          ...    ...\n",
      "759  1239213600   -1.0\n",
      "760  1239235200   -1.0\n",
      "761  1239256800   -1.0\n",
      "762  1239278400   -1.0\n",
      "763  1239300000   -1.0\n",
      "\n",
      "[764 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1239321600   -1.0\n",
      "1     1239343200   -1.0\n",
      "2     1239364800   -1.0\n",
      "3     1239386400   -1.0\n",
      "4     1239408000   -1.0\n",
      "...          ...    ...\n",
      "2046  1283515200   -1.0\n",
      "2047  1283536800   -1.0\n",
      "2048  1283558400   -1.0\n",
      "2049  1283580000   -1.0\n",
      "2050  1283601600   -1.0\n",
      "\n",
      "[2051 rows x 2 columns]\n",
      "TIMESEGMENT:  (764, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(764, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.87it/s, epoch=1/20, avg_epoch_loss=-.27]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.521 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.269525\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=2/20, avg_epoch_loss=-2.51]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.788 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.507115\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s, epoch=3/20, avg_epoch_loss=-2.97]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.186 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.973169\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.93it/s, epoch=4/20, avg_epoch_loss=-3.06]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.433 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-3.055224\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=5/20, avg_epoch_loss=-3.27]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.057 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-3.267030\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s, epoch=6/20, avg_epoch_loss=-3.29]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.012 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-3.291734\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.02it/s, epoch=7/20, avg_epoch_loss=-3.4]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.312 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.395176\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=8/20, avg_epoch_loss=-3.47]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.105 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-3.466545\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.16it/s, epoch=9/20, avg_epoch_loss=-3.51]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 8.117 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.514748\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=10/20, avg_epoch_loss=-3.56]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.856 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.562082\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=11/20, avg_epoch_loss=-3.64]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.787 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.637147\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=12/20, avg_epoch_loss=-3.64]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.851 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.640359\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.15it/s, epoch=13/20, avg_epoch_loss=-3.59]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.129 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.593733\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.22it/s, epoch=14/20, avg_epoch_loss=-3.68]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.039 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.682876\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=15/20, avg_epoch_loss=-3.73]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 7.993 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.725649\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.43it/s, epoch=16/20, avg_epoch_loss=-3.75]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.783 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.751352\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.38it/s, epoch=17/20, avg_epoch_loss=-3.78]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.844 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.776550\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=18/20, avg_epoch_loss=-3.77]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.869 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.773745\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=19/20, avg_epoch_loss=-3.83]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.884 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.832433\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.38it/s, epoch=20/20, avg_epoch_loss=-3.82]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.845 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.821086\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-0.96038812]\n",
      " [-1.00435138]\n",
      " [-0.98673064]\n",
      " [-0.98866755]\n",
      " [-0.97188777]\n",
      " [-0.98690683]\n",
      " [-0.98571986]\n",
      " [-0.98594618]\n",
      " [-0.98865044]\n",
      " [-0.98885399]\n",
      " [-0.98803025]\n",
      " [-0.98913813]\n",
      " [-0.98969531]\n",
      " [-0.98967719]\n",
      " [-0.99227911]\n",
      " [-0.99191231]\n",
      " [-0.99169612]\n",
      " [-0.99099213]\n",
      " [-0.99172229]\n",
      " [-0.99329489]\n",
      " [-0.99187928]\n",
      " [-0.99075884]\n",
      " [-0.9931531 ]\n",
      " [-0.98612791]\n",
      " [-0.99278688]\n",
      " [-0.98968351]\n",
      " [-0.99260688]\n",
      " [-0.99026942]\n",
      " [-0.99217176]\n",
      " [-0.99032539]\n",
      " [-0.99143863]\n",
      " [-0.99013674]\n",
      " [-0.99155205]\n",
      " [-0.99080276]\n",
      " [-0.99141765]\n",
      " [-0.99205261]\n",
      " [-0.99229026]\n",
      " [-0.99284005]\n",
      " [-0.99228531]\n",
      " [-0.99277353]\n",
      " [-0.99407768]\n",
      " [-0.99188071]\n",
      " [-0.99224138]\n",
      " [-0.99211222]\n",
      " [-0.99211639]\n",
      " [-0.99337751]\n",
      " [-0.99382752]\n",
      " [-0.99317795]\n",
      " [-0.99038154]\n",
      " [-0.99403566]\n",
      " [-0.99351972]\n",
      " [-0.99312001]\n",
      " [-0.99145019]\n",
      " [-0.99067706]\n",
      " [-0.99066877]\n",
      " [-0.99157262]\n",
      " [-0.99094605]\n",
      " [-0.99051112]\n",
      " [-0.99017924]\n",
      " [-0.99057025]\n",
      " [-0.99133372]\n",
      " [-0.99128115]\n",
      " [-0.99030656]\n",
      " [-0.99103898]\n",
      " [-0.99249786]\n",
      " [-0.99197054]\n",
      " [-0.99208701]\n",
      " [-0.99170148]\n",
      " [-0.99200636]\n",
      " [-0.99178386]\n",
      " [-0.99098104]\n",
      " [-0.99011594]\n",
      " [-0.99663401]\n",
      " [-0.99418741]\n",
      " [-0.99020332]\n",
      " [-0.98984617]\n",
      " [-0.99093223]\n",
      " [-0.99092859]\n",
      " [-0.99063498]\n",
      " [-0.99189097]\n",
      " [-0.99177831]\n",
      " [-0.99121422]\n",
      " [-0.99195755]\n",
      " [-0.9917118 ]\n",
      " [-0.99278235]\n",
      " [-0.99253166]\n",
      " [-0.9929136 ]\n",
      " [-0.99228865]\n",
      " [-0.99194396]\n",
      " [-0.99232775]\n",
      " [-0.99320197]\n",
      " [-0.99330676]\n",
      " [-0.99404711]\n",
      " [-0.99404573]\n",
      " [-0.99287015]\n",
      " [-0.99204338]\n",
      " [-0.98414886]\n",
      " [-0.99180412]\n",
      " [-0.99374253]\n",
      " [-0.99485916]\n",
      " [-0.99336261]\n",
      " [-0.99312037]\n",
      " [-0.9932043 ]\n",
      " [-0.99240339]\n",
      " [-0.99162275]\n",
      " [-0.99283981]\n",
      " [-0.99173111]\n",
      " [-0.99300283]\n",
      " [-0.9928723 ]\n",
      " [-0.98996025]\n",
      " [-0.99163878]\n",
      " [-0.9909637 ]\n",
      " [-0.99128366]\n",
      " [-0.99167258]\n",
      " [-0.99128592]\n",
      " [-0.991072  ]\n",
      " [-0.98939103]\n",
      " [-0.99019212]\n",
      " [-0.98947251]\n",
      " [-1.01195884]\n",
      " [-0.98754388]\n",
      " [-0.99319428]\n",
      " [-0.99004716]\n",
      " [-0.99059141]\n",
      " [-0.99046594]\n",
      " [-0.99129224]\n",
      " [-0.9925946 ]\n",
      " [-0.99182093]\n",
      " [-0.99245042]\n",
      " [-0.99364471]\n",
      " [-0.99369943]\n",
      " [-0.9943254 ]\n",
      " [-0.99313527]\n",
      " [-0.99345118]\n",
      " [-0.99321645]\n",
      " [-0.99229169]\n",
      " [-0.99086374]\n",
      " [-0.99049348]\n",
      " [-0.99197549]\n",
      " [-0.99136895]\n",
      " [-0.9895286 ]\n",
      " [-0.99021703]\n",
      " [-0.99000359]\n",
      " [-0.99854314]\n",
      " [-0.99643654]\n",
      " [-0.99268413]\n",
      " [-0.99185377]\n",
      " [-0.99201012]\n",
      " [-0.99081618]\n",
      " [-0.99034148]\n",
      " [-0.9915626 ]\n",
      " [-0.99092942]\n",
      " [-0.99083519]\n",
      " [-0.99041915]\n",
      " [-0.99098974]\n",
      " [-0.99258202]\n",
      " [-0.99225366]\n",
      " [-0.99033087]\n",
      " [-0.99166733]\n",
      " [-0.99184942]\n",
      " [-0.99234873]\n",
      " [-0.99202418]\n",
      " [-0.99200624]\n",
      " [-0.99274409]\n",
      " [-0.99258012]\n",
      " [-0.99171835]\n",
      " [-0.99163026]\n",
      " [-0.99323386]\n",
      " [-0.98870951]\n",
      " [-0.99205744]\n",
      " [-0.99443984]\n",
      " [-0.99357665]\n",
      " [-0.99245787]\n",
      " [-0.99199384]\n",
      " [-0.99224013]\n",
      " [-0.9920578 ]\n",
      " [-0.99115503]\n",
      " [-0.99265939]\n",
      " [-0.99095637]\n",
      " [-0.99214369]\n",
      " [-0.9922635 ]\n",
      " [-0.99255013]\n",
      " [-0.992652  ]\n",
      " [-0.99219596]\n",
      " [-0.99277222]\n",
      " [-0.99224937]\n",
      " [-0.99115962]\n",
      " [-0.99324447]\n",
      " [-0.99206907]\n",
      " [-0.9914853 ]\n",
      " [-0.99200088]\n",
      " [-0.99277395]\n",
      " [-0.99335855]\n",
      " [-0.99217337]\n",
      " [-0.99251199]\n",
      " [-0.99287689]\n",
      " [-0.99196541]\n",
      " [-0.99303186]\n",
      " [-0.99130553]\n",
      " [-0.99217445]\n",
      " [-0.99128783]\n",
      " [-0.99300814]\n",
      " [-0.99296385]\n",
      " [-0.99317396]\n",
      " [-0.99277949]\n",
      " [-0.99217474]\n",
      " [-0.99274302]\n",
      " [-0.99317205]\n",
      " [-0.99229032]\n",
      " [-0.99272573]\n",
      " [-0.99179959]\n",
      " [-0.9922331 ]\n",
      " [-0.99274665]\n",
      " [-0.99431348]\n",
      " [-0.99373513]\n",
      " [-0.99288964]\n",
      " [-0.99303144]\n",
      " [-0.99403405]\n",
      " [-0.99353874]\n",
      " [-0.99353004]\n",
      " [-0.9927637 ]\n",
      " [-0.99435306]\n",
      " [-0.99224466]\n",
      " [-0.99258649]\n",
      " [-0.99267298]\n",
      " [-0.99279344]\n",
      " [-0.99319059]\n",
      " [-0.99252403]\n",
      " [-0.99328727]\n",
      " [-0.99209869]\n",
      " [-0.99351954]\n",
      " [-0.99313074]\n",
      " [-0.99314904]\n",
      " [-0.99322355]\n",
      " [-0.99329519]\n",
      " [-0.993563  ]\n",
      " [-0.99296916]\n",
      " [-0.99308133]\n",
      " [-0.99283999]\n",
      " [-0.99366945]\n",
      " [-0.99258256]\n",
      " [-0.99255621]\n",
      " [-0.99354637]\n",
      " [-0.99275804]\n",
      " [-0.99318469]\n",
      " [-0.99299318]\n",
      " [-0.99191904]\n",
      " [-0.99254358]\n",
      " [-0.99388701]\n",
      " [-0.99252075]\n",
      " [-0.99290937]\n",
      " [-0.99327993]\n",
      " [-0.99293953]\n",
      " [-0.99406374]\n",
      " [-0.99266934]\n",
      " [-0.99327463]\n",
      " [-0.99329901]\n",
      " [-0.99442065]\n",
      " [-0.99289477]\n",
      " [-0.99263984]\n",
      " [-0.99260068]\n",
      " [-0.99317545]\n",
      " [-0.99445969]\n",
      " [-0.99204046]\n",
      " [-0.99342155]\n",
      " [-0.99202424]\n",
      " [-0.99338931]\n",
      " [-0.99397993]\n",
      " [-0.99329674]\n",
      " [-0.99260908]\n",
      " [-0.99343407]\n",
      " [-0.99297786]\n",
      " [-0.99168557]\n",
      " [-0.99267411]\n",
      " [-0.99294418]\n",
      " [-0.99324274]\n",
      " [-0.99309534]\n",
      " [-0.99266207]\n",
      " [-0.99303597]\n",
      " [-0.99364573]\n",
      " [-0.99373245]\n",
      " [-0.99371165]\n",
      " [-0.99260092]\n",
      " [-0.99333519]\n",
      " [-0.99182343]\n",
      " [-0.99271065]\n",
      " [-0.99401689]\n",
      " [-0.99324518]\n",
      " [-0.99347991]\n",
      " [-0.99074274]\n",
      " [-0.99279004]\n",
      " [-0.99226737]\n",
      " [-0.9917469 ]\n",
      " [-0.99240351]\n",
      " [-0.99413252]\n",
      " [-0.99282998]\n",
      " [-0.99393362]\n",
      " [-0.99228078]\n",
      " [-0.99347341]\n",
      " [-0.99407858]\n",
      " [-0.99288261]\n",
      " [-0.99287188]\n",
      " [-0.99283075]\n",
      " [-0.99313241]\n",
      " [-0.99333274]\n",
      " [-0.99383909]\n",
      " [-0.99319476]\n",
      " [-0.99242407]\n",
      " [-0.99252051]\n",
      " [-0.99369168]\n",
      " [-0.99344724]\n",
      " [-0.99298292]\n",
      " [-0.99311101]\n",
      " [-0.99290049]\n",
      " [-0.99413717]\n",
      " [-0.99328309]\n",
      " [-0.99451602]\n",
      " [-0.99303359]\n",
      " [-0.99337035]\n",
      " [-0.99322337]\n",
      " [-0.99332976]\n",
      " [-0.99355769]\n",
      " [-0.99408942]\n",
      " [-0.99228317]\n",
      " [-0.99266273]\n",
      " [-0.99377489]\n",
      " [-0.99299967]\n",
      " [-0.99250215]\n",
      " [-0.99334192]\n",
      " [-0.99339622]\n",
      " [-0.99296403]\n",
      " [-0.99298203]\n",
      " [-0.99400717]\n",
      " [-0.99359149]\n",
      " [-0.99350166]\n",
      " [-0.99732757]\n",
      " [-0.99468321]\n",
      " [-0.98898542]\n",
      " [-0.99186116]\n",
      " [-0.99499184]\n",
      " [-0.99484777]\n",
      " [-0.99468076]\n",
      " [-0.99400175]\n",
      " [-0.99426538]\n",
      " [-0.99502474]\n",
      " [-0.99294657]\n",
      " [-0.99299192]\n",
      " [-0.99344361]\n",
      " [-0.99422121]\n",
      " [-0.99451101]\n",
      " [-0.99375391]\n",
      " [-0.99451941]\n",
      " [-0.99374342]\n",
      " [-0.99381858]\n",
      " [-0.99254262]\n",
      " [-0.99263245]\n",
      " [-0.99379486]\n",
      " [-0.99415916]\n",
      " [-0.99395478]\n",
      " [-0.99343246]\n",
      " [-0.99532199]\n",
      " [-0.99398702]\n",
      " [-0.99407083]\n",
      " [-0.99231368]\n",
      " [-0.99322367]\n",
      " [-0.99443984]\n",
      " [-0.9951387 ]\n",
      " [-0.99482858]\n",
      " [-0.99368471]\n",
      " [-0.99343139]\n",
      " [-0.99501687]\n",
      " [-0.99302185]\n",
      " [-0.99316752]\n",
      " [-0.993972  ]\n",
      " [-0.99357218]\n",
      " [-0.99302566]\n",
      " [-0.99359483]\n",
      " [-0.99486113]\n",
      " [-0.99256057]\n",
      " [-0.99365133]\n",
      " [-0.99412596]\n",
      " [-0.99347514]\n",
      " [-0.99368471]\n",
      " [-0.99297625]\n",
      " [-0.99422592]\n",
      " [-0.99207979]\n",
      " [-0.99334478]\n",
      " [-0.99379545]\n",
      " [-0.99360466]\n",
      " [-0.9930855 ]\n",
      " [-0.99253964]\n",
      " [-0.99313414]\n",
      " [-0.99421483]\n",
      " [-0.99425918]\n",
      " [-0.99453574]\n",
      " [-0.99355799]\n",
      " [-0.99411768]\n",
      " [-0.99419647]\n",
      " [-0.99322838]\n",
      " [-0.99298149]\n",
      " [-0.99528241]\n",
      " [-0.99352735]\n",
      " [-0.99510527]\n",
      " [-0.99374902]\n",
      " [-0.99511266]\n",
      " [-0.99455184]\n",
      " [-0.99339598]\n",
      " [-0.9940964 ]\n",
      " [-0.99375558]\n",
      " [-0.99284041]\n",
      " [-0.99295568]\n",
      " [-0.99408829]\n",
      " [-0.99321055]\n",
      " [-0.99237525]\n",
      " [-0.99221349]\n",
      " [-0.99324793]\n",
      " [-0.99265856]\n",
      " [-0.99442118]\n",
      " [-0.99202394]\n",
      " [-0.99325591]\n",
      " [-0.99362528]\n",
      " [-0.99347556]\n",
      " [-0.99328184]\n",
      " [-0.99245924]\n",
      " [-0.99228036]\n",
      " [-0.9923737 ]\n",
      " [-0.99453491]\n",
      " [-0.99257421]\n",
      " [-0.99404287]\n",
      " [-0.9928329 ]\n",
      " [-0.99203867]\n",
      " [-0.99290323]\n",
      " [-0.992769  ]\n",
      " [-0.99179131]\n",
      " [-0.99168998]\n",
      " [-0.99184173]\n",
      " [-0.99440885]\n",
      " [-0.99234933]\n",
      " [-0.99285287]\n",
      " [-0.99365103]\n",
      " [-0.99273318]\n",
      " [-0.99234879]\n",
      " [-0.99316877]\n",
      " [-0.99336576]\n",
      " [-0.99291098]\n",
      " [-0.99292356]\n",
      " [-0.99255759]\n",
      " [-0.9942863 ]\n",
      " [-0.99315453]\n",
      " [-0.99228334]\n",
      " [-0.99237061]\n",
      " [-0.99305427]\n",
      " [-0.99298024]\n",
      " [-0.99265379]\n",
      " [-0.9937923 ]\n",
      " [-0.99191201]\n",
      " [-0.99167359]\n",
      " [-0.99113536]\n",
      " [-0.99308443]\n",
      " [-0.99225008]\n",
      " [-0.99259794]\n",
      " [-0.99303812]\n",
      " [-0.99302542]\n",
      " [-0.99377078]\n",
      " [-0.99183351]\n",
      " [-0.99360007]\n",
      " [-0.99383062]\n",
      " [-0.99220741]\n",
      " [-0.99301046]\n",
      " [-0.99374551]\n",
      " [-0.9947874 ]\n",
      " [-0.99251395]\n",
      " [-0.99378496]\n",
      " [-0.99365973]\n",
      " [-0.99329352]\n",
      " [-0.99342692]\n",
      " [-0.9933489 ]\n",
      " [-0.99261045]\n",
      " [-0.992329  ]\n",
      " [-0.99289727]\n",
      " [-0.99229354]\n",
      " [-0.99199957]\n",
      " [-0.992338  ]\n",
      " [-0.99286789]\n",
      " [-0.99203759]\n",
      " [-0.99310827]\n",
      " [-0.99238914]\n",
      " [-0.99265569]\n",
      " [-0.99256593]\n",
      " [-0.99339217]\n",
      " [-0.99219871]\n",
      " [-0.99228132]\n",
      " [-0.9933275 ]\n",
      " [-0.99306178]\n",
      " [-0.99280965]\n",
      " [-0.99266589]\n",
      " [-0.992544  ]\n",
      " [-0.9920578 ]\n",
      " [-0.99263579]\n",
      " [-0.99231946]\n",
      " [-0.9920693 ]\n",
      " [-0.99080819]\n",
      " [-0.99159682]\n",
      " [-0.99188185]\n",
      " [-0.9986915 ]\n",
      " [-0.9920252 ]\n",
      " [-0.99312681]\n",
      " [-0.99402893]\n",
      " [-0.99347955]\n",
      " [-0.99366403]\n",
      " [-0.99317366]\n",
      " [-0.992661  ]\n",
      " [-0.99286431]\n",
      " [-0.99364877]\n",
      " [-0.99312645]\n",
      " [-0.9928984 ]\n",
      " [-0.9934178 ]\n",
      " [-0.99327064]\n",
      " [-0.99334359]\n",
      " [-0.99240601]\n",
      " [-0.99321061]\n",
      " [-0.99306536]\n",
      " [-0.99321425]\n",
      " [-0.99321616]\n",
      " [-0.99332613]\n",
      " [-0.99339211]\n",
      " [-0.99408585]\n",
      " [-0.99392396]\n",
      " [-0.99515986]\n",
      " [-0.99374282]\n",
      " [-0.9939785 ]\n",
      " [-0.9935267 ]\n",
      " [-0.99342108]\n",
      " [-0.99274337]\n",
      " [-0.9932003 ]\n",
      " [-0.9933275 ]\n",
      " [-0.99360853]\n",
      " [-0.99301153]\n",
      " [-0.99302721]\n",
      " [-0.99256116]\n",
      " [-0.99273843]\n",
      " [-0.99368787]\n",
      " [-0.99322295]\n",
      " [-0.99400175]\n",
      " [-0.99488145]\n",
      " [-0.99382454]\n",
      " [-0.99257439]\n",
      " [-0.99214929]\n",
      " [-0.99401617]\n",
      " [-0.99264228]\n",
      " [-0.9939096 ]\n",
      " [-0.9951973 ]\n",
      " [-0.99649698]\n",
      " [-0.9942649 ]\n",
      " [-0.99286222]\n",
      " [-0.99341071]\n",
      " [-0.99351782]\n",
      " [-0.99316376]\n",
      " [-0.99392676]\n",
      " [-0.99344015]\n",
      " [-0.9939332 ]\n",
      " [-0.99295014]\n",
      " [-0.99384034]\n",
      " [-0.99439245]\n",
      " [-0.99260992]\n",
      " [-0.9939009 ]\n",
      " [-0.99441713]\n",
      " [-0.99333173]\n",
      " [-0.99377501]\n",
      " [-0.9937191 ]\n",
      " [-0.99460775]\n",
      " [-0.99385118]\n",
      " [-0.99292207]\n",
      " [-0.99321246]\n",
      " [-0.99538171]\n",
      " [-0.99354959]\n",
      " [-0.99483037]\n",
      " [-0.99374199]\n",
      " [-0.99438632]\n",
      " [-0.99352753]\n",
      " [-0.99319887]\n",
      " [-0.99358213]\n",
      " [-0.99316388]\n",
      " [-0.99281365]\n",
      " [-0.994385  ]\n",
      " [-0.99416375]\n",
      " [-0.99454516]\n",
      " [-0.99333137]\n",
      " [-0.99434549]\n",
      " [-0.99390543]\n",
      " [-0.99496084]\n",
      " [-0.99415934]\n",
      " [-0.99399954]\n",
      " [-0.99245834]\n",
      " [-0.99319959]\n",
      " [-0.99322337]\n",
      " [-0.99393862]\n",
      " [-0.99363798]\n",
      " [-0.99452406]\n",
      " [-0.99529618]\n",
      " [-0.99384338]\n",
      " [-0.99305427]\n",
      " [-0.99425292]\n",
      " [-0.99351311]\n",
      " [-0.99420983]\n",
      " [-0.99349242]\n",
      " [-0.99429488]\n",
      " [-0.99425769]\n",
      " [-0.99315286]\n",
      " [-0.99384058]\n",
      " [-0.99362493]\n",
      " [-0.99376893]\n",
      " [-0.99385613]\n",
      " [-0.99374831]\n",
      " [-0.99422312]\n",
      " [-0.9939934 ]\n",
      " [-0.99367356]\n",
      " [-0.99446875]\n",
      " [-0.99399215]\n",
      " [-0.99301046]\n",
      " [-0.9951992 ]\n",
      " [-0.99413091]\n",
      " [-0.99400759]\n",
      " [-0.99455047]\n",
      " [-0.99427867]\n",
      " [-0.9935382 ]\n",
      " [-0.9937892 ]\n",
      " [-0.9941448 ]\n",
      " [-0.99294263]\n",
      " [-0.99224991]\n",
      " [-0.99274063]\n",
      " [-0.99311334]\n",
      " [-0.99319381]\n",
      " [-0.99420762]\n",
      " [-0.99288988]\n",
      " [-0.99481553]\n",
      " [-0.99310219]\n",
      " [-0.99322754]\n",
      " [-0.99462259]\n",
      " [-0.99438286]\n",
      " [-0.99398595]\n",
      " [-0.99290878]\n",
      " [-0.99438649]\n",
      " [-0.99426514]\n",
      " [-0.99451309]\n",
      " [-0.99407935]\n",
      " [-0.99364221]\n",
      " [-0.99356163]\n",
      " [-0.99213082]\n",
      " [-0.99295151]\n",
      " [-0.99396044]\n",
      " [-0.99357063]\n",
      " [-0.99366957]\n",
      " [-0.9933551 ]\n",
      " [-0.99367422]\n",
      " [-0.99272573]\n",
      " [-0.99218804]\n",
      " [-0.993119  ]\n",
      " [-0.99358499]\n",
      " [-0.99337161]\n",
      " [-0.99322683]\n",
      " [-0.9935376 ]\n",
      " [-0.99292147]\n",
      " [-0.99384832]\n",
      " [-0.99340159]\n",
      " [-0.99354744]\n",
      " [-0.99403131]\n",
      " [-0.99363434]\n",
      " [-0.99370247]\n",
      " [-0.99350113]\n",
      " [-0.9944756 ]\n",
      " [-0.99594527]\n",
      " [-0.99305516]\n",
      " [-0.9945752 ]\n",
      " [-0.99266279]\n",
      " [-0.99388266]\n",
      " [-0.99451196]\n",
      " [-0.99362487]\n",
      " [-0.99325317]\n",
      " [-0.99330872]\n",
      " [-0.99393743]\n",
      " [-0.99229956]\n",
      " [-0.99313527]\n",
      " [-0.99346507]\n",
      " [-0.99442232]\n",
      " [-0.99306351]\n",
      " [-0.99235964]\n",
      " [-0.99207377]\n",
      " [-0.9935289 ]\n",
      " [-0.99346805]\n",
      " [-0.99282598]\n",
      " [-0.99229944]\n",
      " [-0.99148887]\n",
      " [-0.99291253]\n",
      " [-0.99199837]\n",
      " [-0.99285895]\n",
      " [-0.99406362]\n",
      " [-0.9946478 ]\n",
      " [-0.99449521]\n",
      " [-0.99400735]\n",
      " [-0.99431574]\n",
      " [-0.9933964 ]\n",
      " [-0.99464965]\n",
      " [-0.99310976]\n",
      " [-0.99392474]\n",
      " [-0.99481565]\n",
      " [-0.99325514]\n",
      " [-0.99343604]\n",
      " [-0.99407095]\n",
      " [-0.9939993 ]\n",
      " [-0.99311996]\n",
      " [-0.99366182]\n",
      " [-0.99311632]\n",
      " [-0.99277174]\n",
      " [-0.99335128]\n",
      " [-0.99154848]\n",
      " [-0.9933821 ]\n",
      " [-0.99303633]\n",
      " [-0.9944036 ]\n",
      " [-0.99263263]\n",
      " [-0.99326462]\n",
      " [-0.99360776]\n",
      " [-0.99408877]\n",
      " [-0.99395096]\n",
      " [-0.99433917]\n",
      " [-0.99465287]\n",
      " [-0.99538147]\n",
      " [-0.99333119]\n",
      " [-0.99543327]\n",
      " [-0.99534762]\n",
      " [-0.99450392]\n",
      " [-0.99412173]\n",
      " [-0.99453539]\n",
      " [-0.99591035]\n",
      " [-0.99602163]\n",
      " [-0.99487883]\n",
      " [-0.99447006]\n",
      " [-0.99411231]\n",
      " [-0.9940114 ]\n",
      " [-0.99303126]\n",
      " [-0.99428755]\n",
      " [-0.99477911]\n",
      " [-0.99502838]\n",
      " [-0.99395937]\n",
      " [-0.99037981]\n",
      " [-0.99246961]\n",
      " [-0.99234885]\n",
      " [-0.99247092]\n",
      " [-0.99239945]\n",
      " [-0.99251503]\n",
      " [-0.99271911]\n",
      " [-0.99333578]\n",
      " [-0.99254179]\n",
      " [-0.99199224]\n",
      " [-0.99254197]\n",
      " [-0.99234045]\n",
      " [-0.99292922]\n",
      " [-0.99267548]\n",
      " [-0.99279994]\n",
      " [-0.99120903]\n",
      " [-0.99240339]\n",
      " [-0.99206632]\n",
      " [-0.99299806]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2051, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-12 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.00955272]\n",
      " [-0.98869079]\n",
      " [-0.99233985]\n",
      " ...\n",
      " [-0.69219893]\n",
      " [-0.68696207]\n",
      " [-0.68050575]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.765676\n",
      "1     1222840800 -0.764035\n",
      "2     1222862400 -0.762395\n",
      "3     1222884000 -0.760755\n",
      "4     1222905600 -0.759114\n",
      "...          ...       ...\n",
      "1140  1247443200  0.974957\n",
      "1141  1247464800  0.976598\n",
      "1142  1247486400  0.978238\n",
      "1143  1247508000  0.979878\n",
      "1144  1247529600  0.981519\n",
      "\n",
      "[1145 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1247551200 -0.960603\n",
      "1     1247572800 -0.958970\n",
      "2     1247594400 -0.957336\n",
      "3     1247616000 -0.955703\n",
      "4     1247637600 -0.954069\n",
      "...          ...       ...\n",
      "2425  1299931200  0.558360\n",
      "2426  1299952800  0.559993\n",
      "2427  1299974400  0.561627\n",
      "2428  1299996000  0.563261\n",
      "2429  1300017600  0.565711\n",
      "\n",
      "[2430 rows x 2 columns]\n",
      "TIMESEGMENT:  (1145, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(1145, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.91it/s, epoch=1/20, avg_epoch_loss=-.93]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.462 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.930214\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.27it/s, epoch=2/20, avg_epoch_loss=-2.09]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 7.978 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.091517\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=3/20, avg_epoch_loss=-2.39]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.051 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.390830\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.01it/s, epoch=4/20, avg_epoch_loss=-2.76]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.317 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.756684\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.09it/s, epoch=5/20, avg_epoch_loss=-2.83]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.215 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.830553\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.95it/s, epoch=6/20, avg_epoch_loss=-2.72]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.406 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.720135\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.03it/s, epoch=7/20, avg_epoch_loss=-2.93]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.292 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.932018\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=8/20, avg_epoch_loss=-2.95]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 7.916 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.952268\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.46it/s, epoch=9/20, avg_epoch_loss=-3.1]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.746 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.098390\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=10/20, avg_epoch_loss=-2.95]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.861 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-2.949685\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=11/20, avg_epoch_loss=-3.14]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.900 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.140784\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=12/20, avg_epoch_loss=-3.19]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.901 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.187662\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.41it/s, epoch=13/20, avg_epoch_loss=-3.16]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 7.806 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.162536\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=14/20, avg_epoch_loss=-3.02]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 7.902 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.024601\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=15/20, avg_epoch_loss=-3.3]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 7.900 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.304139\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.36it/s, epoch=16/20, avg_epoch_loss=-3.36]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.858 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.356007\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=17/20, avg_epoch_loss=-3.37]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.058 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.374440\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=18/20, avg_epoch_loss=-3.15]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.934 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.146012\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=19/20, avg_epoch_loss=-3.42]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.899 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.419886\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.37it/s, epoch=20/20, avg_epoch_loss=-3.39]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.857 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.391766\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.76567562]\n",
      " [-0.76403527]\n",
      " [-0.76239491]\n",
      " ...\n",
      " [ 0.97823799]\n",
      " [ 0.97987834]\n",
      " [ 0.98151869]]\n",
      "Y_HAT:  [[-0.04192941]\n",
      " [-0.23236899]\n",
      " [-0.39913473]\n",
      " ...\n",
      " [ 0.87969613]\n",
      " [ 0.71538508]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2430, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-13 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.96060334]\n",
      " [-0.95896975]\n",
      " [-0.95733616]\n",
      " ...\n",
      " [ 0.56162705]\n",
      " [ 0.56326064]\n",
      " [ 0.56571102]]\n",
      "Y_HAT:  [[-0.24782555]\n",
      " [-0.39015391]\n",
      " [-0.57728964]\n",
      " ...\n",
      " [ 0.20090854]\n",
      " [ 0.19177279]\n",
      " [ 0.1935343 ]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -1.000000\n",
      "1     1222840800 -0.999214\n",
      "2     1222862400 -0.998428\n",
      "3     1222884000 -0.997642\n",
      "4     1222905600 -0.996856\n",
      "...          ...       ...\n",
      "1140  1247443200  0.996856\n",
      "1141  1247464800  0.997642\n",
      "1142  1247486400  0.998428\n",
      "1143  1247508000  0.999214\n",
      "1144  1247529600  1.000000\n",
      "\n",
      "[1145 rows x 2 columns]\n",
      "TEST:         timestamp    value\n",
      "0     1247551200 -1.00000\n",
      "1     1247572800 -0.99976\n",
      "2     1247594400 -0.99952\n",
      "3     1247616000 -0.99928\n",
      "4     1247637600 -0.99904\n",
      "...          ...      ...\n",
      "2425  1299931200  0.99892\n",
      "2426  1299952800  0.99916\n",
      "2427  1299974400  0.99940\n",
      "2428  1299996000  0.99964\n",
      "2429  1300017600  1.00000\n",
      "\n",
      "[2430 rows x 2 columns]\n",
      "TIMESEGMENT:  (1145, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(1145, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.54it/s, epoch=1/20, avg_epoch_loss=-1.03]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 9.022 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-1.029346\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.11it/s, epoch=2/20, avg_epoch_loss=-2.11]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.184 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.113562\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.03it/s, epoch=3/20, avg_epoch_loss=-2.18]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.297 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.177999\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.33it/s, epoch=4/20, avg_epoch_loss=-2.49]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 7.900 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.487717\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.42it/s, epoch=5/20, avg_epoch_loss=-2.71]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.791 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.708257\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.15it/s, epoch=6/20, avg_epoch_loss=-2.93]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.136 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.926910\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.29it/s, epoch=7/20, avg_epoch_loss=-2.66]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.949 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.662659\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.19it/s, epoch=8/20, avg_epoch_loss=-2.83]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.080 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.831606\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=9/20, avg_epoch_loss=-2.99]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.915 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.993596\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=10/20, avg_epoch_loss=-3.07]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.889 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.067870\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=11/20, avg_epoch_loss=-3.16]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.987 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.156244\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.79it/s, epoch=12/20, avg_epoch_loss=-2.68]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.635 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.677065\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.02it/s, epoch=13/20, avg_epoch_loss=-3.05]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.302 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.045533\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=14/20, avg_epoch_loss=-2.88]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 7.833 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.875533\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=15/20, avg_epoch_loss=-3.3]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 7.924 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.296190\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.39it/s, epoch=16/20, avg_epoch_loss=-3.23]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 7.821 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.233203\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=17/20, avg_epoch_loss=-2.79]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.048 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.786966\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=18/20, avg_epoch_loss=-2.94]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.920 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.943011\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.34it/s, epoch=19/20, avg_epoch_loss=-3.06]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.886 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.061209\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.40it/s, epoch=20/20, avg_epoch_loss=-3.13]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 7.811 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.127418\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-0.99921406]\n",
      " [-0.99842812]\n",
      " ...\n",
      " [ 0.99842812]\n",
      " [ 0.99921406]\n",
      " [ 1.        ]]\n",
      "Y_HAT:  [[-0.32287499]\n",
      " [-0.62114906]\n",
      " [-0.52956957]\n",
      " ...\n",
      " [ 0.80267596]\n",
      " [ 0.80411792]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2430, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal F-4 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-0.99975997]\n",
      " [-0.99951994]\n",
      " ...\n",
      " [ 0.99939992]\n",
      " [ 0.99963995]\n",
      " [ 1.        ]]\n",
      "Y_HAT:  [[-0.31597576]\n",
      " [-0.61258447]\n",
      " [-0.87148446]\n",
      " ...\n",
      " [ 0.22511823]\n",
      " [ 0.2267125 ]\n",
      " [ 0.22828165]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.467745\n",
      "1     1222840800 -0.467206\n",
      "2     1222862400 -0.467129\n",
      "3     1222884000 -0.466590\n",
      "4     1222905600 -0.451646\n",
      "...          ...       ...\n",
      "2239  1271181600 -0.828538\n",
      "2240  1271203200 -0.825765\n",
      "2241  1271224800 -0.825072\n",
      "2242  1271246400 -0.824533\n",
      "2243  1271268000 -0.819218\n",
      "\n",
      "[2244 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1271289600 -0.998999\n",
      "1     1271311200 -0.968265\n",
      "2     1271332800 -0.966801\n",
      "3     1271354400 -0.962334\n",
      "4     1271376000 -0.961795\n",
      "...          ...       ...\n",
      "3417  1345096800  0.680185\n",
      "3418  1345118400  0.681648\n",
      "3419  1345140000  0.682111\n",
      "3420  1345161600  0.684421\n",
      "3421  1345183200  0.685423\n",
      "\n",
      "[3422 rows x 2 columns]\n",
      "TIMESEGMENT:  (2244, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2244, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.83it/s, epoch=1/20, avg_epoch_loss=-.231]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.574 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.231381\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.09it/s, epoch=2/20, avg_epoch_loss=-1.11]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.212 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.114450\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.00it/s, epoch=3/20, avg_epoch_loss=-1.35]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.339 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.347017\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.85it/s, epoch=4/20, avg_epoch_loss=-1.45]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.556 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.451775\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=5/20, avg_epoch_loss=-1.63]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.672 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.628483\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=6/20, avg_epoch_loss=-1.65]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.032 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.649517\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=7/20, avg_epoch_loss=-1.82]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.054 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.818954\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s, epoch=8/20, avg_epoch_loss=-1.87]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.011 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.871220\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.35it/s, epoch=9/20, avg_epoch_loss=-1.85]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 7.874 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.854869\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.47it/s, epoch=10/20, avg_epoch_loss=-1.98]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.733 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.982614\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=11/20, avg_epoch_loss=-2]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 7.909 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.004506\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=12/20, avg_epoch_loss=-2]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.908 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.003993\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.58it/s, epoch=13/20, avg_epoch_loss=-2.12]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.969 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.123607\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.02it/s, epoch=14/20, avg_epoch_loss=-2.14]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.314 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.143232\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.22it/s, epoch=15/20, avg_epoch_loss=-2.1]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.038 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.095892\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.15it/s, epoch=16/20, avg_epoch_loss=-2.21]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.128 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.214171\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=17/20, avg_epoch_loss=-2.11]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.926 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.112627\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.29it/s, epoch=18/20, avg_epoch_loss=-2.29]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 7.955 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.291758\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.27it/s, epoch=19/20, avg_epoch_loss=-2.29]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 7.978 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.292055\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.85it/s, epoch=20/20, avg_epoch_loss=-2.32]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.550 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.316855\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.46774504]\n",
      " [-0.46720585]\n",
      " [-0.46712883]\n",
      " ...\n",
      " [-0.82507221]\n",
      " [-0.82453303]\n",
      " [-0.81921818]]\n",
      "Y_HAT:  [[-0.12372728]\n",
      " [-0.23274407]\n",
      " [-0.45915595]\n",
      " ...\n",
      " [-0.83289009]\n",
      " [-0.82589221]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (3422, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal F-5 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.99899865]\n",
      " [-0.96826497]\n",
      " [-0.96680146]\n",
      " ...\n",
      " [ 0.68211053]\n",
      " [ 0.68442134]\n",
      " [ 0.68542268]]\n",
      "Y_HAT:  [[-0.25048873]\n",
      " [-0.42433968]\n",
      " [-0.46885574]\n",
      " ...\n",
      " [-0.80301279]\n",
      " [-0.83138412]\n",
      " [-0.81768858]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.059837\n",
      "1     1222840800 -0.059238\n",
      "2     1222862400 -0.059163\n",
      "3     1222884000 -0.058563\n",
      "4     1222905600 -0.056016\n",
      "...          ...       ...\n",
      "2593  1278828000 -0.440069\n",
      "2594  1278849600 -0.438570\n",
      "2595  1278871200 -0.437971\n",
      "2596  1278892800 -0.437446\n",
      "2597  1278914400 -0.434299\n",
      "\n",
      "[2598 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1278936000 -0.597137\n",
      "1     1278957600 -0.588220\n",
      "2     1278979200 -0.587321\n",
      "3     1279000800 -0.584773\n",
      "4     1279022400 -0.584248\n",
      "...          ...       ...\n",
      "3917  1363543200  1.340140\n",
      "3918  1363564800  1.342388\n",
      "3919  1363586400  1.343063\n",
      "3920  1363608000  1.345985\n",
      "3921  1363629600  1.347409\n",
      "\n",
      "[3922 rows x 2 columns]\n",
      "TIMESEGMENT:  (2598, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2598, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=1/20, avg_epoch_loss=0.258]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 8.670 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.258468\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=2/20, avg_epoch_loss=-.853]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.032 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.853118\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=3/20, avg_epoch_loss=-.964]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.003 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.964068\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.27it/s, epoch=4/20, avg_epoch_loss=-1.27]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 7.982 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.273786\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.29it/s, epoch=5/20, avg_epoch_loss=-1.54]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.953 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.544728\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=6/20, avg_epoch_loss=-1.63]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.002 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.633118\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.25it/s, epoch=7/20, avg_epoch_loss=-1.64]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.000 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.643622\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.21it/s, epoch=8/20, avg_epoch_loss=-1.74]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.048 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.744260\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.16it/s, epoch=9/20, avg_epoch_loss=-1.91]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 8.113 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.912313\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.98it/s, epoch=10/20, avg_epoch_loss=-1.87]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 8.366 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.874036\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.99it/s, epoch=11/20, avg_epoch_loss=-1.96]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.354 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.956977\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.06it/s, epoch=12/20, avg_epoch_loss=-2]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.247 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.002714\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.20it/s, epoch=13/20, avg_epoch_loss=-2.01]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.063 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.009498\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.10it/s, epoch=14/20, avg_epoch_loss=-2.02]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.195 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.018125\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.19it/s, epoch=15/20, avg_epoch_loss=-2.09]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.086 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.085548\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.13it/s, epoch=16/20, avg_epoch_loss=-2.06]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.161 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.058066\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.38it/s, epoch=17/20, avg_epoch_loss=-2.24]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 7.836 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.241831\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.05it/s, epoch=18/20, avg_epoch_loss=-2.17]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.265 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.169049\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.17it/s, epoch=19/20, avg_epoch_loss=-2.14]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.108 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.139058\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=20/20, avg_epoch_loss=-2.27]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.033 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.271081\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.05983739]\n",
      " [-0.05923789]\n",
      " [-0.05916295]\n",
      " ...\n",
      " [-0.4379707 ]\n",
      " [-0.43744614]\n",
      " [-0.43429877]]\n",
      "Y_HAT:  [[-0.02463682]\n",
      " [-0.02872156]\n",
      " [-0.04663705]\n",
      " ...\n",
      " [-0.43539792]\n",
      " [-0.42231423]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (3922, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.5971374 ]\n",
      " [-0.58821987]\n",
      " [-0.58732062]\n",
      " ...\n",
      " [ 1.34306269]\n",
      " [ 1.34598524]\n",
      " [ 1.34740904]]\n",
      "Y_HAT:  [[-0.03979114]\n",
      " [-0.05086812]\n",
      " [-0.06500641]\n",
      " ...\n",
      " [-0.45165265]\n",
      " [-0.45340833]\n",
      " [-0.45107374]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal D-14 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp  value\n",
      "0     1222819200   -1.0\n",
      "1     1222840800   -1.0\n",
      "2     1222862400   -1.0\n",
      "3     1222884000   -1.0\n",
      "4     1222905600   -1.0\n",
      "...          ...    ...\n",
      "3670  1302091200   -1.0\n",
      "3671  1302112800   -1.0\n",
      "3672  1302134400   -1.0\n",
      "3673  1302156000   -1.0\n",
      "3674  1302177600   -1.0\n",
      "\n",
      "[3675 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1302199200   -1.0\n",
      "1     1302220800   -1.0\n",
      "2     1302242400   -1.0\n",
      "3     1302264000   -1.0\n",
      "4     1302285600   -1.0\n",
      "...          ...    ...\n",
      "2620  1358791200   -1.0\n",
      "2621  1358812800   -1.0\n",
      "2622  1358834400   -1.0\n",
      "2623  1358856000   -1.0\n",
      "2624  1358877600   -1.0\n",
      "\n",
      "[2625 rows x 2 columns]\n",
      "TIMESEGMENT:  (3675, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(3675, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.53it/s, epoch=1/20, avg_epoch_loss=-.547]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 9.039 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.546994\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=2/20, avg_epoch_loss=-2.46]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.025 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.463824\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=3/20, avg_epoch_loss=-2.98]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 7.920 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.977873\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.31it/s, epoch=4/20, avg_epoch_loss=-3.13]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 7.929 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-3.129370\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.27it/s, epoch=5/20, avg_epoch_loss=-3.29]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 7.982 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-3.285999\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.40it/s, epoch=6/20, avg_epoch_loss=-3.39]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 7.818 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-3.391644\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=7/20, avg_epoch_loss=-3.44]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 7.990 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-3.435236\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.23it/s, epoch=8/20, avg_epoch_loss=-3.52]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.026 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-3.524278\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=9/20, avg_epoch_loss=-3.54]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 8.008 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.539342\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.32it/s, epoch=10/20, avg_epoch_loss=-3.61]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 7.914 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.609829\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.25it/s, epoch=11/20, avg_epoch_loss=-3.64]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.002 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.635822\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.26it/s, epoch=12/20, avg_epoch_loss=-3.7]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 7.987 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.695136\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.28it/s, epoch=13/20, avg_epoch_loss=-3.68]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 7.964 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.682078\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:07<00:00,  6.30it/s, epoch=14/20, avg_epoch_loss=-3.33]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 7.942 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.332029\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.90it/s, epoch=15/20, avg_epoch_loss=-3.38]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.474 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.381613\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.98it/s, epoch=16/20, avg_epoch_loss=-3.43]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.362 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.426079\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.37it/s, epoch=17/20, avg_epoch_loss=-3.41]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 11.443 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.405387\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.17it/s, epoch=18/20, avg_epoch_loss=-3.43]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 12.007 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.425257\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.99it/s, epoch=19/20, avg_epoch_loss=-3.81]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 10.019 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.812638\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.97it/s, epoch=20/20, avg_epoch_loss=-3.78]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 10.064 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.776030\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.00857568]\n",
      " [-1.04637897]\n",
      " [-1.01891863]\n",
      " ...\n",
      " [-1.00094068]\n",
      " [-0.99834639]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2625, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-9 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-1.04671323]\n",
      " [-1.01923847]\n",
      " [-1.02831113]\n",
      " ...\n",
      " [-0.99952781]\n",
      " [-1.00133336]\n",
      " [-0.99975008]]\n",
      "TRAIN:        timestamp     value\n",
      "0    1222819200 -0.333329\n",
      "1    1222840800 -0.333329\n",
      "2    1222862400 -0.333329\n",
      "3    1222884000 -0.333329\n",
      "4    1222905600 -1.000000\n",
      "..          ...       ...\n",
      "434  1232193600  0.333338\n",
      "435  1232215200  0.333338\n",
      "436  1232236800  0.333338\n",
      "437  1232258400  0.333338\n",
      "438  1232280000  0.333338\n",
      "\n",
      "[439 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1232301600  0.639967\n",
      "1     1232323200  0.639967\n",
      "2     1232344800  0.639967\n",
      "3     1232366400  0.639967\n",
      "4     1232388000  0.637897\n",
      "...          ...       ...\n",
      "1091  1255867200  0.499149\n",
      "1092  1255888800  0.501221\n",
      "1093  1255910400  0.501221\n",
      "1094  1255932000  0.501221\n",
      "1095  1255953600 -0.954212\n",
      "\n",
      "[1096 rows x 2 columns]\n",
      "TIMESEGMENT:  (439, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(439, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.15it/s, epoch=1/20, avg_epoch_loss=-.77]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 9.710 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.769885\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.25it/s, epoch=2/20, avg_epoch_loss=-2.05]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 9.524 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-2.049637\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.49it/s, epoch=3/20, avg_epoch_loss=-2.17]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.104 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.166238\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.25it/s, epoch=4/20, avg_epoch_loss=-2.48]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.530 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.476355\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.07it/s, epoch=5/20, avg_epoch_loss=-2.74]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.863 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.742207\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.57it/s, epoch=6/20, avg_epoch_loss=-2.7]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.983 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.703375\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.12it/s, epoch=7/20, avg_epoch_loss=-2.89]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.767 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.888697\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.22it/s, epoch=8/20, avg_epoch_loss=-3.11]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.582 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-3.109098\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.26it/s, epoch=9/20, avg_epoch_loss=-3.04]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 11.739 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-3.043015\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.42it/s, epoch=10/20, avg_epoch_loss=-3.15]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 11.318 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.150428\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.03it/s, epoch=11/20, avg_epoch_loss=-3.23]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 9.938 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-3.233877\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.22it/s, epoch=12/20, avg_epoch_loss=-3.24]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 9.578 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.241649\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.24it/s, epoch=13/20, avg_epoch_loss=-3.17]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 9.555 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-3.170072\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=14/20, avg_epoch_loss=-3.11]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 9.446 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.114297\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=15/20, avg_epoch_loss=-2.58]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.450 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.583977\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.21it/s, epoch=16/20, avg_epoch_loss=-3.25]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 9.597 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.247669\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.29it/s, epoch=17/20, avg_epoch_loss=-3.32]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.449 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.324980\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=18/20, avg_epoch_loss=-3.3]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.435 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.299124\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.26it/s, epoch=19/20, avg_epoch_loss=-3.21]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.515 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.206645\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.05it/s, epoch=20/20, avg_epoch_loss=-3.32]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 9.905 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.319917\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-1.        ]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 1.        ]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [-0.33332882]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]\n",
      " [ 0.33333784]]\n",
      "Y_HAT:  [[-0.34158722]\n",
      " [-0.31889668]\n",
      " [-0.32036158]\n",
      " [-0.32097024]\n",
      " [-0.31407675]\n",
      " [-0.31206143]\n",
      " [-0.33092007]\n",
      " [-0.34058174]\n",
      " [-0.34271774]\n",
      " [-0.34597686]\n",
      " [-0.35171479]\n",
      " [-0.34997296]\n",
      " [-0.34776783]\n",
      " [-0.34231454]\n",
      " [-0.34462571]\n",
      " [-0.34113026]\n",
      " [-0.340262  ]\n",
      " [-0.34550366]\n",
      " [-0.34043354]\n",
      " [-0.34018013]\n",
      " [-0.34082568]\n",
      " [-0.34084278]\n",
      " [-0.33770818]\n",
      " [-0.33555552]\n",
      " [-0.33830628]\n",
      " [-0.35314819]\n",
      " [-0.32870311]\n",
      " [-0.33912295]\n",
      " [-0.35033333]\n",
      " [-0.32711715]\n",
      " [-0.36553615]\n",
      " [-0.36661887]\n",
      " [-0.29099932]\n",
      " [-0.31552172]\n",
      " [-0.29410976]\n",
      " [-0.3108553 ]\n",
      " [-0.22115804]\n",
      " [-0.0922804 ]\n",
      " [ 0.00443622]\n",
      " [-0.29831731]\n",
      " [ 0.20562187]\n",
      " [ 0.08638155]\n",
      " [ 0.16780052]\n",
      " [ 0.02753132]\n",
      " [ 0.20195968]\n",
      " [ 0.26212785]\n",
      " [ 0.28809524]\n",
      " [ 0.29829806]\n",
      " [ 0.31296915]\n",
      " [ 0.33917838]\n",
      " [ 0.34157342]\n",
      " [ 0.31588751]\n",
      " [ 0.33485511]\n",
      " [ 0.33533439]\n",
      " [ 0.33230045]\n",
      " [ 0.33571813]\n",
      " [ 0.33945271]\n",
      " [ 0.33793753]\n",
      " [ 0.33361599]\n",
      " [ 0.33609062]\n",
      " [ 0.33844244]\n",
      " [ 0.33889854]\n",
      " [ 0.33997041]\n",
      " [ 0.33676013]\n",
      " [ 0.33819333]\n",
      " [ 0.3383522 ]\n",
      " [ 0.34171101]\n",
      " [ 0.34110147]\n",
      " [ 0.34584463]\n",
      " [ 0.34020579]\n",
      " [ 0.33723295]\n",
      " [ 0.33680397]\n",
      " [ 0.33585149]\n",
      " [ 0.34021676]\n",
      " [ 0.33875775]\n",
      " [ 0.33753601]\n",
      " [ 0.34063253]\n",
      " [ 0.33719489]\n",
      " [ 0.33972564]\n",
      " [ 0.33988997]\n",
      " [ 0.3410373 ]\n",
      " [ 0.34015641]\n",
      " [ 0.33855823]\n",
      " [ 0.3380962 ]\n",
      " [ 0.33901408]\n",
      " [ 0.34327915]\n",
      " [ 0.33980414]\n",
      " [ 0.33523619]\n",
      " [ 0.33988249]\n",
      " [ 0.34109837]\n",
      " [ 0.34037867]\n",
      " [ 0.34000218]\n",
      " [ 0.33895004]\n",
      " [ 0.33857021]\n",
      " [ 0.33994094]\n",
      " [ 0.33938628]\n",
      " [ 0.33904353]\n",
      " [ 0.3389931 ]\n",
      " [ 0.34003991]\n",
      " [ 0.33897072]\n",
      " [ 0.3379097 ]\n",
      " [ 0.33873418]\n",
      " [ 0.33865571]\n",
      " [ 0.33870113]\n",
      " [ 0.33721393]\n",
      " [ 0.33253661]\n",
      " [ 0.33317092]\n",
      " [ 0.33264938]\n",
      " [ 0.33367261]\n",
      " [ 0.33206245]\n",
      " [ 0.3317152 ]\n",
      " [ 0.33299595]\n",
      " [ 0.33354267]\n",
      " [ 0.33358312]\n",
      " [ 0.33355087]\n",
      " [ 0.33396295]\n",
      " [ 0.33293462]\n",
      " [ 0.33346298]\n",
      " [ 0.33434463]\n",
      " [ 0.33419693]\n",
      " [ 0.33189064]\n",
      " [ 0.33358252]\n",
      " [ 0.33281568]\n",
      " [ 0.33360496]\n",
      " [ 0.3333059 ]\n",
      " [ 0.33025187]\n",
      " [ 0.33355662]\n",
      " [ 0.33739412]\n",
      " [ 0.3334851 ]\n",
      " [ 0.3333616 ]\n",
      " [ 0.33405194]\n",
      " [ 0.33343098]\n",
      " [ 0.33402103]\n",
      " [ 0.33230963]\n",
      " [ 0.33312026]\n",
      " [ 0.33477771]\n",
      " [ 0.33448899]\n",
      " [ 0.33324626]\n",
      " [ 0.33427024]\n",
      " [ 0.33437446]\n",
      " [ 0.33437201]\n",
      " [ 0.33296466]\n",
      " [ 0.33555835]\n",
      " [ 0.33154365]\n",
      " [ 0.33386192]\n",
      " [ 0.33221304]\n",
      " [ 0.33317146]\n",
      " [ 0.33299366]\n",
      " [ 0.33240432]\n",
      " [ 0.33137283]\n",
      " [ 0.33216548]\n",
      " [ 0.33236584]\n",
      " [ 0.3337619 ]\n",
      " [ 0.33190247]\n",
      " [ 0.33341014]\n",
      " [ 0.33389503]\n",
      " [ 0.33326855]\n",
      " [ 0.33247086]\n",
      " [ 0.33385086]\n",
      " [ 0.33574468]\n",
      " [ 0.33311191]\n",
      " [ 0.33322346]\n",
      " [ 0.3335911 ]\n",
      " [ 0.33354622]\n",
      " [ 0.33241746]\n",
      " [ 0.33448654]\n",
      " [ 0.33374551]\n",
      " [ 0.33443055]\n",
      " [ 0.33469817]\n",
      " [ 0.33309215]\n",
      " [ 0.3361617 ]\n",
      " [ 0.33125499]\n",
      " [ 0.33137131]\n",
      " [ 0.33311611]\n",
      " [ 0.33223435]\n",
      " [ 0.33278728]\n",
      " [ 0.33490586]\n",
      " [ 0.33061004]\n",
      " [ 0.33329108]\n",
      " [ 0.33304417]\n",
      " [ 0.33275032]\n",
      " [ 0.33417714]\n",
      " [ 0.33166534]\n",
      " [ 0.33289367]\n",
      " [ 0.33312771]\n",
      " [ 0.33268958]\n",
      " [ 0.33222976]\n",
      " [ 0.33109027]\n",
      " [ 0.33513555]\n",
      " [ 0.33321172]\n",
      " [ 0.33368006]\n",
      " [ 0.33460844]\n",
      " [ 0.33448386]\n",
      " [ 0.33367324]\n",
      " [ 0.33321983]\n",
      " [ 0.33210969]\n",
      " [ 0.33115283]\n",
      " [ 0.33465725]\n",
      " [ 0.33411339]\n",
      " [ 0.334066  ]\n",
      " [ 0.33486629]\n",
      " [ 0.33532706]\n",
      " [ 0.3352586 ]\n",
      " [ 0.33506212]\n",
      " [ 0.33439064]\n",
      " [ 0.33468837]\n",
      " [ 0.33525768]\n",
      " [ 0.33627796]\n",
      " [ 0.33421093]\n",
      " [ 0.33594376]\n",
      " [ 0.3352029 ]\n",
      " [ 0.33323729]\n",
      " [ 0.33586144]\n",
      " [ 0.33275881]\n",
      " [ 0.33434296]\n",
      " [ 0.33471385]\n",
      " [ 0.33464074]\n",
      " [ 0.33618653]\n",
      " [ 0.3347261 ]\n",
      " [ 0.33465606]\n",
      " [ 0.33525047]\n",
      " [ 0.3335762 ]\n",
      " [ 0.33303094]\n",
      " [ 0.3344962 ]\n",
      " [ 0.33600807]\n",
      " [ 0.33454505]\n",
      " [ 0.33496451]\n",
      " [ 0.33472934]\n",
      " [ 0.33363971]\n",
      " [ 0.33307639]\n",
      " [ 0.33485413]\n",
      " [ 0.33398664]\n",
      " [ 0.33527523]\n",
      " [ 0.33379582]\n",
      " [ 0.33471307]\n",
      " [ 0.33559144]\n",
      " [ 0.33642331]\n",
      " [ 0.33445096]\n",
      " [ 0.33476722]\n",
      " [ 0.33398911]\n",
      " [ 0.3351208 ]\n",
      " [ 0.33454838]\n",
      " [ 0.33473927]\n",
      " [ 0.33380646]\n",
      " [ 0.33418176]\n",
      " [ 0.33230636]\n",
      " [ 0.33357117]\n",
      " [ 0.33418462]\n",
      " [ 0.33415759]\n",
      " [ 0.33323517]\n",
      " [ 0.33438218]\n",
      " [ 0.33284283]\n",
      " [ 0.3330408 ]\n",
      " [ 0.33249718]\n",
      " [ 0.33615699]\n",
      " [ 0.33241069]\n",
      " [ 0.33437851]\n",
      " [ 0.33359772]\n",
      " [ 0.3339088 ]\n",
      " [ 0.33488891]\n",
      " [ 0.33374155]\n",
      " [ 0.33398387]\n",
      " [ 0.33348164]\n",
      " [ 0.33447877]\n",
      " [ 0.33426139]\n",
      " [ 0.33352575]\n",
      " [ 0.33229244]\n",
      " [ 0.33426708]\n",
      " [ 0.33325016]\n",
      " [ 0.33342305]\n",
      " [ 0.33327949]\n",
      " [ 0.33357915]\n",
      " [ 0.33356541]\n",
      " [ 0.33339459]\n",
      " [ 0.33336845]\n",
      " [ 0.33323085]\n",
      " [ 0.33349136]\n",
      " [ 0.33326009]\n",
      " [ 0.33554494]\n",
      " [ 0.33188576]\n",
      " [ 0.33295968]\n",
      " [ 0.33232659]\n",
      " [ 0.33256462]\n",
      " [ 0.33242521]\n",
      " [ 0.33101857]\n",
      " [ 0.33172953]\n",
      " [ 0.33380717]\n",
      " [ 0.33535019]\n",
      " [ 0.33363974]\n",
      " [ 0.3321709 ]\n",
      " [ 0.33183327]\n",
      " [ 0.33105209]\n",
      " [ 0.33207825]\n",
      " [ 0.33256531]\n",
      " [ 0.33151948]\n",
      " [ 0.33062795]\n",
      " [ 0.32957822]\n",
      " [ 0.33168447]\n",
      " [ 0.33236179]\n",
      " [ 0.33263803]\n",
      " [ 0.33007428]\n",
      " [ 0.33217236]\n",
      " [ 0.33170295]\n",
      " [ 0.33247128]\n",
      " [ 0.33168575]\n",
      " [ 0.33273071]\n",
      " [ 0.33208534]\n",
      " [ 0.33184394]\n",
      " [ 0.33141044]\n",
      " [ 0.32881051]\n",
      " [ 0.33183929]\n",
      " [ 0.32999784]\n",
      " [ 0.33075225]\n",
      " [ 0.3302432 ]\n",
      " [ 0.33037427]\n",
      " [ 0.32990608]\n",
      " [ 0.33113837]\n",
      " [ 0.32982692]\n",
      " [ 0.32981107]\n",
      " [ 0.33059448]\n",
      " [ 0.33058953]\n",
      " [ 0.33212948]\n",
      " [ 0.33352757]\n",
      " [ 0.3312887 ]\n",
      " [ 0.33899897]\n",
      " [ 0.33534276]\n",
      " [ 0.33423454]\n",
      " [ 0.33596519]\n",
      " [ 0.3359707 ]\n",
      " [ 0.33377376]\n",
      " [ 0.32919124]\n",
      " [ 0.33625796]\n",
      " [ 0.33587682]\n",
      " [ 0.33768895]\n",
      " [ 0.3383196 ]\n",
      " [ 0.33723304]\n",
      " [ 0.33729753]\n",
      " [ 0.33778736]\n",
      " [ 0.33817929]\n",
      " [ 0.33849072]\n",
      " [ 0.34042552]\n",
      " [ 0.33685875]\n",
      " [ 0.33991131]\n",
      " [ 0.3385134 ]\n",
      " [ 0.33701771]\n",
      " [ 0.33756325]\n",
      " [ 0.33755204]\n",
      " [ 0.33914685]\n",
      " [ 0.34242451]\n",
      " [ 0.33547607]\n",
      " [ 0.33833003]\n",
      " [ 0.33654457]\n",
      " [ 0.3355833 ]\n",
      " [ 0.33853611]\n",
      " [ 0.33605123]\n",
      " [ 0.336063  ]\n",
      " [ 0.33479756]\n",
      " [ 0.33756828]\n",
      " [ 0.33504665]\n",
      " [ 0.33745944]\n",
      " [ 0.33610284]\n",
      " [ 0.33687276]\n",
      " [ 0.33577922]\n",
      " [ 0.33814037]\n",
      " [ 0.33579341]\n",
      " [ 0.33639225]\n",
      " [ 0.33527404]\n",
      " [ 0.33466187]\n",
      " [ 0.33660412]\n",
      " [ 0.33792609]\n",
      " [ 0.33666551]\n",
      " [ 0.3394976 ]\n",
      " [ 0.33760726]\n",
      " [ 0.3360647 ]\n",
      " [ 0.33058524]\n",
      " [ 0.33641723]\n",
      " [ 0.3361086 ]\n",
      " [ 0.33501706]\n",
      " [ 0.33694199]\n",
      " [ 0.33659974]\n",
      " [ 0.33656234]\n",
      " [ 0.33774933]\n",
      " [ 0.33627689]\n",
      " [ 0.33621681]\n",
      " [ 0.33419028]\n",
      " [ 0.33854717]\n",
      " [ 0.33650836]\n",
      " [ 0.33737919]\n",
      " [ 0.3376087 ]\n",
      " [ 0.33930114]\n",
      " [ 0.33707049]\n",
      " [ 0.33834305]\n",
      " [ 0.33906239]\n",
      " [ 0.33735061]\n",
      " [ 0.33696136]\n",
      " [ 0.3465392 ]\n",
      " [ 0.33939207]\n",
      " [ 0.33327088]\n",
      " [ 0.33590028]\n",
      " [ 0.33936653]\n",
      " [ 0.3370077 ]\n",
      " [ 0.33629951]\n",
      " [ 0.33665401]\n",
      " [ 0.33786601]\n",
      " [ 0.33680356]\n",
      " [ 0.33845082]\n",
      " [ 0.33507428]\n",
      " [ 0.33658352]\n",
      " [ 0.33750647]\n",
      " [ 0.33927062]\n",
      " [ 0.33887359]\n",
      " [ 0.33778042]\n",
      " [ 0.33710149]\n",
      " [ 0.33761322]\n",
      " [ 0.33753437]\n",
      " [ 0.3376596 ]\n",
      " [ 0.33803645]\n",
      " [ 0.33803409]\n",
      " [ 0.33890218]\n",
      " [ 0.33521166]\n",
      " [ 0.33129242]\n",
      " [ 0.32514286]\n",
      " [ 0.33793727]\n",
      " [ 0.33733895]\n",
      " [ 0.33132771]\n",
      " [ 0.33227119]\n",
      " [ 0.33049107]\n",
      " [ 0.32979804]\n",
      " [ 0.33079919]\n",
      " [ 0.33089048]\n",
      " [ 0.3304908 ]\n",
      " [ 0.3306841 ]\n",
      " [ 0.33307135]\n",
      " [ 0.32322657]\n",
      " [ 0.3271243 ]\n",
      " [ 0.32530037]\n",
      " [ 0.32722291]\n",
      " [ 0.32918453]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (1096, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal P-14 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 0.63996705]\n",
      " [ 0.63996705]\n",
      " [ 0.63996705]\n",
      " ...\n",
      " [ 0.50122056]\n",
      " [ 0.50122056]\n",
      " [-0.95421168]]\n",
      "Y_HAT:  [[-0.32312766]\n",
      " [-0.31848863]\n",
      " [-0.31766301]\n",
      " ...\n",
      " [ 0.65260375]\n",
      " [ 0.65223032]\n",
      " [ 0.64948022]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.999426\n",
      "1     1222840800  0.999296\n",
      "2     1222862400  0.999611\n",
      "3     1222884000  0.999500\n",
      "4     1222905600  0.999519\n",
      "...          ...       ...\n",
      "2875  1284919200  0.999389\n",
      "2876  1284940800  0.999426\n",
      "2877  1284962400  0.999574\n",
      "2878  1284984000  0.999500\n",
      "2879  1285005600  0.999500\n",
      "\n",
      "[2880 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1285027200  0.992941\n",
      "1     1285048800  0.993788\n",
      "2     1285070400  0.993788\n",
      "3     1285092000  0.994635\n",
      "4     1285113600  0.994635\n",
      "...          ...       ...\n",
      "6095  1416679200 -0.653819\n",
      "6096  1416700800 -0.654666\n",
      "6097  1416722400 -0.654666\n",
      "6098  1416744000 -0.652972\n",
      "6099  1416765600 -0.663137\n",
      "\n",
      "[6100 rows x 2 columns]\n",
      "TIMESEGMENT:  (2880, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2880, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.80it/s, epoch=1/20, avg_epoch_loss=-.161] \n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.417 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.161463\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.71it/s, epoch=2/20, avg_epoch_loss=-1.82]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 10.625 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.818581\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.12it/s, epoch=3/20, avg_epoch_loss=-2.44]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.772 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.437434\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.39it/s, epoch=4/20, avg_epoch_loss=-1.69]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.274 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.690869\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.89it/s, epoch=5/20, avg_epoch_loss=-2.91]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 10.219 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.909593\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.80it/s, epoch=6/20, avg_epoch_loss=-2.84]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 10.426 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.840900\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.47it/s, epoch=7/20, avg_epoch_loss=-2.18]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 11.183 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.183917\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.40it/s, epoch=8/20, avg_epoch_loss=-2.89]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 11.376 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.892343\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.63it/s, epoch=9/20, avg_epoch_loss=-2.57]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.799 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.574550\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.24it/s, epoch=10/20, avg_epoch_loss=-3.18]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 9.542 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-3.181083\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.44it/s, epoch=11/20, avg_epoch_loss=-2.06]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 9.196 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.056917\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.92it/s, epoch=12/20, avg_epoch_loss=-3.22]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 10.170 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-3.222332\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.12it/s, epoch=13/20, avg_epoch_loss=-2.28]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 9.778 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.276665\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=14/20, avg_epoch_loss=-3]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 9.426 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-3.000115\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.12it/s, epoch=15/20, avg_epoch_loss=-3.54]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.173 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-3.536651\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.94it/s, epoch=16/20, avg_epoch_loss=-3.57]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.453 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-3.565299\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.84it/s, epoch=17/20, avg_epoch_loss=-3.64]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 10.331 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.639812\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.31it/s, epoch=18/20, avg_epoch_loss=-3.02]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.417 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-3.024054\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=19/20, avg_epoch_loss=-3.32]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.439 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-3.321167\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.28it/s, epoch=20/20, avg_epoch_loss=-3.33]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 9.502 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-3.326571\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.99942593]\n",
      " [0.9992963 ]\n",
      " [0.99961111]\n",
      " ...\n",
      " [0.99957407]\n",
      " [0.9995    ]\n",
      " [0.9995    ]]\n",
      "Y_HAT:  [[0.98148477]\n",
      " [0.97273088]\n",
      " [0.97993797]\n",
      " ...\n",
      " [0.99555022]\n",
      " [0.99414706]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (6100, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[ 0.99294084]\n",
      " [ 0.99378794]\n",
      " [ 0.99378794]\n",
      " ...\n",
      " [-0.6546661 ]\n",
      " [-0.6529719 ]\n",
      " [-0.66313709]]\n",
      "Y_HAT:  [[0.97051728]\n",
      " [0.97473043]\n",
      " [0.99226332]\n",
      " ...\n",
      " [0.98502105]\n",
      " [0.98639143]\n",
      " [0.98817587]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal T-8 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:        timestamp  value\n",
      "0    1222819200   -1.0\n",
      "1    1222840800   -1.0\n",
      "2    1222862400   -1.0\n",
      "3    1222884000   -1.0\n",
      "4    1222905600   -1.0\n",
      "..          ...    ...\n",
      "743  1238868000   -1.0\n",
      "744  1238889600   -1.0\n",
      "745  1238911200   -1.0\n",
      "746  1238932800   -1.0\n",
      "747  1238954400   -1.0\n",
      "\n",
      "[748 rows x 2 columns]\n",
      "TEST:         timestamp  value\n",
      "0     1238976000   -1.0\n",
      "1     1238997600   -1.0\n",
      "2     1239019200   -1.0\n",
      "3     1239040800   -1.0\n",
      "4     1239062400   -1.0\n",
      "...          ...    ...\n",
      "1514  1271678400   -1.0\n",
      "1515  1271700000   -1.0\n",
      "1516  1271721600   -1.0\n",
      "1517  1271743200   -1.0\n",
      "1518  1271764800   -1.0\n",
      "\n",
      "[1519 rows x 2 columns]\n",
      "TIMESEGMENT:  (748, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(748, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.19it/s, epoch=1/20, avg_epoch_loss=-.89]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 9.633 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.889860\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.65it/s, epoch=2/20, avg_epoch_loss=-2]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.857 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.997680\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.82it/s, epoch=3/20, avg_epoch_loss=-2.41]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 8.597 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-2.408838\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.86it/s, epoch=4/20, avg_epoch_loss=-2.27]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.537 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.268457\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.78it/s, epoch=5/20, avg_epoch_loss=-2.32]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.647 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.321317\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.85it/s, epoch=6/20, avg_epoch_loss=-2.52]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 8.545 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-2.516996\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.85it/s, epoch=7/20, avg_epoch_loss=-2.19]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.555 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.188750\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.81it/s, epoch=8/20, avg_epoch_loss=-2.73]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 8.609 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.732810\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.84it/s, epoch=9/20, avg_epoch_loss=-2.52]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 8.566 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.524087\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=10/20, avg_epoch_loss=-2.96]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 8.661 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-2.956410\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=11/20, avg_epoch_loss=-2.41]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.666 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-2.405331\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.82it/s, epoch=12/20, avg_epoch_loss=-2.5]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.597 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.504415\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.78it/s, epoch=13/20, avg_epoch_loss=-1.6]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 8.649 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.601184\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.82it/s, epoch=14/20, avg_epoch_loss=-2.69]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.597 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.685054\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=15/20, avg_epoch_loss=-2.72]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 8.668 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-2.719971\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.80it/s, epoch=16/20, avg_epoch_loss=-2.91]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 8.617 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.910325\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.67it/s, epoch=17/20, avg_epoch_loss=-3.05]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 8.814 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-3.046457\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.75it/s, epoch=18/20, avg_epoch_loss=-2.77]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 8.692 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.773786\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.77it/s, epoch=19/20, avg_epoch_loss=-2.89]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 8.674 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.890684\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.62it/s, epoch=20/20, avg_epoch_loss=-2.85]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.894 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.851271\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.99019608]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 1.00980392]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.99019608]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 1.02941176]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.51960784]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [ 1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]]\n",
      "Y_HAT:  [[-0.9847219 ]\n",
      " [-1.00043476]\n",
      " [-0.99808508]\n",
      " [-0.98651046]\n",
      " [-0.98590463]\n",
      " [-0.99690366]\n",
      " [-0.99149078]\n",
      " [-0.98606837]\n",
      " [-0.99420577]\n",
      " [-0.99114144]\n",
      " [-0.9872666 ]\n",
      " [-0.99599016]\n",
      " [-0.99547422]\n",
      " [-0.9949016 ]\n",
      " [-0.99566162]\n",
      " [-0.99561357]\n",
      " [-0.99393684]\n",
      " [-0.99407786]\n",
      " [-0.99594969]\n",
      " [-1.01040494]\n",
      " [-0.99375802]\n",
      " [-0.98902321]\n",
      " [-0.99495596]\n",
      " [-0.99841005]\n",
      " [-0.98941469]\n",
      " [-0.99694192]\n",
      " [-1.00217974]\n",
      " [-0.99493849]\n",
      " [-0.99084425]\n",
      " [-0.99152964]\n",
      " [-0.99500465]\n",
      " [-0.99608117]\n",
      " [-0.99177343]\n",
      " [-0.9942916 ]\n",
      " [-0.99159867]\n",
      " [-0.99675155]\n",
      " [-0.99801844]\n",
      " [-0.99487931]\n",
      " [-0.99437004]\n",
      " [-0.99493194]\n",
      " [-0.99095458]\n",
      " [-0.98682642]\n",
      " [-0.99211067]\n",
      " [-0.99705333]\n",
      " [-0.99235505]\n",
      " [-0.99272239]\n",
      " [-0.99932951]\n",
      " [-0.99593157]\n",
      " [-0.99623752]\n",
      " [-0.99103385]\n",
      " [-0.99084491]\n",
      " [-0.98813629]\n",
      " [-0.99318576]\n",
      " [-0.99148256]\n",
      " [-0.99605006]\n",
      " [-0.99282753]\n",
      " [-0.99314028]\n",
      " [-0.9863165 ]\n",
      " [-0.99206185]\n",
      " [-0.99224532]\n",
      " [-0.99306625]\n",
      " [-0.99104822]\n",
      " [-0.98959297]\n",
      " [-0.99204904]\n",
      " [-0.99354136]\n",
      " [-0.99270338]\n",
      " [-0.99458289]\n",
      " [-0.99252057]\n",
      " [-0.99288023]\n",
      " [-0.99423599]\n",
      " [-0.99406278]\n",
      " [-1.00168896]\n",
      " [-0.99971527]\n",
      " [-0.99176431]\n",
      " [-0.9850657 ]\n",
      " [-0.9929679 ]\n",
      " [-0.98742628]\n",
      " [-0.99234885]\n",
      " [-0.9889521 ]\n",
      " [-0.98438776]\n",
      " [-0.98495531]\n",
      " [-0.98658353]\n",
      " [-0.98138374]\n",
      " [-0.98394668]\n",
      " [-1.00222778]\n",
      " [-0.99538994]\n",
      " [-0.99030226]\n",
      " [-0.99529046]\n",
      " [-0.99308866]\n",
      " [-0.9925769 ]\n",
      " [-0.98874837]\n",
      " [-0.99239516]\n",
      " [-0.99289787]\n",
      " [-0.98664004]\n",
      " [-0.99065453]\n",
      " [-0.99291915]\n",
      " [-0.98272592]\n",
      " [-0.98657262]\n",
      " [-0.98419672]\n",
      " [-0.98621392]\n",
      " [-0.98577249]\n",
      " [-0.98067802]\n",
      " [-0.98558962]\n",
      " [-0.99122447]\n",
      " [-0.98636401]\n",
      " [-0.98505586]\n",
      " [-0.98799849]\n",
      " [-0.98494005]\n",
      " [-0.99039137]\n",
      " [-0.98286164]\n",
      " [-0.98818117]\n",
      " [-0.98599952]\n",
      " [-0.99214494]\n",
      " [-0.98736453]\n",
      " [-0.98240012]\n",
      " [-0.976978  ]\n",
      " [-0.99043572]\n",
      " [-0.99243253]\n",
      " [-0.98414803]\n",
      " [-0.98336387]\n",
      " [-0.99167311]\n",
      " [-0.98213583]\n",
      " [-0.97835565]\n",
      " [-0.9808718 ]\n",
      " [-0.98249793]\n",
      " [-0.98435646]\n",
      " [-0.97958869]\n",
      " [-0.97976983]\n",
      " [-0.98528457]\n",
      " [-0.98360199]\n",
      " [-0.98605216]\n",
      " [-0.98202765]\n",
      " [-0.98436457]\n",
      " [-0.98007661]\n",
      " [-0.99201322]\n",
      " [-0.98232543]\n",
      " [-0.98785472]\n",
      " [-0.98698372]\n",
      " [-0.98311722]\n",
      " [-0.98261148]\n",
      " [-0.98481035]\n",
      " [-0.98819238]\n",
      " [-0.98820877]\n",
      " [-0.98427469]\n",
      " [-0.98093987]\n",
      " [-0.97553545]\n",
      " [-0.97863269]\n",
      " [-0.97644907]\n",
      " [-0.97962356]\n",
      " [-0.97795701]\n",
      " [-0.97663188]\n",
      " [-0.98089278]\n",
      " [-0.98055273]\n",
      " [-0.98071158]\n",
      " [-0.97779769]\n",
      " [-0.97917676]\n",
      " [-0.97790521]\n",
      " [-0.9803443 ]\n",
      " [-0.97455961]\n",
      " [-0.97594434]\n",
      " [-0.9836778 ]\n",
      " [-0.98226875]\n",
      " [-0.98048699]\n",
      " [-0.98290205]\n",
      " [-0.98235857]\n",
      " [-0.98191077]\n",
      " [-0.97974503]\n",
      " [-0.98233086]\n",
      " [-0.97516519]\n",
      " [-0.97366595]\n",
      " [-0.97850174]\n",
      " [-0.9730072 ]\n",
      " [-0.9760859 ]\n",
      " [-0.97932208]\n",
      " [-0.98285729]\n",
      " [-0.9710778 ]\n",
      " [-0.97446442]\n",
      " [-0.97673106]\n",
      " [-0.9788143 ]\n",
      " [-0.97525686]\n",
      " [-0.97876495]\n",
      " [-0.98030835]\n",
      " [-0.97954202]\n",
      " [-0.96917969]\n",
      " [-0.98119891]\n",
      " [-0.97876745]\n",
      " [-0.98117888]\n",
      " [-0.97828925]\n",
      " [-0.97423941]\n",
      " [-0.97465426]\n",
      " [-0.97818106]\n",
      " [-0.98141283]\n",
      " [-0.97713423]\n",
      " [-0.97455269]\n",
      " [-0.97512376]\n",
      " [-0.97625595]\n",
      " [-0.97433454]\n",
      " [-0.9692924 ]\n",
      " [-0.96804816]\n",
      " [-0.98638415]\n",
      " [-0.98395681]\n",
      " [-0.98091024]\n",
      " [-0.97772294]\n",
      " [-0.97770005]\n",
      " [-0.97746909]\n",
      " [-0.97478861]\n",
      " [-0.98102653]\n",
      " [-0.97584802]\n",
      " [-0.97584671]\n",
      " [-0.97686553]\n",
      " [-0.98446375]\n",
      " [-0.97659761]\n",
      " [-0.97807837]\n",
      " [-0.98222071]\n",
      " [-0.98061723]\n",
      " [-0.97730148]\n",
      " [-0.98072433]\n",
      " [-0.97492683]\n",
      " [-0.97355825]\n",
      " [-0.97635913]\n",
      " [-0.97602087]\n",
      " [-0.98050654]\n",
      " [-0.97859168]\n",
      " [-0.97379458]\n",
      " [-0.97463912]\n",
      " [-0.96734393]\n",
      " [-0.97611487]\n",
      " [-0.97546095]\n",
      " [-0.9756968 ]\n",
      " [-0.97316658]\n",
      " [-0.96620119]\n",
      " [-0.98311585]\n",
      " [-0.98181361]\n",
      " [-0.97531134]\n",
      " [-0.97763735]\n",
      " [-0.97653085]\n",
      " [-0.97896928]\n",
      " [-0.97724009]\n",
      " [-0.97559601]\n",
      " [-0.97833043]\n",
      " [-0.97401053]\n",
      " [-0.97549796]\n",
      " [-0.97602707]\n",
      " [-0.97538376]\n",
      " [-0.97714579]\n",
      " [-0.97208107]\n",
      " [-0.97341913]\n",
      " [-0.98314422]\n",
      " [-0.97556996]\n",
      " [-0.97960126]\n",
      " [-0.9767077 ]\n",
      " [-0.97528082]\n",
      " [-0.97940111]\n",
      " [-0.97959375]\n",
      " [-0.97464478]\n",
      " [-0.97417241]\n",
      " [-0.97278368]\n",
      " [-0.97543931]\n",
      " [-0.97454637]\n",
      " [-0.97361368]\n",
      " [-0.97458696]\n",
      " [-0.99072617]\n",
      " [-0.97729784]\n",
      " [-0.9757548 ]\n",
      " [-0.97231507]\n",
      " [-0.97031099]\n",
      " [-0.97407985]\n",
      " [-0.97414237]\n",
      " [-0.97662866]\n",
      " [-0.97965109]\n",
      " [-0.97526556]\n",
      " [-0.9761802 ]\n",
      " [-0.97621655]\n",
      " [-0.97614479]\n",
      " [-0.97938621]\n",
      " [-0.97872728]\n",
      " [-0.97612548]\n",
      " [-0.97647887]\n",
      " [-0.97476792]\n",
      " [-0.97806925]\n",
      " [-0.98003078]\n",
      " [-0.97514945]\n",
      " [-0.97399032]\n",
      " [-0.97616285]\n",
      " [-0.97378349]\n",
      " [-0.97435433]\n",
      " [-0.98206896]\n",
      " [-0.97590655]\n",
      " [-0.97119653]\n",
      " [-0.98360634]\n",
      " [-0.97257555]\n",
      " [-0.97266912]\n",
      " [-0.9771319 ]\n",
      " [-0.97898185]\n",
      " [-0.97325945]\n",
      " [-0.9756732 ]\n",
      " [-0.97328621]\n",
      " [-0.97459549]\n",
      " [-0.97682589]\n",
      " [-0.97350097]\n",
      " [-0.97624528]\n",
      " [-0.97422945]\n",
      " [-0.97542894]\n",
      " [-0.97499198]\n",
      " [-0.97655606]\n",
      " [-0.97828865]\n",
      " [-0.97851205]\n",
      " [-0.98283988]\n",
      " [-0.97714752]\n",
      " [-0.97578204]\n",
      " [-0.97473794]\n",
      " [-0.98269701]\n",
      " [-0.97786903]\n",
      " [-0.97347158]\n",
      " [-0.98058558]\n",
      " [-0.97383392]\n",
      " [-0.97667283]\n",
      " [-0.97812915]\n",
      " [-0.97516531]\n",
      " [-0.97608209]\n",
      " [-0.97492653]\n",
      " [-0.97627521]\n",
      " [-0.97480547]\n",
      " [-0.97614723]\n",
      " [-0.98055249]\n",
      " [-0.97578621]\n",
      " [-0.96685165]\n",
      " [-0.97672164]\n",
      " [-0.97878724]\n",
      " [-0.97599   ]\n",
      " [-0.97675782]\n",
      " [-0.97333229]\n",
      " [-0.97754049]\n",
      " [-0.97517723]\n",
      " [-0.98606944]\n",
      " [-0.98233879]\n",
      " [-0.97729319]\n",
      " [-0.96891141]\n",
      " [-0.96897334]\n",
      " [-0.97165924]\n",
      " [-0.97850019]\n",
      " [-0.97283816]\n",
      " [-0.97311807]\n",
      " [-0.97805268]\n",
      " [-0.97565985]\n",
      " [-0.9731366 ]\n",
      " [-0.96932787]\n",
      " [-0.97639549]\n",
      " [-0.97186208]\n",
      " [-0.97022456]\n",
      " [-0.9799636 ]\n",
      " [-0.97525007]\n",
      " [-0.97579163]\n",
      " [-0.97845042]\n",
      " [-0.96890187]\n",
      " [-0.97440195]\n",
      " [-0.95343053]\n",
      " [-0.9725737 ]\n",
      " [-0.9834215 ]\n",
      " [-0.98452026]\n",
      " [-0.97368622]\n",
      " [-0.97109151]\n",
      " [-0.9694097 ]\n",
      " [-0.9705112 ]\n",
      " [-0.9709509 ]\n",
      " [-0.97127175]\n",
      " [-0.97094047]\n",
      " [-0.97209376]\n",
      " [-0.98069525]\n",
      " [-0.97553688]\n",
      " [-0.97058898]\n",
      " [-0.97063881]\n",
      " [-0.97378111]\n",
      " [-0.97261393]\n",
      " [-0.97562689]\n",
      " [-0.97113252]\n",
      " [-0.97428489]\n",
      " [-0.97417402]\n",
      " [-0.97472399]\n",
      " [-0.97069842]\n",
      " [-0.97394294]\n",
      " [-0.98283583]\n",
      " [-0.96971351]\n",
      " [-0.97557759]\n",
      " [-0.97316122]\n",
      " [-0.97154176]\n",
      " [-0.97317892]\n",
      " [-0.97373712]\n",
      " [-0.97372055]\n",
      " [-0.97445679]\n",
      " [-0.96993113]\n",
      " [-0.97195733]\n",
      " [-0.974307  ]\n",
      " [-0.97213149]\n",
      " [-0.97239196]\n",
      " [-0.97177428]\n",
      " [-0.97279227]\n",
      " [-0.9732483 ]\n",
      " [-0.97496742]\n",
      " [-0.9745149 ]\n",
      " [-0.97459269]\n",
      " [-0.97490573]\n",
      " [-0.97376961]\n",
      " [-0.97570729]\n",
      " [-0.97420168]\n",
      " [-0.97272819]\n",
      " [-0.97805017]\n",
      " [-0.97469056]\n",
      " [-0.97316283]\n",
      " [-0.97183877]\n",
      " [-0.97355521]\n",
      " [-0.96753591]\n",
      " [-0.97088695]\n",
      " [-0.97206855]\n",
      " [-0.97234213]\n",
      " [-0.97498596]\n",
      " [-0.96629286]\n",
      " [-0.97162169]\n",
      " [-0.97262883]\n",
      " [-0.97057503]\n",
      " [-0.97135127]\n",
      " [-0.97631574]\n",
      " [-0.97316819]\n",
      " [-0.97053343]\n",
      " [-0.97415   ]\n",
      " [-0.97506833]\n",
      " [-0.97363901]\n",
      " [-0.97808611]\n",
      " [-0.9842453 ]\n",
      " [-0.98116034]\n",
      " [-0.96491599]\n",
      " [-0.97430056]\n",
      " [-0.97216815]\n",
      " [-0.97035187]\n",
      " [-0.96878928]\n",
      " [-0.96863437]\n",
      " [-0.97118056]\n",
      " [-0.97165704]\n",
      " [-0.99469948]\n",
      " [-0.98137522]\n",
      " [-0.96498924]\n",
      " [-0.97432268]\n",
      " [-0.9740181 ]\n",
      " [-0.96550769]\n",
      " [-0.97825867]\n",
      " [-0.97428924]\n",
      " [-0.97118241]\n",
      " [-0.97555763]\n",
      " [-0.96620482]\n",
      " [-0.96984982]\n",
      " [-0.97363174]\n",
      " [-0.97574013]\n",
      " [-0.97325492]\n",
      " [-0.97106028]\n",
      " [-0.98666137]\n",
      " [-0.97219241]\n",
      " [-0.97146612]\n",
      " [-0.96938658]\n",
      " [-0.96908563]\n",
      " [-0.9716844 ]\n",
      " [-0.97496498]\n",
      " [-0.9700017 ]\n",
      " [-0.98300707]\n",
      " [-0.98042506]\n",
      " [-0.97794664]\n",
      " [-0.97815871]\n",
      " [-0.97496605]\n",
      " [-0.97348523]\n",
      " [-0.97578931]\n",
      " [-0.97353524]\n",
      " [-0.97601438]\n",
      " [-0.97318816]\n",
      " [-0.97592485]\n",
      " [-0.97506708]\n",
      " [-0.97176856]\n",
      " [-0.97370744]\n",
      " [-0.97604406]\n",
      " [-0.97027397]\n",
      " [-0.98089296]\n",
      " [-0.97712344]\n",
      " [-0.97001374]\n",
      " [-0.97327584]\n",
      " [-0.97217482]\n",
      " [-0.97420156]\n",
      " [-0.97349358]\n",
      " [-0.97723508]\n",
      " [-0.98509079]\n",
      " [-0.98210752]\n",
      " [-0.97372198]\n",
      " [-0.97412819]\n",
      " [-0.96721429]\n",
      " [-0.97955203]\n",
      " [-0.97337323]\n",
      " [-0.97320098]\n",
      " [-0.97129929]\n",
      " [-0.96933663]\n",
      " [-0.9706521 ]\n",
      " [-0.97493911]\n",
      " [-0.97184396]\n",
      " [-0.97482383]\n",
      " [-0.97185427]\n",
      " [-0.97176087]\n",
      " [-0.97332656]\n",
      " [-0.97054893]\n",
      " [-0.96649361]\n",
      " [-0.96597075]\n",
      " [-0.96588188]\n",
      " [-0.9701342 ]\n",
      " [-0.97760832]\n",
      " [-0.97164732]\n",
      " [-0.96401918]\n",
      " [-0.96862358]\n",
      " [-0.97140688]\n",
      " [-0.96909219]\n",
      " [-0.96946013]\n",
      " [-0.97151512]\n",
      " [-0.97241682]\n",
      " [-0.97099566]\n",
      " [-0.97344446]\n",
      " [-0.9719882 ]\n",
      " [-0.98994339]\n",
      " [-0.96586776]\n",
      " [-0.96802634]\n",
      " [-0.96607995]\n",
      " [-0.96753258]\n",
      " [-0.96541184]\n",
      " [-0.97033232]\n",
      " [-0.9677906 ]\n",
      " [-0.97021031]\n",
      " [-0.96823347]\n",
      " [-0.9630453 ]\n",
      " [-0.96748233]\n",
      " [-0.9702968 ]\n",
      " [-0.96555483]\n",
      " [-0.97119164]\n",
      " [-0.96306092]\n",
      " [-0.96706259]\n",
      " [-0.967296  ]\n",
      " [-0.96692222]\n",
      " [-0.96409082]\n",
      " [-0.96765184]\n",
      " [-0.97131568]\n",
      " [-0.96227866]\n",
      " [-0.96316206]\n",
      " [-0.97526813]\n",
      " [-0.96914625]\n",
      " [-0.97271377]\n",
      " [-0.96711087]\n",
      " [-0.96928138]\n",
      " [-0.98269457]\n",
      " [-0.96949106]\n",
      " [-0.96514601]\n",
      " [-0.96461546]\n",
      " [-0.96202523]\n",
      " [-0.96215838]\n",
      " [-0.9683879 ]\n",
      " [-0.96457726]\n",
      " [-0.97106117]\n",
      " [-0.96554404]\n",
      " [-0.96832681]\n",
      " [-0.96582067]\n",
      " [-0.96922803]\n",
      " [-0.96512526]\n",
      " [-0.96748972]\n",
      " [-0.96570671]\n",
      " [-0.96430594]\n",
      " [-0.96583784]\n",
      " [-0.97312284]\n",
      " [-0.97630018]\n",
      " [-0.97282922]\n",
      " [-0.96670341]\n",
      " [-0.96781534]\n",
      " [-0.96385473]\n",
      " [-0.962565  ]\n",
      " [-0.96403825]\n",
      " [-0.96810538]\n",
      " [-0.96343118]\n",
      " [-0.96193278]\n",
      " [-0.96324706]\n",
      " [-0.96735412]\n",
      " [-0.96619779]\n",
      " [-0.96372354]\n",
      " [-0.97415054]\n",
      " [-0.97275841]\n",
      " [-0.97139949]\n",
      " [-0.96291596]\n",
      " [-0.96290755]\n",
      " [-0.96402258]\n",
      " [-0.96304816]\n",
      " [-0.96167952]\n",
      " [-0.96900231]\n",
      " [-0.96300459]\n",
      " [-0.95958108]\n",
      " [-0.96677023]\n",
      " [-0.96324652]\n",
      " [-0.96603113]\n",
      " [-0.96022242]\n",
      " [-0.96384376]\n",
      " [-0.95927447]\n",
      " [-0.96454757]\n",
      " [-0.96507937]\n",
      " [-0.9606753 ]\n",
      " [-0.96700978]\n",
      " [-0.96125758]\n",
      " [-0.96363032]\n",
      " [-0.96735644]\n",
      " [-0.97074544]\n",
      " [-0.96387935]\n",
      " [-0.96214163]\n",
      " [-0.96391451]\n",
      " [-0.96268409]\n",
      " [-0.9600656 ]\n",
      " [-0.96833313]\n",
      " [-0.96772546]\n",
      " [-0.9566105 ]\n",
      " [-0.96914786]\n",
      " [-0.97170502]\n",
      " [-0.96171498]\n",
      " [-0.96402442]\n",
      " [-0.961981  ]\n",
      " [-0.97022539]\n",
      " [-0.96854067]\n",
      " [-0.98289484]\n",
      " [-0.96699554]\n",
      " [-0.9673906 ]\n",
      " [-0.96464837]\n",
      " [-0.9715358 ]\n",
      " [-0.97647858]\n",
      " [-0.9578808 ]\n",
      " [-0.97017348]\n",
      " [-0.9702282 ]\n",
      " [-0.96957505]\n",
      " [-0.97110724]\n",
      " [-0.9661805 ]\n",
      " [-0.96960568]\n",
      " [-0.96491349]\n",
      " [-0.96631044]\n",
      " [-0.96628404]\n",
      " [-0.97704244]\n",
      " [-0.96946174]\n",
      " [-0.96567291]\n",
      " [-0.97624308]\n",
      " [-0.9680866 ]\n",
      " [-0.96634829]\n",
      " [-0.97471762]\n",
      " [-0.9729619 ]\n",
      " [-0.95281595]\n",
      " [-0.9696582 ]\n",
      " [-0.97386718]\n",
      " [-0.97048587]\n",
      " [-0.97293031]\n",
      " [-0.97131646]\n",
      " [-0.96878129]\n",
      " [-0.96835768]\n",
      " [-0.96896124]\n",
      " [-0.96920007]\n",
      " [-0.97333902]\n",
      " [-0.9670046 ]\n",
      " [-0.97259802]\n",
      " [-0.96948099]\n",
      " [-0.97112763]\n",
      " [-0.97249961]\n",
      " [-0.97235703]\n",
      " [-0.9632746 ]\n",
      " [-0.97870874]\n",
      " [-0.96697736]\n",
      " [-0.96649224]\n",
      " [-0.96862119]\n",
      " [-0.97468156]\n",
      " [-0.97021133]\n",
      " [-0.98126745]\n",
      " [-0.96885771]\n",
      " [-0.97004664]\n",
      " [-0.9671402 ]\n",
      " [-0.96499079]\n",
      " [-0.96871078]\n",
      " [-0.96940184]\n",
      " [-0.96914589]\n",
      " [-0.96898293]\n",
      " [-0.96711105]\n",
      " [-0.97011673]\n",
      " [-0.9681288 ]\n",
      " [-0.9684574 ]\n",
      " [-0.97150749]\n",
      " [-0.96960336]\n",
      " [-0.96723801]\n",
      " [-0.97794998]\n",
      " [-0.97578967]\n",
      " [-0.96911621]\n",
      " [-0.96574539]\n",
      " [-0.96704865]\n",
      " [-0.96442872]\n",
      " [-0.96830773]\n",
      " [-0.97230941]\n",
      " [-0.962102  ]\n",
      " [-0.97327685]\n",
      " [-0.96586907]\n",
      " [-0.96805686]\n",
      " [-0.96564567]\n",
      " [-0.96800643]\n",
      " [-0.96132815]\n",
      " [-0.96626782]\n",
      " [-0.96557909]\n",
      " [-0.9685787 ]\n",
      " [-0.96772581]\n",
      " [-0.96823335]\n",
      " [-0.97211128]\n",
      " [-0.96763849]\n",
      " [-0.96928221]\n",
      " [-0.96993279]\n",
      " [-0.96899694]\n",
      " [-0.970469  ]\n",
      " [-0.97094131]\n",
      " [-0.96668082]\n",
      " [-0.96819794]\n",
      " [-0.96935219]\n",
      " [-0.96501791]\n",
      " [-0.95834923]\n",
      " [-0.98212159]\n",
      " [-0.96771622]\n",
      " [-0.96101481]\n",
      " [-0.96863991]\n",
      " [-0.9598316 ]\n",
      " [-0.96055108]\n",
      " [-0.96114808]\n",
      " [-0.96161765]\n",
      " [-0.97219574]\n",
      " [-0.96058267]\n",
      " [-0.95806962]\n",
      " [-0.96973372]\n",
      " [-0.95857191]\n",
      " [-0.96380454]\n",
      " [-0.96001595]\n",
      " [-0.95769519]\n",
      " [-0.96077001]\n",
      " [-0.95991713]\n",
      " [-0.96328139]\n",
      " [-0.95965606]\n",
      " [-0.96106577]\n",
      " [-0.96069574]\n",
      " [-0.96047592]\n",
      " [-0.97882187]\n",
      " [-0.9616977 ]\n",
      " [-0.96945053]\n",
      " [-0.97047806]\n",
      " [-0.96870267]\n",
      " [-0.96780694]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (1519, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal P-11 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " ...\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-1.]]\n",
      "Y_HAT:  [[-0.99727094]\n",
      " [-1.00332844]\n",
      " [-0.98317468]\n",
      " ...\n",
      " [-0.96525812]\n",
      " [-0.95571136]\n",
      " [-0.95656532]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200  0.941907\n",
      "1     1222840800  0.944196\n",
      "2     1222862400  0.943751\n",
      "3     1222884000  0.941081\n",
      "4     1222905600  0.941653\n",
      "...          ...       ...\n",
      "3964  1308441600  0.874789\n",
      "3965  1308463200  0.927480\n",
      "3966  1308484800  0.741634\n",
      "3967  1308506400  0.744558\n",
      "3968  1308528000  0.745511\n",
      "\n",
      "[3969 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1308549600  0.930975\n",
      "1     1308571200  0.918009\n",
      "2     1308592800  0.927861\n",
      "3     1308614400  0.921442\n",
      "4     1308636000  0.916484\n",
      "...          ...       ...\n",
      "3530  1384797600  0.567865\n",
      "3531  1384819200  0.513840\n",
      "3532  1384840800  0.498713\n",
      "3533  1384862400  0.659135\n",
      "3534  1384884000  0.566594\n",
      "\n",
      "[3535 rows x 2 columns]\n",
      "TIMESEGMENT:  (3969, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(3969, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.98it/s, epoch=1/20, avg_epoch_loss=-.274]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.044 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.273831\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.59it/s, epoch=2/20, avg_epoch_loss=-1.14]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 8.948 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.135098\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.49it/s, epoch=3/20, avg_epoch_loss=-1.38]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.105 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.381365\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.69it/s, epoch=4/20, avg_epoch_loss=-1.5]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 8.786 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-1.495016\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.66it/s, epoch=5/20, avg_epoch_loss=-1.58]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 8.843 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-1.583549\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.55it/s, epoch=6/20, avg_epoch_loss=-1.66]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.018 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.656725\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.56it/s, epoch=7/20, avg_epoch_loss=-1.63]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 8.995 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-1.630080\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.16it/s, epoch=8/20, avg_epoch_loss=-1.7]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.688 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-1.701085\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.20it/s, epoch=9/20, avg_epoch_loss=-1.76]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 9.626 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.763944\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.47it/s, epoch=10/20, avg_epoch_loss=-1.78]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 9.139 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.775403\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  6.03it/s, epoch=11/20, avg_epoch_loss=-1.77]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 8.289 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.768060\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.94it/s, epoch=12/20, avg_epoch_loss=-1.77]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 8.419 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.767680\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.55it/s, epoch=13/20, avg_epoch_loss=-1.83]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 9.007 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-1.833831\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.68it/s, epoch=14/20, avg_epoch_loss=-1.88]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 8.800 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.882325\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s, epoch=15/20, avg_epoch_loss=-1.84]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 9.681 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.842492\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=16/20, avg_epoch_loss=-1.92]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 11.244 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.921434\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.52it/s, epoch=17/20, avg_epoch_loss=-1.85]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 11.065 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.847275\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.70it/s, epoch=18/20, avg_epoch_loss=-1.91]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 10.633 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.907578\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.49it/s, epoch=19/20, avg_epoch_loss=-1.94]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.114 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.937759\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:08<00:00,  5.61it/s, epoch=20/20, avg_epoch_loss=-1.96]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 8.933 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.961582\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.9419074 ]\n",
      " [0.94419551]\n",
      " [0.9437506 ]\n",
      " ...\n",
      " [0.74163409]\n",
      " [0.74455779]\n",
      " [0.74551117]]\n",
      "Y_HAT:  [[0.27944049]\n",
      " [0.58842957]\n",
      " [0.74225038]\n",
      " ...\n",
      " [0.90931845]\n",
      " [0.81434143]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (3535, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[0.93097531]\n",
      " [0.91800934]\n",
      " [0.92786093]\n",
      " ...\n",
      " [0.49871294]\n",
      " [0.65913497]\n",
      " [0.56659357]]\n",
      "Y_HAT:  [[0.45345959]\n",
      " [0.7724914 ]\n",
      " [0.89301431]\n",
      " ...\n",
      " [0.84739059]\n",
      " [0.85920256]\n",
      " [0.85244489]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal D-15 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -1.000000\n",
      "1     1222840800 -1.000000\n",
      "2     1222862400  0.952800\n",
      "3     1222884000  0.951874\n",
      "4     1222905600 -1.000000\n",
      "...          ...       ...\n",
      "2069  1267509600 -1.000000\n",
      "2070  1267531200  0.868579\n",
      "2071  1267552800  0.867654\n",
      "2072  1267574400  0.867654\n",
      "2073  1267596000  0.867654\n",
      "\n",
      "[2074 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1267617600 -1.000000\n",
      "1     1267639200  0.832485\n",
      "2     1267660800  0.831559\n",
      "3     1267682400  0.831559\n",
      "4     1267704000  0.831559\n",
      "...          ...       ...\n",
      "2153  1314122400  1.271171\n",
      "2154  1314144000  1.267469\n",
      "2155  1314165600  1.262841\n",
      "2156  1314187200  1.261916\n",
      "2157  1314208800  1.261916\n",
      "\n",
      "[2158 rows x 2 columns]\n",
      "TIMESEGMENT:  (2074, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(2074, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.04it/s, epoch=1/20, avg_epoch_loss=0.344]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 9.916 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.344230\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.38it/s, epoch=2/20, avg_epoch_loss=-.325]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 11.418 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.324982\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.14it/s, epoch=3/20, avg_epoch_loss=-.434]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 9.725 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.434297\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.06it/s, epoch=4/20, avg_epoch_loss=-.508]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.874 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.507657\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.39it/s, epoch=5/20, avg_epoch_loss=-.543]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.280 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.543417\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.93it/s, epoch=6/20, avg_epoch_loss=-.638]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 10.140 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-0.637947\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.19it/s, epoch=7/20, avg_epoch_loss=-.654]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.629 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-0.654018\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.51it/s, epoch=8/20, avg_epoch_loss=-.665]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 9.076 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-0.664576\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.89it/s, epoch=9/20, avg_epoch_loss=-.755]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.233 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-0.754697\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.23it/s, epoch=10/20, avg_epoch_loss=-.71] \n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 11.837 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-0.710368\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.79it/s, epoch=11/20, avg_epoch_loss=-.711]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 10.450 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-0.711218\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.53it/s, epoch=12/20, avg_epoch_loss=-.835]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 14.183 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-0.835288\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.97it/s, epoch=13/20, avg_epoch_loss=-.861]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 12.583 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-0.861242\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.70it/s, epoch=14/20, avg_epoch_loss=-.853]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 10.631 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-0.853069\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.05it/s, epoch=15/20, avg_epoch_loss=-.909]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 12.340 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-0.909337\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.62it/s, epoch=16/20, avg_epoch_loss=-.978]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 10.827 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-0.977883\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.30it/s, epoch=17/20, avg_epoch_loss=-.988]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.441 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-0.988132\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.32it/s, epoch=18/20, avg_epoch_loss=-1.03]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.408 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.034493\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.54it/s, epoch=19/20, avg_epoch_loss=-1.08]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 11.011 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.077732\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.90it/s, epoch=20/20, avg_epoch_loss=-1.1] \n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 12.811 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.104306\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.95279963]\n",
      " ...\n",
      " [ 0.86765386]\n",
      " [ 0.86765386]\n",
      " [ 0.86765386]]\n",
      "Y_HAT:  [[0.2183295 ]\n",
      " [0.71901286]\n",
      " [0.3439379 ]\n",
      " ...\n",
      " [0.96620756]\n",
      " [0.97707099]\n",
      " [0.        ]]\n",
      "TIMESEGMENT:  (2158, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [ 0.83248496]\n",
      " [ 0.83155946]\n",
      " ...\n",
      " [ 1.26284128]\n",
      " [ 1.26191578]\n",
      " [ 1.26191578]]\n",
      "Y_HAT:  [[0.04216712]\n",
      " [0.54219741]\n",
      " [0.57026434]\n",
      " ...\n",
      " [0.98332804]\n",
      " [0.9856658 ]\n",
      " [1.02203023]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal D-16 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -1.000000\n",
      "1     1222840800 -1.000000\n",
      "2     1222862400  0.983735\n",
      "3     1222884000 -1.000000\n",
      "4     1222905600 -1.000000\n",
      "...          ...       ...\n",
      "1446  1254052800 -1.000000\n",
      "1447  1254074400 -1.000000\n",
      "1448  1254096000 -1.000000\n",
      "1449  1254117600 -1.000000\n",
      "1450  1254139200 -1.000000\n",
      "\n",
      "[1451 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1254160800 -1.000000\n",
      "1     1254182400 -1.000000\n",
      "2     1254204000 -1.000000\n",
      "3     1254225600 -1.000000\n",
      "4     1254247200 -1.000000\n",
      "...          ...       ...\n",
      "2186  1301378400  0.068929\n",
      "2187  1301400000  0.088535\n",
      "2188  1301421600  0.100492\n",
      "2189  1301443200  0.100492\n",
      "2190  1301464800  0.100492\n",
      "\n",
      "[2191 rows x 2 columns]\n",
      "TIMESEGMENT:  (1451, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(1451, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.43it/s, epoch=1/20, avg_epoch_loss=0.419]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 11.290 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.418714\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.56it/s, epoch=2/20, avg_epoch_loss=-.278]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 9.003 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.278174\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.83it/s, epoch=3/20, avg_epoch_loss=-.241]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 10.356 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.241422\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.02it/s, epoch=4/20, avg_epoch_loss=-.491]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.985 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.491249\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.08it/s, epoch=5/20, avg_epoch_loss=-.659]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.850 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.658943\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.08it/s, epoch=6/20, avg_epoch_loss=-.475]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.847 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-0.474884\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.39it/s, epoch=7/20, avg_epoch_loss=-.737]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 9.274 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-0.737209\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.45it/s, epoch=8/20, avg_epoch_loss=-.632]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 11.250 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-0.631692\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.57it/s, epoch=9/20, avg_epoch_loss=-1.18]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 10.938 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-1.177122\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.36it/s, epoch=10/20, avg_epoch_loss=-1.15]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 11.466 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-1.154994\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.24it/s, epoch=11/20, avg_epoch_loss=-.605]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 11.818 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-0.604980\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.06it/s, epoch=12/20, avg_epoch_loss=-1.43]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 9.889 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-1.426216\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.74it/s, epoch=13/20, avg_epoch_loss=-.85] \n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 10.553 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-0.849826\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.00it/s, epoch=14/20, avg_epoch_loss=-1.41]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 12.492 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-1.407363\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.73it/s, epoch=15/20, avg_epoch_loss=-1.08]\n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 10.572 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.080715\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.23it/s, epoch=16/20, avg_epoch_loss=-1.56]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 9.566 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-1.563613\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.12it/s, epoch=17/20, avg_epoch_loss=-1.31]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.764 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-1.306616\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.15it/s, epoch=18/20, avg_epoch_loss=-1.42]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 9.714 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-1.416539\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.17it/s, epoch=19/20, avg_epoch_loss=-1.55]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 9.672 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.547553\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.04it/s, epoch=20/20, avg_epoch_loss=-1.39]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 12.384 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-1.387342\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-1.        ]\n",
      " [ 0.98373483]\n",
      " ...\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]]\n",
      "Y_HAT:  [[-0.07548382]\n",
      " [-0.35038197]\n",
      " [-0.19269539]\n",
      " ...\n",
      " [-1.00998807]\n",
      " [-1.008479  ]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2191, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal M-7 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " ...\n",
      " [ 0.10049235]\n",
      " [ 0.10049235]\n",
      " [ 0.10049235]]\n",
      "Y_HAT:  [[-0.11119545]\n",
      " [-0.51360232]\n",
      " [ 0.26007465]\n",
      " ...\n",
      " [-0.48429677]\n",
      " [-0.41598618]\n",
      " [-0.39816955]]\n",
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -1.001157\n",
      "1     1222840800 -1.001157\n",
      "2     1222862400 -1.001157\n",
      "3     1222884000 -1.001157\n",
      "4     1222905600 -1.001157\n",
      "...          ...       ...\n",
      "1582  1256990400 -0.999096\n",
      "1583  1257012000 -0.999096\n",
      "1584  1257033600 -0.999096\n",
      "1585  1257055200 -0.999096\n",
      "1586  1257076800 -0.999096\n",
      "\n",
      "[1587 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1257098400 -0.999133\n",
      "1     1257120000 -0.999133\n",
      "2     1257141600 -0.999133\n",
      "3     1257163200 -0.999133\n",
      "4     1257184800 -0.999133\n",
      "...          ...       ...\n",
      "2151  1303560000 -0.999602\n",
      "2152  1303581600 -0.999602\n",
      "2153  1303603200 -0.999602\n",
      "2154  1303624800 -0.999602\n",
      "2155  1303646400 -0.999602\n",
      "\n",
      "[2156 rows x 2 columns]\n",
      "TIMESEGMENT:  (1587, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(1587, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.96it/s, epoch=1/20, avg_epoch_loss=-.762]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 10.084 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=-0.762101\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.38it/s, epoch=2/20, avg_epoch_loss=-1.78]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 11.419 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-1.775114\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.70it/s, epoch=3/20, avg_epoch_loss=-1.93]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 10.639 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-1.925876\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.32it/s, epoch=4/20, avg_epoch_loss=-2.27]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 9.404 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-2.270021\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.39it/s, epoch=5/20, avg_epoch_loss=-2.34]\n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 9.280 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-2.335712\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.10it/s, epoch=6/20, avg_epoch_loss=-1.91]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 9.804 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-1.906648\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.55it/s, epoch=7/20, avg_epoch_loss=-2.56]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 11.002 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-2.560711\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.71it/s, epoch=8/20, avg_epoch_loss=-2.05]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 13.493 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-2.052964\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.05it/s, epoch=9/20, avg_epoch_loss=-2.35]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 12.359 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-2.347200\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.87it/s, epoch=10/20, avg_epoch_loss=-2.83]\n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 12.940 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-2.832758\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.28it/s, epoch=11/20, avg_epoch_loss=-1.14]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 11.697 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-1.138496\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.23it/s, epoch=12/20, avg_epoch_loss=-2.56]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 11.821 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-2.560038\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.24it/s, epoch=13/20, avg_epoch_loss=-2.24]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 11.810 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-2.241905\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.12it/s, epoch=14/20, avg_epoch_loss=-2.82]\n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 12.132 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-2.816519\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.91it/s, epoch=15/20, avg_epoch_loss=-1.8] \n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 12.799 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-1.802788\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.99it/s, epoch=16/20, avg_epoch_loss=-2.97]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 12.527 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-2.974750\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.04it/s, epoch=17/20, avg_epoch_loss=-2.99]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 12.391 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-2.991878\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.91it/s, epoch=18/20, avg_epoch_loss=-2.03]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 12.774 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-2.033306\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.64it/s, epoch=19/20, avg_epoch_loss=-2.91]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 13.740 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-2.905992\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.78it/s, epoch=20/20, avg_epoch_loss=-2.43]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 13.232 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-2.426594\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-1.00115663]\n",
      " [-1.00115663]\n",
      " [-1.00115663]\n",
      " ...\n",
      " [-0.99909638]\n",
      " [-0.99909638]\n",
      " [-0.99909638]]\n",
      "Y_HAT:  [[-0.9778021 ]\n",
      " [-1.01377022]\n",
      " [-1.02157784]\n",
      " ...\n",
      " [-1.01065922]\n",
      " [-1.0101074 ]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2156, 2) 21600 timestamp mean\n",
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.99913252]\n",
      " [-0.99913252]\n",
      " [-0.99913252]\n",
      " ...\n",
      " [-0.99960241]\n",
      " [-0.99960241]\n",
      " [-0.99960241]]\n",
      "Y_HAT:  [[-1.00086033]\n",
      " [-1.01542878]\n",
      " [-0.98623133]\n",
      " ...\n",
      " [-1.01266265]\n",
      " [-1.01796114]\n",
      " [-1.01475596]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orion.benchmark:Scoring pipeline deepar on signal F-8 (test split: True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN:         timestamp     value\n",
      "0     1222819200 -0.826087\n",
      "1     1222840800 -0.869565\n",
      "2     1222862400 -0.869565\n",
      "3     1222884000 -0.782609\n",
      "4     1222905600 -0.869565\n",
      "...          ...       ...\n",
      "3337  1294898400 -0.173913\n",
      "3338  1294920000 -1.000000\n",
      "3339  1294941600 -1.000000\n",
      "3340  1294963200 -1.000000\n",
      "3341  1294984800 -1.000000\n",
      "\n",
      "[3342 rows x 2 columns]\n",
      "TEST:         timestamp     value\n",
      "0     1295006400 -1.000000\n",
      "1     1295028000 -0.565217\n",
      "2     1295049600 -1.000000\n",
      "3     1295071200 -1.000000\n",
      "4     1295092800 -1.000000\n",
      "...          ...       ...\n",
      "2482  1348617600 -1.000000\n",
      "2483  1348639200 -0.956522\n",
      "2484  1348660800 -1.000000\n",
      "2485  1348682400 -0.869565\n",
      "2486  1348704000 -1.000000\n",
      "\n",
      "[2487 rows x 2 columns]\n",
      "TIMESEGMENT:  (3342, 2) 21600 timestamp mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Start model training\n",
      "INFO:gluonts.trainer:Epoch[0] Learning rate is 0.001\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fit\n",
      "(3342, 1)\n",
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gluonts.trainer:Number of parameters in DeepARTrainingNetwork: 27644\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.60it/s, epoch=1/20, avg_epoch_loss=0.154]\n",
      "INFO:gluonts.trainer:Epoch[0] Elapsed time 13.905 seconds\n",
      "INFO:gluonts.trainer:Epoch[0] Evaluation metric 'epoch_loss'=0.154031\n",
      "INFO:gluonts.trainer:Epoch[1] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.86it/s, epoch=2/20, avg_epoch_loss=-.248]\n",
      "INFO:gluonts.trainer:Epoch[1] Elapsed time 12.945 seconds\n",
      "INFO:gluonts.trainer:Epoch[1] Evaluation metric 'epoch_loss'=-0.248125\n",
      "INFO:gluonts.trainer:Epoch[2] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.82it/s, epoch=3/20, avg_epoch_loss=-.442]\n",
      "INFO:gluonts.trainer:Epoch[2] Elapsed time 13.088 seconds\n",
      "INFO:gluonts.trainer:Epoch[2] Evaluation metric 'epoch_loss'=-0.441800\n",
      "INFO:gluonts.trainer:Epoch[3] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.92it/s, epoch=4/20, avg_epoch_loss=-.582]\n",
      "INFO:gluonts.trainer:Epoch[3] Elapsed time 12.758 seconds\n",
      "INFO:gluonts.trainer:Epoch[3] Evaluation metric 'epoch_loss'=-0.581511\n",
      "INFO:gluonts.trainer:Epoch[4] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:17<00:00,  2.94it/s, epoch=5/20, avg_epoch_loss=-.63] \n",
      "INFO:gluonts.trainer:Epoch[4] Elapsed time 17.060 seconds\n",
      "INFO:gluonts.trainer:Epoch[4] Evaluation metric 'epoch_loss'=-0.629539\n",
      "INFO:gluonts.trainer:Epoch[5] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.40it/s, epoch=6/20, avg_epoch_loss=-.71]\n",
      "INFO:gluonts.trainer:Epoch[5] Elapsed time 14.713 seconds\n",
      "INFO:gluonts.trainer:Epoch[5] Evaluation metric 'epoch_loss'=-0.709683\n",
      "INFO:gluonts.trainer:Epoch[6] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.03it/s, epoch=7/20, avg_epoch_loss=-.781]\n",
      "INFO:gluonts.trainer:Epoch[6] Elapsed time 12.424 seconds\n",
      "INFO:gluonts.trainer:Epoch[6] Evaluation metric 'epoch_loss'=-0.780829\n",
      "INFO:gluonts.trainer:Epoch[7] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.16it/s, epoch=8/20, avg_epoch_loss=-.812]\n",
      "INFO:gluonts.trainer:Epoch[7] Elapsed time 12.023 seconds\n",
      "INFO:gluonts.trainer:Epoch[7] Evaluation metric 'epoch_loss'=-0.811806\n",
      "INFO:gluonts.trainer:Epoch[8] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.16it/s, epoch=9/20, avg_epoch_loss=-.801]\n",
      "INFO:gluonts.trainer:Epoch[8] Elapsed time 12.014 seconds\n",
      "INFO:gluonts.trainer:Epoch[8] Evaluation metric 'epoch_loss'=-0.801153\n",
      "INFO:gluonts.trainer:Epoch[9] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.71it/s, epoch=10/20, avg_epoch_loss=-.86] \n",
      "INFO:gluonts.trainer:Epoch[9] Elapsed time 13.472 seconds\n",
      "INFO:gluonts.trainer:Epoch[9] Evaluation metric 'epoch_loss'=-0.860299\n",
      "INFO:gluonts.trainer:Epoch[10] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.02it/s, epoch=11/20, avg_epoch_loss=-.865]\n",
      "INFO:gluonts.trainer:Epoch[10] Elapsed time 12.451 seconds\n",
      "INFO:gluonts.trainer:Epoch[10] Evaluation metric 'epoch_loss'=-0.864824\n",
      "INFO:gluonts.trainer:Epoch[11] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.60it/s, epoch=12/20, avg_epoch_loss=-.843]\n",
      "INFO:gluonts.trainer:Epoch[11] Elapsed time 13.905 seconds\n",
      "INFO:gluonts.trainer:Epoch[11] Evaluation metric 'epoch_loss'=-0.843280\n",
      "INFO:gluonts.trainer:Epoch[12] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:14<00:00,  3.48it/s, epoch=13/20, avg_epoch_loss=-.933]\n",
      "INFO:gluonts.trainer:Epoch[12] Elapsed time 14.375 seconds\n",
      "INFO:gluonts.trainer:Epoch[12] Evaluation metric 'epoch_loss'=-0.932733\n",
      "INFO:gluonts.trainer:Epoch[13] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  3.94it/s, epoch=14/20, avg_epoch_loss=-.89] \n",
      "INFO:gluonts.trainer:Epoch[13] Elapsed time 12.704 seconds\n",
      "INFO:gluonts.trainer:Epoch[13] Evaluation metric 'epoch_loss'=-0.889670\n",
      "INFO:gluonts.trainer:Epoch[14] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:13<00:00,  3.72it/s, epoch=15/20, avg_epoch_loss=-.94] \n",
      "INFO:gluonts.trainer:Epoch[14] Elapsed time 13.425 seconds\n",
      "INFO:gluonts.trainer:Epoch[14] Evaluation metric 'epoch_loss'=-0.940315\n",
      "INFO:gluonts.trainer:Epoch[15] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.89it/s, epoch=16/20, avg_epoch_loss=-.987]\n",
      "INFO:gluonts.trainer:Epoch[15] Elapsed time 10.236 seconds\n",
      "INFO:gluonts.trainer:Epoch[15] Evaluation metric 'epoch_loss'=-0.987440\n",
      "INFO:gluonts.trainer:Epoch[16] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:09<00:00,  5.10it/s, epoch=17/20, avg_epoch_loss=-.9]\n",
      "INFO:gluonts.trainer:Epoch[16] Elapsed time 9.821 seconds\n",
      "INFO:gluonts.trainer:Epoch[16] Evaluation metric 'epoch_loss'=-0.899813\n",
      "INFO:gluonts.trainer:Epoch[17] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:12<00:00,  4.06it/s, epoch=18/20, avg_epoch_loss=-.955]\n",
      "INFO:gluonts.trainer:Epoch[17] Elapsed time 12.330 seconds\n",
      "INFO:gluonts.trainer:Epoch[17] Evaluation metric 'epoch_loss'=-0.954559\n",
      "INFO:gluonts.trainer:Epoch[18] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:10<00:00,  4.72it/s, epoch=19/20, avg_epoch_loss=-1.01]\n",
      "INFO:gluonts.trainer:Epoch[18] Elapsed time 10.593 seconds\n",
      "INFO:gluonts.trainer:Epoch[18] Evaluation metric 'epoch_loss'=-1.007174\n",
      "INFO:gluonts.trainer:Epoch[19] Learning rate is 0.001\n",
      "100%|██████████| 50/50 [00:11<00:00,  4.25it/s, epoch=20/20, avg_epoch_loss=-.967]\n",
      "INFO:gluonts.trainer:Epoch[19] Elapsed time 11.766 seconds\n",
      "INFO:gluonts.trainer:Epoch[19] Evaluation metric 'epoch_loss'=-0.967346\n",
      "INFO:root:Computing averaged parameters.\n",
      "INFO:root:Loading averaged parameters.\n",
      "INFO:gluonts.trainer:End model training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions produced\n",
      "REGRESSION ERRORS\n",
      "Y:  [[-0.82608696]\n",
      " [-0.86956522]\n",
      " [-0.86956522]\n",
      " ...\n",
      " [-1.        ]\n",
      " [-1.        ]\n",
      " [-1.        ]]\n",
      "Y_HAT:  [[-0.86189288]\n",
      " [-0.86118937]\n",
      " [-0.83960783]\n",
      " ...\n",
      " [-0.9971469 ]\n",
      " [-0.97773087]\n",
      " [ 0.        ]]\n",
      "TIMESEGMENT:  (2487, 2) 21600 timestamp mean\n"
     ]
    }
   ],
   "source": [
    "data = {'YAHOOA2': BENCHMARK_DATA['YAHOOA2']}\n",
    "\n",
    "for key in BENCHMARK_DATA:\n",
    "    print(key)\n",
    "    if key in {'MSL'}:\n",
    "        \n",
    "        data = {key: BENCHMARK_DATA[key]}\n",
    "        datasets_names = '_'.join(list(data.keys()))\n",
    "        scores = benchmark(pipelines=pipelines, datasets=data, metrics=metrics, rank='f1')\n",
    "        scores.to_csv(f'notebooks/results/scores_{pipelines[0]}_{datasets_names}_w2000.csv')\n",
    "        summary = _summarize_results_datasets(scores, metrics)\n",
    "        summary.to_csv(f'notebooks/results/summary_{pipelines[0]}_{datasets_names}_w2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.to_csv(f'results/scores_{pipelines[0]}_{datasets_names}.csv')\n",
    "summary = _summarize_results_datasets(scores, metrics)\n",
    "datasets_names = '_'.join(list(data.keys()))\n",
    "summary.to_csv(f'results/summary_{pipelines[0]}_{datasets_names}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>pipeline</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YAHOOA2</td>\n",
       "      <td>deepar</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>199</td>\n",
       "      <td>0.868996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset pipeline  fp  fn   tp        f1\n",
       "0  YAHOOA2   deepar  59   1  199  0.868996"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'YAHOOA1'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
